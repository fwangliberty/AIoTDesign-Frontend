{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN1D_78_features_split_70_30.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwangliberty/AIoTDesign-Frontend/blob/master/CNN1D_78_features_split_70_30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq5p9swvZ04G"
      },
      "source": [
        "# Intrusion Detection using CNN1N for CICIDS 2017 Data Set with 78 Features "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXg4HMXOZ04H"
      },
      "source": [
        "We use the pre-processing dataset, and its splitting rate is 70:15:15.  The train, test and validation sets have connection-based new features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SOKT1sRZ04I"
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH9hOnpmzv6-"
      },
      "source": [
        "def display_metrics(y_test, y_pred, label_names):\n",
        "  print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "  print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
        "  print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
        "  print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
        "\n",
        "  print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
        "  print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
        "  print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
        "\n",
        "  print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
        "  print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
        "  print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
        "\n",
        "  print('\\nClassification Report\\n')\n",
        "  print(classification_report(y_test, y_pred, target_names=label_names))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCwZZFMTZ04J"
      },
      "source": [
        "def display_all(df):\n",
        "    with pd.option_context(\"display.max_rows\", 100, \"display.max_columns\", 100): \n",
        "        print(df)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceDogrv3Z04J"
      },
      "source": [
        "def make_value2index(attacks):\n",
        "    #make dictionary\n",
        "    attacks = sorted(attacks)\n",
        "    d = {}\n",
        "    counter=0\n",
        "    for attack in attacks:\n",
        "        d[attack] = counter\n",
        "        counter+=1\n",
        "    return d"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht3b8hIQZ04K"
      },
      "source": [
        "# chganges label from string to integer/index\n",
        "def encode_label(Y_str):\n",
        "    labels_d = make_value2index(np.unique(Y_str))\n",
        "    Y = [labels_d[y_str] for y_str  in Y_str]\n",
        "    Y = np.array(Y)\n",
        "    return np.array(Y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMisXWZWZ04K"
      },
      "source": [
        "## Step 1. Loading csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwxZ7DrXZ04L"
      },
      "source": [
        "# All columns\n",
        "col_names = np.array(['dst sport count', 'src dport count', 'dst src count', 'dport count', 'sport count', 'dst host count','src host count','Source Port', 'Destination Port',\n",
        "                      'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\n",
        "                      'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
        "                      'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
        "                      'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total',\n",
        "                      'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
        "                      'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\n",
        "                      'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\n",
        "                      'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
        "                      'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
        "                      'Avg Bwd Segment Size','Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
        "                      'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\n",
        "                      'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
        "                      'Idle Std', 'Idle Max', 'Idle Min', 'Label'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoCkMRAcaIA6"
      },
      "source": [
        "### Option 1. Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uaw_A5kaHSj",
        "outputId": "3285a6f1-b3f2-4017-c4f1-492a3a1a86d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qUtBnilZ04M"
      },
      "source": [
        "# load three csv files generated by mlp4nids (Multi-layer perceptron for network intrusion detection )\n",
        "# first load the train set\n",
        "df_train = pd.read_csv('/content/drive/My Drive/CICIDS2017/train_set_ext78_2.csv',names=col_names, skiprows=1)  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBn8DsjhX_U4",
        "outputId": "148826ea-c906-48a9-e66a-53c82c80f649"
      },
      "source": [
        "print('Train set size: ', df_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set size:  (879589, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXYvaCAjZ04P",
        "outputId": "09b69464-a01e-4676-8431-5e65e3bfc8c4"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/CICIDS2017/test_set_ext78_2.csv',names=col_names, skiprows=1)  \n",
        "print('Test set size: ', df_test.shape)\n",
        "\n",
        "df_val = pd.read_csv('/content/drive/My Drive/CICIDS2017/crossval_set_ext78_2.csv',names=col_names, skiprows=1)  \n",
        "print('Validation set size: ', df_val.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set size:  (188483, 79)\n",
            "Validation set size:  (188484, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cbbuInpXhvz"
      },
      "source": [
        "### Option 2. Load from local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLcmd-A8Xhv0"
      },
      "source": [
        "dataroot = '../data/cicids2017clean/train_set_ext.csv'\n",
        "df_train = pd.read_csv(dataroot, names=col_names, skiprows=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9oqAbFyXhv0"
      },
      "source": [
        "dataroot = '../data/cicids2017clean/crossval_set_ext.csv'\n",
        "df_val = pd.read_csv(dataroot, names=col_names, skiprows=1) \n",
        "dataroot = '../data/cicids2017clean/test_set_ext.csv'\n",
        "df_test = pd.read_csv(dataroot, names=col_names, skiprows=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls46tMA9Xhv0"
      },
      "source": [
        "## Step 2. Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "q-oBvrtQXhv0",
        "outputId": "0824808c-c10a-4bc1-ff6a-be47dbac0968"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>61477</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>98136542</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>56</td>\n",
              "      <td>11601</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.656854</td>\n",
              "      <td>5840</td>\n",
              "      <td>0</td>\n",
              "      <td>2320.20</td>\n",
              "      <td>2436.833027</td>\n",
              "      <td>118.783480</td>\n",
              "      <td>0.132468</td>\n",
              "      <td>8.178045e+06</td>\n",
              "      <td>2.460000e+07</td>\n",
              "      <td>85700000</td>\n",
              "      <td>1</td>\n",
              "      <td>97900000</td>\n",
              "      <td>14000000.0</td>\n",
              "      <td>3.190000e+07</td>\n",
              "      <td>85700000</td>\n",
              "      <td>1</td>\n",
              "      <td>286190</td>\n",
              "      <td>71547.5</td>\n",
              "      <td>137766.35380</td>\n",
              "      <td>278139</td>\n",
              "      <td>181</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>112</td>\n",
              "      <td>0.081519</td>\n",
              "      <td>0.050949</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>833.071429</td>\n",
              "      <td>1774.906302</td>\n",
              "      <td>3.150292e+06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>897.153846</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2320.20</td>\n",
              "      <td>8</td>\n",
              "      <td>56</td>\n",
              "      <td>5</td>\n",
              "      <td>11601</td>\n",
              "      <td>256</td>\n",
              "      <td>229</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>996.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>996</td>\n",
              "      <td>996</td>\n",
              "      <td>48900000.0</td>\n",
              "      <td>51900000.0</td>\n",
              "      <td>85700000</td>\n",
              "      <td>12200000</td>\n",
              "      <td>DDoS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>33</td>\n",
              "      <td>49665</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>121917</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>687</td>\n",
              "      <td>361</td>\n",
              "      <td>681</td>\n",
              "      <td>0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>391.454978</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>90.25</td>\n",
              "      <td>172.523187</td>\n",
              "      <td>8596.012041</td>\n",
              "      <td>57.416111</td>\n",
              "      <td>2.031950e+04</td>\n",
              "      <td>2.482528e+04</td>\n",
              "      <td>61854</td>\n",
              "      <td>1</td>\n",
              "      <td>91167</td>\n",
              "      <td>45583.5</td>\n",
              "      <td>2.300996e+04</td>\n",
              "      <td>61854</td>\n",
              "      <td>29313</td>\n",
              "      <td>92688</td>\n",
              "      <td>30896.0</td>\n",
              "      <td>52536.13923</td>\n",
              "      <td>91556</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>88</td>\n",
              "      <td>24.606905</td>\n",
              "      <td>32.809206</td>\n",
              "      <td>0</td>\n",
              "      <td>681</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>253.090046</td>\n",
              "      <td>6.405457e+04</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>149.714286</td>\n",
              "      <td>229.0</td>\n",
              "      <td>90.25</td>\n",
              "      <td>3</td>\n",
              "      <td>687</td>\n",
              "      <td>4</td>\n",
              "      <td>361</td>\n",
              "      <td>8192</td>\n",
              "      <td>5061</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>7</td>\n",
              "      <td>59588</td>\n",
              "      <td>53</td>\n",
              "      <td>17</td>\n",
              "      <td>30773</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>74</td>\n",
              "      <td>262</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>131</td>\n",
              "      <td>131</td>\n",
              "      <td>131.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10918.662464</td>\n",
              "      <td>129.984077</td>\n",
              "      <td>1.025767e+04</td>\n",
              "      <td>1.776074e+04</td>\n",
              "      <td>30766</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>64.992038</td>\n",
              "      <td>64.992038</td>\n",
              "      <td>37</td>\n",
              "      <td>131</td>\n",
              "      <td>74.600000</td>\n",
              "      <td>51.485920</td>\n",
              "      <td>2.650800e+03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>93.250000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>131.00</td>\n",
              "      <td>2</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "      <td>262</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>50918</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16949.152540</td>\n",
              "      <td>1.180000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>118</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>8474.576271</td>\n",
              "      <td>8474.576271</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>905</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>55989</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>47</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42553.191490</td>\n",
              "      <td>4.700000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>42553.191490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>259</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dst sport count  src dport count  dst src count  ...  Idle Max  Idle Min   Label\n",
              "0                2              100            100  ...  85700000  12200000    DDoS\n",
              "1                2               23             13  ...         0         0  BENIGN\n",
              "2                1                2              3  ...         0         0  BENIGN\n",
              "3                2                1              2  ...         0         0  BENIGN\n",
              "4                2                4              2  ...         0         0  BENIGN\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miDxhmNyZ04N"
      },
      "source": [
        "Count the number of attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpKy7b9fZ04O",
        "scrolled": true,
        "outputId": "9545b78c-db28-4bde-fd81-fdfc00a90d11"
      },
      "source": [
        "df_train['Label'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        490029\n",
              "DoS Hulk                      161134\n",
              "PortScan                      110992\n",
              "DDoS                           89590\n",
              "DoS GoldenEye                   7220\n",
              "FTP-Patator                     5621\n",
              "SSH-Patator                     4153\n",
              "DoS slowloris                   4049\n",
              "DoS Slowhttptest                3833\n",
              "Bot                             1401\n",
              "Web Attack � Brute Force        1059\n",
              "Web Attack � XSS                 463\n",
              "Infiltration                      25\n",
              "Web Attack � Sql Injection        12\n",
              "Heartbleed                         8\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "TP5wXlnNtCXd",
        "outputId": "e8181bd5-0791-4b46-c44e-64678b938af3"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>...</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>count</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>mean</td>\n",
              "      <td>63.986114</td>\n",
              "      <td>71.911368</td>\n",
              "      <td>41059.562686</td>\n",
              "      <td>7182.692884</td>\n",
              "      <td>8.358620</td>\n",
              "      <td>2.159931e+07</td>\n",
              "      <td>7.561386</td>\n",
              "      <td>8.259167</td>\n",
              "      <td>6.822941e+02</td>\n",
              "      <td>1.265955e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>4.883591</td>\n",
              "      <td>25.540766</td>\n",
              "      <td>1.082361e+05</td>\n",
              "      <td>3.242660e+04</td>\n",
              "      <td>1.571849e+05</td>\n",
              "      <td>8.865328e+04</td>\n",
              "      <td>1.640646e+07</td>\n",
              "      <td>1.206008e+06</td>\n",
              "      <td>1.730500e+07</td>\n",
              "      <td>1.552621e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>std</td>\n",
              "      <td>40.704131</td>\n",
              "      <td>36.408934</td>\n",
              "      <td>20762.257722</td>\n",
              "      <td>16999.053361</td>\n",
              "      <td>4.518634</td>\n",
              "      <td>3.824665e+07</td>\n",
              "      <td>641.917381</td>\n",
              "      <td>865.356666</td>\n",
              "      <td>8.207379e+03</td>\n",
              "      <td>1.934124e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>612.739185</td>\n",
              "      <td>6.418384</td>\n",
              "      <td>7.164700e+05</td>\n",
              "      <td>3.567006e+05</td>\n",
              "      <td>9.588739e+05</td>\n",
              "      <td>6.668469e+05</td>\n",
              "      <td>3.283531e+07</td>\n",
              "      <td>7.260774e+06</td>\n",
              "      <td>3.390042e+07</td>\n",
              "      <td>3.259279e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>min</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25%</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>33830.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.120000e+02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50%</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>49512.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.867450e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.600000e+01</td>\n",
              "      <td>1.120000e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75%</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57000.000000</td>\n",
              "      <td>1034.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.104332e+07</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.380000e+02</td>\n",
              "      <td>1.159500e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>9.530000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.530000e+02</td>\n",
              "      <td>8.820000e+02</td>\n",
              "      <td>9.553880e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.803576e+06</td>\n",
              "      <td>7.462839e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>max</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65532.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.199999e+08</td>\n",
              "      <td>207964.000000</td>\n",
              "      <td>284602.000000</td>\n",
              "      <td>2.866110e+06</td>\n",
              "      <td>6.270000e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>198636.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>1.100000e+08</td>\n",
              "      <td>7.050000e+07</td>\n",
              "      <td>1.100000e+08</td>\n",
              "      <td>1.100000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>7.420000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 73 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       dst host count  src host count    Source Port  Destination Port  \\\n",
              "count   556548.000000   556548.000000  556548.000000     556548.000000   \n",
              "mean        63.986114       71.911368   41059.562686       7182.692884   \n",
              "std         40.704131       36.408934   20762.257722      16999.053361   \n",
              "min          1.000000        1.000000       0.000000          0.000000   \n",
              "25%         19.000000       42.000000   33830.000000         80.000000   \n",
              "50%         96.000000       97.000000   49512.000000         80.000000   \n",
              "75%        100.000000      100.000000   57000.000000       1034.000000   \n",
              "max        100.000000      100.000000   65535.000000      65532.000000   \n",
              "\n",
              "            Protocol  Flow Duration  Total Fwd Packets  \\\n",
              "count  556548.000000   5.565480e+05      556548.000000   \n",
              "mean        8.358620   2.159931e+07           7.561386   \n",
              "std         4.518634   3.824665e+07         641.917381   \n",
              "min         0.000000  -1.300000e+01           1.000000   \n",
              "25%         6.000000   1.120000e+02           1.000000   \n",
              "50%         6.000000   6.867450e+04           2.000000   \n",
              "75%         6.000000   1.104332e+07           6.000000   \n",
              "max        17.000000   1.199999e+08      207964.000000   \n",
              "\n",
              "       Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "count           556548.000000                 5.565480e+05   \n",
              "mean                 8.259167                 6.822941e+02   \n",
              "std                865.356666                 8.207379e+03   \n",
              "min                  0.000000                 0.000000e+00   \n",
              "25%                  1.000000                 6.000000e+00   \n",
              "50%                  2.000000                 5.600000e+01   \n",
              "75%                  6.000000                 3.380000e+02   \n",
              "max             284602.000000                 2.866110e+06   \n",
              "\n",
              "       Total Length of Bwd Packets  ...  act_data_pkt_fwd  \\\n",
              "count                 5.565480e+05  ...     556548.000000   \n",
              "mean                  1.265955e+04  ...          4.883591   \n",
              "std                   1.934124e+06  ...        612.739185   \n",
              "min                   0.000000e+00  ...          0.000000   \n",
              "25%                   6.000000e+00  ...          0.000000   \n",
              "50%                   1.120000e+02  ...          1.000000   \n",
              "75%                   1.159500e+04  ...          2.000000   \n",
              "max                   6.270000e+08  ...     198636.000000   \n",
              "\n",
              "       min_seg_size_forward   Active Mean    Active Std    Active Max  \\\n",
              "count         556548.000000  5.565480e+05  5.565480e+05  5.565480e+05   \n",
              "mean              25.540766  1.082361e+05  3.242660e+04  1.571849e+05   \n",
              "std                6.418384  7.164700e+05  3.567006e+05  9.588739e+05   \n",
              "min                0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%               20.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "50%               20.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "75%               32.000000  9.530000e+02  0.000000e+00  9.530000e+02   \n",
              "max               60.000000  1.100000e+08  7.050000e+07  1.100000e+08   \n",
              "\n",
              "         Active Min     Idle Mean      Idle Std      Idle Max      Idle Min  \n",
              "count  5.565480e+05  5.565480e+05  5.565480e+05  5.565480e+05  5.565480e+05  \n",
              "mean   8.865328e+04  1.640646e+07  1.206008e+06  1.730500e+07  1.552621e+07  \n",
              "std    6.668469e+05  3.283531e+07  7.260774e+06  3.390042e+07  3.259279e+07  \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
              "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
              "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
              "75%    8.820000e+02  9.553880e+06  0.000000e+00  9.803576e+06  7.462839e+06  \n",
              "max    1.100000e+08  1.200000e+08  7.420000e+07  1.200000e+08  1.200000e+08  \n",
              "\n",
              "[8 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2X3KG4zZ04P"
      },
      "source": [
        "Read test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5hWm9Q-Z04Q",
        "outputId": "b3e5fc1b-1860-45ea-c804-97b540553d1b"
      },
      "source": [
        "print('Test set: ')\n",
        "df_test['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        139135\n",
              "DoS Hulk                       57531\n",
              "PortScan                       39701\n",
              "DDoS                           32006\n",
              "DoS GoldenEye                   2573\n",
              "FTP-Patator                     1983\n",
              "SSH-Patator                     1474\n",
              "DoS slowloris                   1449\n",
              "DoS Slowhttptest                1374\n",
              "Bot                              489\n",
              "Web Attack � Brute Force         376\n",
              "Web Attack � XSS                 163\n",
              "Infiltration                       9\n",
              "Web Attack � Sql Injection         5\n",
              "Heartbleed                         3\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "i5H5oCfvtMm-",
        "outputId": "12508bc0-27a7-4644-bf98-47b34e526bd5"
      },
      "source": [
        "df_test.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>45364.905750</td>\n",
              "      <td>5840.633640</td>\n",
              "      <td>7.480749</td>\n",
              "      <td>2.018494e+07</td>\n",
              "      <td>13.425781</td>\n",
              "      <td>15.071391</td>\n",
              "      <td>5.018160e+02</td>\n",
              "      <td>2.777075e+04</td>\n",
              "      <td>185.079276</td>\n",
              "      <td>9.858127</td>\n",
              "      <td>42.498337</td>\n",
              "      <td>62.543191</td>\n",
              "      <td>1437.918892</td>\n",
              "      <td>16.702825</td>\n",
              "      <td>472.989076</td>\n",
              "      <td>598.916973</td>\n",
              "      <td>1.319690e+06</td>\n",
              "      <td>9.153090e+04</td>\n",
              "      <td>2.091054e+06</td>\n",
              "      <td>4.928267e+06</td>\n",
              "      <td>1.541155e+07</td>\n",
              "      <td>2.119001e+05</td>\n",
              "      <td>1.981716e+07</td>\n",
              "      <td>4.173283e+06</td>\n",
              "      <td>5.569102e+06</td>\n",
              "      <td>1.522487e+07</td>\n",
              "      <td>1.619357e+06</td>\n",
              "      <td>1.058695e+07</td>\n",
              "      <td>2.418274e+06</td>\n",
              "      <td>2.028897e+06</td>\n",
              "      <td>6.305801e+06</td>\n",
              "      <td>1.360565e+06</td>\n",
              "      <td>0.055008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.183946e+02</td>\n",
              "      <td>3.384120e+02</td>\n",
              "      <td>8.541160e+04</td>\n",
              "      <td>6.162424e+03</td>\n",
              "      <td>7.706957</td>\n",
              "      <td>1472.163140</td>\n",
              "      <td>241.332367</td>\n",
              "      <td>466.822599</td>\n",
              "      <td>8.970325e+05</td>\n",
              "      <td>0.058659</td>\n",
              "      <td>0.055008</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.423420</td>\n",
              "      <td>0.383936</td>\n",
              "      <td>0.024473</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.515485</td>\n",
              "      <td>266.229446</td>\n",
              "      <td>42.498337</td>\n",
              "      <td>472.989076</td>\n",
              "      <td>13.425781</td>\n",
              "      <td>5.018160e+02</td>\n",
              "      <td>15.071391</td>\n",
              "      <td>2.777075e+04</td>\n",
              "      <td>10570.921080</td>\n",
              "      <td>1731.267470</td>\n",
              "      <td>10.076965</td>\n",
              "      <td>26.450577</td>\n",
              "      <td>9.950258e+04</td>\n",
              "      <td>4.357601e+04</td>\n",
              "      <td>1.635863e+05</td>\n",
              "      <td>7.265777e+04</td>\n",
              "      <td>1.389976e+07</td>\n",
              "      <td>9.310342e+05</td>\n",
              "      <td>1.461183e+07</td>\n",
              "      <td>1.319746e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17986.051427</td>\n",
              "      <td>15731.041102</td>\n",
              "      <td>3.759347</td>\n",
              "      <td>3.747672e+07</td>\n",
              "      <td>1208.778536</td>\n",
              "      <td>1591.037162</td>\n",
              "      <td>7.898116e+03</td>\n",
              "      <td>3.604963e+06</td>\n",
              "      <td>392.614677</td>\n",
              "      <td>61.235977</td>\n",
              "      <td>99.578231</td>\n",
              "      <td>132.298567</td>\n",
              "      <td>2586.487090</td>\n",
              "      <td>46.983524</td>\n",
              "      <td>797.823718</td>\n",
              "      <td>1144.520735</td>\n",
              "      <td>2.365354e+07</td>\n",
              "      <td>2.939540e+05</td>\n",
              "      <td>5.446991e+06</td>\n",
              "      <td>1.046406e+07</td>\n",
              "      <td>3.156539e+07</td>\n",
              "      <td>3.035605e+06</td>\n",
              "      <td>3.741861e+07</td>\n",
              "      <td>1.178049e+07</td>\n",
              "      <td>1.262896e+07</td>\n",
              "      <td>3.161073e+07</td>\n",
              "      <td>1.066533e+07</td>\n",
              "      <td>2.913323e+07</td>\n",
              "      <td>1.045182e+07</td>\n",
              "      <td>7.731527e+06</td>\n",
              "      <td>2.046630e+07</td>\n",
              "      <td>9.753000e+06</td>\n",
              "      <td>0.227996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.524765e+04</td>\n",
              "      <td>3.182466e+04</td>\n",
              "      <td>2.889885e+05</td>\n",
              "      <td>3.511581e+04</td>\n",
              "      <td>17.933308</td>\n",
              "      <td>2584.335069</td>\n",
              "      <td>383.113699</td>\n",
              "      <td>824.111902</td>\n",
              "      <td>2.290032e+06</td>\n",
              "      <td>0.234986</td>\n",
              "      <td>0.227996</td>\n",
              "      <td>0.008891</td>\n",
              "      <td>0.494102</td>\n",
              "      <td>0.486344</td>\n",
              "      <td>0.154512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008891</td>\n",
              "      <td>0.551013</td>\n",
              "      <td>420.649091</td>\n",
              "      <td>99.578231</td>\n",
              "      <td>797.823718</td>\n",
              "      <td>1208.778536</td>\n",
              "      <td>7.898116e+03</td>\n",
              "      <td>1591.037162</td>\n",
              "      <td>3.604963e+06</td>\n",
              "      <td>17760.016938</td>\n",
              "      <td>7434.284715</td>\n",
              "      <td>1153.408495</td>\n",
              "      <td>6.864564</td>\n",
              "      <td>7.423962e+05</td>\n",
              "      <td>4.382250e+05</td>\n",
              "      <td>1.087195e+06</td>\n",
              "      <td>6.664087e+05</td>\n",
              "      <td>3.055265e+07</td>\n",
              "      <td>6.557272e+06</td>\n",
              "      <td>3.158812e+07</td>\n",
              "      <td>3.024680e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+07</td>\n",
              "      <td>-2.000000e+06</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>39814.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000e+01</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.187093e+01</td>\n",
              "      <td>7.809336e-01</td>\n",
              "      <td>7.100000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.800000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>5.793178e-01</td>\n",
              "      <td>8.503405e-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.309401</td>\n",
              "      <td>5.333333e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50634.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.538300e+04</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.700000e+01</td>\n",
              "      <td>6.100000e+01</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.900480</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.179980e+03</td>\n",
              "      <td>6.026881e+01</td>\n",
              "      <td>2.694690e+04</td>\n",
              "      <td>1.009884e+04</td>\n",
              "      <td>5.489350e+04</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>7.013000e+03</td>\n",
              "      <td>3.503500e+03</td>\n",
              "      <td>3.351686e+02</td>\n",
              "      <td>6.663000e+03</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.200000e+01</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>3.205693e+01</td>\n",
              "      <td>7.639334e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>18.622567</td>\n",
              "      <td>3.468000e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>59.750000</td>\n",
              "      <td>10.900480</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.700000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.100000e+01</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>58142.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.936814e+06</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.560000e+02</td>\n",
              "      <td>4.532000e+03</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>54.333333</td>\n",
              "      <td>111.538871</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>542.958333</td>\n",
              "      <td>663.236171</td>\n",
              "      <td>7.400125e+04</td>\n",
              "      <td>2.631579e+04</td>\n",
              "      <td>1.557685e+06</td>\n",
              "      <td>2.991012e+06</td>\n",
              "      <td>8.012042e+06</td>\n",
              "      <td>7.200000e+01</td>\n",
              "      <td>8.004861e+06</td>\n",
              "      <td>2.007233e+06</td>\n",
              "      <td>2.359285e+06</td>\n",
              "      <td>6.955281e+06</td>\n",
              "      <td>1.450000e+02</td>\n",
              "      <td>2.174638e+05</td>\n",
              "      <td>4.452351e+04</td>\n",
              "      <td>5.501563e+04</td>\n",
              "      <td>1.481998e+05</td>\n",
              "      <td>4.500000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.720000e+02</td>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>1.388889e+04</td>\n",
              "      <td>6.120382e+01</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>298.055556</td>\n",
              "      <td>533.916876</td>\n",
              "      <td>2.850672e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>315.055556</td>\n",
              "      <td>54.333333</td>\n",
              "      <td>542.958333</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.560000e+02</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.532000e+03</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>5.853280e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.860882e+06</td>\n",
              "      <td>5.499876e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>65534.000000</td>\n",
              "      <td>65534.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.199999e+08</td>\n",
              "      <td>219759.000000</td>\n",
              "      <td>291922.000000</td>\n",
              "      <td>1.323378e+06</td>\n",
              "      <td>6.554530e+08</td>\n",
              "      <td>23360.000000</td>\n",
              "      <td>2065.000000</td>\n",
              "      <td>4638.923469</td>\n",
              "      <td>7125.596846</td>\n",
              "      <td>17376.000000</td>\n",
              "      <td>2146.000000</td>\n",
              "      <td>3884.924556</td>\n",
              "      <td>6715.738331</td>\n",
              "      <td>2.071000e+09</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>1.143926e+08</td>\n",
              "      <td>8.478172e+07</td>\n",
              "      <td>1.199946e+08</td>\n",
              "      <td>1.143926e+08</td>\n",
              "      <td>1.199998e+08</td>\n",
              "      <td>1.199610e+08</td>\n",
              "      <td>8.460293e+07</td>\n",
              "      <td>1.199948e+08</td>\n",
              "      <td>1.199610e+08</td>\n",
              "      <td>1.199996e+08</td>\n",
              "      <td>1.199741e+08</td>\n",
              "      <td>8.441801e+07</td>\n",
              "      <td>1.199741e+08</td>\n",
              "      <td>1.199741e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.644908e+06</td>\n",
              "      <td>5.838440e+06</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>389.000000</td>\n",
              "      <td>23360.000000</td>\n",
              "      <td>1877.272727</td>\n",
              "      <td>4414.547151</td>\n",
              "      <td>1.948823e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2068.000000</td>\n",
              "      <td>4638.923469</td>\n",
              "      <td>3884.924556</td>\n",
              "      <td>219759.000000</td>\n",
              "      <td>1.323378e+06</td>\n",
              "      <td>291922.000000</td>\n",
              "      <td>6.554530e+08</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>213557.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>1.016597e+08</td>\n",
              "      <td>6.434950e+07</td>\n",
              "      <td>1.016597e+08</td>\n",
              "      <td>1.016597e+08</td>\n",
              "      <td>1.199946e+08</td>\n",
              "      <td>7.353239e+07</td>\n",
              "      <td>1.199946e+08</td>\n",
              "      <td>1.199946e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Source Port  Destination Port  ...      Idle Max      Idle Min\n",
              "count  278270.000000     278270.000000  ...  2.782700e+05  2.782700e+05\n",
              "mean    45364.905750       5840.633640  ...  1.461183e+07  1.319746e+07\n",
              "std     17986.051427      15731.041102  ...  3.158812e+07  3.024680e+07\n",
              "min         0.000000          0.000000  ...  0.000000e+00  0.000000e+00\n",
              "25%     39814.000000         80.000000  ...  0.000000e+00  0.000000e+00\n",
              "50%     50634.000000         80.000000  ...  0.000000e+00  0.000000e+00\n",
              "75%     58142.000000        443.000000  ...  5.860882e+06  5.499876e+06\n",
              "max     65534.000000      65534.000000  ...  1.199946e+08  1.199946e+08\n",
              "\n",
              "[8 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0-lHNicZ04Q",
        "outputId": "04ed9641-b558-40d6-be3d-aa6715a78e50"
      },
      "source": [
        "print('Validation set: ')\n",
        "df_val['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        139135\n",
              "DoS Hulk                       57531\n",
              "PortScan                       39701\n",
              "DDoS                           32006\n",
              "DoS GoldenEye                   2573\n",
              "FTP-Patator                     1983\n",
              "SSH-Patator                     1474\n",
              "DoS slowloris                   1449\n",
              "DoS Slowhttptest                1374\n",
              "Bot                              489\n",
              "Web Attack � Brute Force         376\n",
              "Web Attack � XSS                 163\n",
              "Infiltration                       9\n",
              "Web Attack � Sql Injection         5\n",
              "Heartbleed                         3\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "jdr4JCpftQvk",
        "outputId": "b9e26e02-ecf1-487b-d241-8ebd703c7c31"
      },
      "source": [
        "df_val.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>42404.657796</td>\n",
              "      <td>4584.284134</td>\n",
              "      <td>8.772361</td>\n",
              "      <td>2.267720e+07</td>\n",
              "      <td>5.697168</td>\n",
              "      <td>5.401071</td>\n",
              "      <td>363.328418</td>\n",
              "      <td>6.993901e+03</td>\n",
              "      <td>146.271053</td>\n",
              "      <td>12.216883</td>\n",
              "      <td>37.118951</td>\n",
              "      <td>48.506259</td>\n",
              "      <td>1644.006185</td>\n",
              "      <td>31.044985</td>\n",
              "      <td>545.020851</td>\n",
              "      <td>677.301293</td>\n",
              "      <td>1.026168e+06</td>\n",
              "      <td>7.647836e+04</td>\n",
              "      <td>2.035292e+06</td>\n",
              "      <td>5.660128e+06</td>\n",
              "      <td>1.867983e+07</td>\n",
              "      <td>1.176209e+05</td>\n",
              "      <td>2.242947e+07</td>\n",
              "      <td>4.097971e+06</td>\n",
              "      <td>7.275898e+06</td>\n",
              "      <td>1.857577e+07</td>\n",
              "      <td>8.532117e+05</td>\n",
              "      <td>1.033244e+07</td>\n",
              "      <td>2.108780e+06</td>\n",
              "      <td>2.497470e+06</td>\n",
              "      <td>6.852268e+06</td>\n",
              "      <td>8.777106e+05</td>\n",
              "      <td>0.032285</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.853584e+04</td>\n",
              "      <td>-6.184786e+03</td>\n",
              "      <td>6.922916e+04</td>\n",
              "      <td>7.292921e+03</td>\n",
              "      <td>11.819104</td>\n",
              "      <td>1667.675854</td>\n",
              "      <td>265.849753</td>\n",
              "      <td>521.021331</td>\n",
              "      <td>1.032910e+06</td>\n",
              "      <td>0.063622</td>\n",
              "      <td>0.032285</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.325008</td>\n",
              "      <td>0.360617</td>\n",
              "      <td>0.052697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.635189</td>\n",
              "      <td>293.529747</td>\n",
              "      <td>37.118951</td>\n",
              "      <td>545.020851</td>\n",
              "      <td>5.697168</td>\n",
              "      <td>363.328418</td>\n",
              "      <td>5.401071</td>\n",
              "      <td>6.994360e+03</td>\n",
              "      <td>8300.353962</td>\n",
              "      <td>1196.878449</td>\n",
              "      <td>2.850606</td>\n",
              "      <td>-6.302925e+03</td>\n",
              "      <td>1.011663e+05</td>\n",
              "      <td>3.866528e+04</td>\n",
              "      <td>1.584032e+05</td>\n",
              "      <td>7.772919e+04</td>\n",
              "      <td>1.758377e+07</td>\n",
              "      <td>9.337417e+05</td>\n",
              "      <td>1.829755e+07</td>\n",
              "      <td>1.689405e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>18921.321337</td>\n",
              "      <td>13260.493797</td>\n",
              "      <td>4.780477</td>\n",
              "      <td>3.957518e+07</td>\n",
              "      <td>67.142466</td>\n",
              "      <td>87.166823</td>\n",
              "      <td>3246.913595</td>\n",
              "      <td>2.585565e+05</td>\n",
              "      <td>380.776699</td>\n",
              "      <td>29.589643</td>\n",
              "      <td>80.881268</td>\n",
              "      <td>118.838474</td>\n",
              "      <td>2798.340693</td>\n",
              "      <td>63.404307</td>\n",
              "      <td>851.938455</td>\n",
              "      <td>1229.566919</td>\n",
              "      <td>1.848896e+07</td>\n",
              "      <td>2.733855e+05</td>\n",
              "      <td>4.353752e+06</td>\n",
              "      <td>1.081619e+07</td>\n",
              "      <td>3.532609e+07</td>\n",
              "      <td>1.940212e+06</td>\n",
              "      <td>3.955407e+07</td>\n",
              "      <td>9.992215e+06</td>\n",
              "      <td>1.450108e+07</td>\n",
              "      <td>3.536583e+07</td>\n",
              "      <td>7.979563e+06</td>\n",
              "      <td>2.928691e+07</td>\n",
              "      <td>9.212534e+06</td>\n",
              "      <td>9.080364e+06</td>\n",
              "      <td>2.268132e+07</td>\n",
              "      <td>8.098570e+06</td>\n",
              "      <td>0.176757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.255039e+06</td>\n",
              "      <td>8.563325e+05</td>\n",
              "      <td>2.681766e+05</td>\n",
              "      <td>3.540818e+04</td>\n",
              "      <td>21.282926</td>\n",
              "      <td>2802.004249</td>\n",
              "      <td>395.033818</td>\n",
              "      <td>872.649085</td>\n",
              "      <td>2.337799e+06</td>\n",
              "      <td>0.244078</td>\n",
              "      <td>0.176757</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.468379</td>\n",
              "      <td>0.480181</td>\n",
              "      <td>0.223428</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.543604</td>\n",
              "      <td>431.308583</td>\n",
              "      <td>80.881268</td>\n",
              "      <td>851.938455</td>\n",
              "      <td>67.142466</td>\n",
              "      <td>3246.913595</td>\n",
              "      <td>87.166823</td>\n",
              "      <td>2.586082e+05</td>\n",
              "      <td>13668.065695</td>\n",
              "      <td>6710.083319</td>\n",
              "      <td>32.991321</td>\n",
              "      <td>7.286969e+05</td>\n",
              "      <td>8.404515e+05</td>\n",
              "      <td>4.487356e+05</td>\n",
              "      <td>1.167019e+06</td>\n",
              "      <td>7.582087e+05</td>\n",
              "      <td>3.455426e+07</td>\n",
              "      <td>6.638199e+06</td>\n",
              "      <td>3.540421e+07</td>\n",
              "      <td>3.437331e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+07</td>\n",
              "      <td>-2.000000e+06</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.929350e+09</td>\n",
              "      <td>-1.677705e+08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-8.388531e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35454.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.700000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.197319e+02</td>\n",
              "      <td>6.190867e-01</td>\n",
              "      <td>6.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.500000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>4.824028e-01</td>\n",
              "      <td>6.077324e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>49688.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.852000e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.380000e+02</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.111790e+03</td>\n",
              "      <td>7.889413e+01</td>\n",
              "      <td>1.977895e+04</td>\n",
              "      <td>1.062092e+04</td>\n",
              "      <td>4.508800e+04</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>7.600000e+01</td>\n",
              "      <td>6.900000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.400000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>3.994567e+01</td>\n",
              "      <td>7.588463e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>59.600000</td>\n",
              "      <td>28.481573</td>\n",
              "      <td>8.112000e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>75.500000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.380000e+02</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>55812.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.181203e+07</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>6.899000e+03</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>79.203964</td>\n",
              "      <td>2052.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>702.750000</td>\n",
              "      <td>757.420270</td>\n",
              "      <td>1.224490e+05</td>\n",
              "      <td>2.597403e+04</td>\n",
              "      <td>1.982858e+06</td>\n",
              "      <td>3.728053e+06</td>\n",
              "      <td>9.999176e+06</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>1.070000e+07</td>\n",
              "      <td>2.714097e+06</td>\n",
              "      <td>3.740416e+06</td>\n",
              "      <td>1.000000e+07</td>\n",
              "      <td>4.800000e+01</td>\n",
              "      <td>1.524908e+05</td>\n",
              "      <td>3.187914e+04</td>\n",
              "      <td>5.662772e+04</td>\n",
              "      <td>1.364448e+05</td>\n",
              "      <td>4.600000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.640000e+02</td>\n",
              "      <td>1.320000e+02</td>\n",
              "      <td>1.333333e+04</td>\n",
              "      <td>8.474576e+03</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>2313.000000</td>\n",
              "      <td>384.862121</td>\n",
              "      <td>682.325913</td>\n",
              "      <td>4.655687e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>408.011858</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>702.750000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.899000e+03</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>6.520000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.520000e+02</td>\n",
              "      <td>5.047500e+02</td>\n",
              "      <td>9.604032e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.992129e+06</td>\n",
              "      <td>7.454226e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65389.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>16412.000000</td>\n",
              "      <td>20326.000000</td>\n",
              "      <td>624920.000000</td>\n",
              "      <td>7.490000e+07</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>2325.000000</td>\n",
              "      <td>5177.256410</td>\n",
              "      <td>5199.042702</td>\n",
              "      <td>15928.000000</td>\n",
              "      <td>1983.000000</td>\n",
              "      <td>5800.500000</td>\n",
              "      <td>8194.660487</td>\n",
              "      <td>2.070000e+09</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>8.480000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.370000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.340000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.335800e+05</td>\n",
              "      <td>6.504400e+05</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1306.000000</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>2265.586207</td>\n",
              "      <td>4731.522394</td>\n",
              "      <td>2.240000e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2328.000000</td>\n",
              "      <td>5177.256410</td>\n",
              "      <td>5800.500000</td>\n",
              "      <td>16412.000000</td>\n",
              "      <td>624920.000000</td>\n",
              "      <td>20326.000000</td>\n",
              "      <td>7.487024e+07</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>6697.000000</td>\n",
              "      <td>5.600000e+01</td>\n",
              "      <td>1.060000e+08</td>\n",
              "      <td>5.040000e+07</td>\n",
              "      <td>1.060000e+08</td>\n",
              "      <td>1.060000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>7.660000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Source Port  Destination Port  ...      Idle Max      Idle Min\n",
              "count  278270.000000     278270.000000  ...  2.782700e+05  2.782700e+05\n",
              "mean    42404.657796       4584.284134  ...  1.829755e+07  1.689405e+07\n",
              "std     18921.321337      13260.493797  ...  3.540421e+07  3.437331e+07\n",
              "min         0.000000          0.000000  ...  0.000000e+00  0.000000e+00\n",
              "25%     35454.000000         53.000000  ...  0.000000e+00  0.000000e+00\n",
              "50%     49688.000000         80.000000  ...  0.000000e+00  0.000000e+00\n",
              "75%     55812.000000        443.000000  ...  9.992129e+06  7.454226e+06\n",
              "max     65535.000000      65389.000000  ...  1.200000e+08  1.200000e+08\n",
              "\n",
              "[8 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0O9ZuKoXhv3"
      },
      "source": [
        "## Step 3. Encode Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwXKhZOjXhv3"
      },
      "source": [
        "Encoding the labels, and generate numpy array. Note that the label has not been encoded as one-hot coding. We will use one-hot code later. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyAnny9yZ04R"
      },
      "source": [
        "### Step 3.1 Encoding train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsR6_hJDZ04R"
      },
      "source": [
        "df_label = df_train['Label']\n",
        "data = df_train.drop(columns=['Label'])\n",
        "Xtrain = data.values\n",
        "y_train = encode_label(df_label.values)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XlV2AK3Z04S"
      },
      "source": [
        "### Step 3.2. Encoding test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVSrGExFZ04S",
        "scrolled": true
      },
      "source": [
        "df_label = df_test['Label']\n",
        "data = df_test.drop(columns=['Label'])\n",
        "Xtest = data.values\n",
        "y_test = encode_label(df_label.values)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO3PgredZ04T"
      },
      "source": [
        "### Step 3.3 Encoding validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ2wDKpZZ04T"
      },
      "source": [
        "df_label = df_val['Label']\n",
        "data = df_val.drop(columns=['Label'])\n",
        "Xval = data.values\n",
        "y_val = encode_label(df_label.values)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viMki-R0Z04Q"
      },
      "source": [
        "## Step 4. Normalization or Standardization\n",
        "\n",
        "The continuous feature values are normalized into the same feature space. This is important when using features that have different measurements, and is a general requirement of many machine learning algorithms. We implement the two methods to see the impact on the final classifications. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ERJidxXhv5"
      },
      "source": [
        "## Option 1. Normalization\n",
        "\n",
        "The values of the datasets are normalized using the Min-Max scaling technique, bringing them all within a range of [0,1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c523vLd-Z04R"
      },
      "source": [
        "### Step 4.1 Normalizing train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5izaj07Z04R"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbYQFmfgZ04S",
        "scrolled": true,
        "outputId": "6de856d7-25cd-4a76-d092-be7170475cff"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.66048676e-01, 5.93603125e-03, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [7.29167620e-01, 1.22077764e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 7.12500000e-01, 7.12500000e-01],\n",
              "       [7.86144808e-01, 6.76005616e-03, 3.52941176e-01, ...,\n",
              "        8.96864890e-03, 4.90833333e-01, 4.83333333e-01],\n",
              "       ...,\n",
              "       [2.53009842e-01, 1.22077764e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [7.85610742e-01, 8.08765183e-04, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [8.26276036e-01, 1.22077764e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ5x1QxAXhv5"
      },
      "source": [
        "### Step 4.2. Normalizing validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_BpWSsXhv6",
        "outputId": "90111a78-a086-461d-a4c4-0979e500e1f8"
      },
      "source": [
        "X_val = scaler.fit_transform(Xval)\n",
        "X_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.37994965e-01, 1.22344737e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [8.41290913e-01, 6.12488339e-02, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [2.87327382e-02, 6.77483980e-03, 3.52941176e-01, ...,\n",
              "        5.68691207e-05, 8.33333333e-02, 8.32947583e-02],\n",
              "       ...,\n",
              "       [9.30510414e-01, 8.10533882e-04, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [6.50492103e-01, 8.68494701e-02, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [4.24353399e-01, 1.22344737e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TItkmTF1Z04S"
      },
      "source": [
        "### Step 4.3. Normalizing test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXmp2w2bZ04T",
        "outputId": "e8c141dc-efba-4c1c-d4ec-7d451e0de593"
      },
      "source": [
        "X_test = scaler.fit_transform(Xtest)\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.45487838e-01, 9.66383862e-01, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [9.17142247e-01, 1.22074038e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [7.92001099e-01, 7.97448653e-02, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       ...,\n",
              "       [9.04507584e-01, 1.22074038e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 8.33370661e-01, 8.33370661e-01],\n",
              "       [9.22345653e-01, 8.08740501e-04, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [5.45030061e-01, 6.75984985e-03, 3.52941176e-01, ...,\n",
              "        5.01804492e-03, 4.88761059e-01, 4.84412289e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge2XVkhTXhv6"
      },
      "source": [
        "## Option 2. Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu459dh3Xhv7"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJud1h5Xhv7",
        "outputId": "3c1d08d3-1bea-4816-94fd-6c865bf38d0b"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_val = scaler.fit_transform(Xval)\n",
        "X_test = scaler.fit_transform(Xtest)\n",
        "\n",
        "X_train"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.29659729,  1.51710965,  1.13640038, ...,  8.4581104 ,\n",
              "         2.22140524, -0.0393603 ],\n",
              "       [-0.29659729, -0.36301636, -0.83451004, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       [-0.33534125, -0.87577799, -1.06105146, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       ...,\n",
              "       [-0.33534125, -0.60718856, -0.83451004, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       [-0.33534125,  1.224103  ,  0.86455067, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       [ 3.50031109, -0.90019522,  1.13640038, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reoNDQZhZ04T"
      },
      "source": [
        "## Step 5 One-hot encoding for labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So8gvIF8Z04T"
      },
      "source": [
        "y_train, y_test and y_val have to be one-hot-encoded. That means they must have dimension (number_of_samples, 15), where 15 denotes number of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc97u4oZZ04U"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfeM_ZzsXhv8"
      },
      "source": [
        "Save the labels for AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0GfC_zXhv8"
      },
      "source": [
        "y_train_ada = y_train\n",
        "y_test_ada = y_test\n",
        "y_val_ada = y_val"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQVqV19KZ04U"
      },
      "source": [
        "y_train = to_categorical(y_train, 15)\n",
        "y_test = to_categorical(y_test, 15)\n",
        "y_val = to_categorical(y_val, 15)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd9_XX_5Xhv8"
      },
      "source": [
        "## Step 6. Define the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqOSi1KcXhv8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#importing confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxRNywIXXhwC"
      },
      "source": [
        "Get the attacks' names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9AlIiTKXhwC"
      },
      "source": [
        "labels_d = make_value2index(df_test['Label'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1vqAhE1XhwC",
        "outputId": "b747d3d7-5218-4756-b3b8-4dd5234b3e99"
      },
      "source": [
        "print(labels_d)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'BENIGN': 105018, 'Bot': 105298, 'DDoS': 124569, 'DoS GoldenEye': 126111, 'DoS Hulk': 160658, 'DoS Slowhttptest': 161486, 'DoS slowloris': 162320, 'FTP-Patator': 163498, 'Heartbleed': 163500, 'Infiltration': 163501, 'PortScan': 187347, 'SSH-Patator': 188173, 'Web Attack � Brute Force': 188382, 'Web Attack � Sql Injection': 188389, 'Web Attack � XSS': 188482}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erUa8gpIZ04U"
      },
      "source": [
        "# CNN1D Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTmLBZDpZ04U"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Flatten, Dense, Activation,Dropout,MaxPooling1D\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLXy3meMZ04U",
        "outputId": "1ac09873-788e-4506-c100-fca6c636f3d8"
      },
      "source": [
        "#hyper-params\n",
        "batch_size = 7500 # increasing batch size with more gpu added\n",
        "input_dim = X_train.shape[1]\n",
        "num_class = 15                   # 15 intrusion classes, including benign traffic class\n",
        "num_epochs = 100\n",
        "learning_rates = 1e-4\n",
        "regularizations = 1e-3\n",
        "optim = tf.keras.optimizers.Adam(lr=learning_rates, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "print(input_dim)\n",
        "print(num_class)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNRbsq6CZ04V",
        "outputId": "4047045f-de1e-437c-ce9f-a3d93c40eff0"
      },
      "source": [
        "#X_train_r = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train_r = np.zeros((len(X_train), input_dim, 1))\n",
        "X_train_r[:, :, 0] = X_train[:, :input_dim]\n",
        "print(X_train_r.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(879589, 78, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjmIpn1HZ04W",
        "outputId": "7cac7fe2-9aec-47a4-8fba-2ab6c39608df"
      },
      "source": [
        "X_test_r = np.zeros((len(X_test), input_dim, 1))\n",
        "X_test_r[:, :, 0] = X_test[:, :input_dim]\n",
        "print(X_test_r.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(188483, 78, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_KlI1VeZ04W",
        "outputId": "cbd0163c-d164-4dea-b580-d3a0613111f5"
      },
      "source": [
        "X_val_r = np.zeros((len(X_val), input_dim, 1))\n",
        "X_val_r[:, :, 0] = X_val[:, :input_dim]\n",
        "print(X_val_r.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(188484, 78, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpTZU5OPZ04W",
        "outputId": "00ca2e8a-ffe1-49bc-fbb8-5c841ab0664b"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "model.add(Conv1D(filters=32, kernel_size=23, activation='relu', padding='same', kernel_initializer='he_uniform', input_shape=(78,1)))\n",
        "model.add(Conv1D(filters=32, kernel_size=17, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling1D(pool_size=2,strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "\n",
        "model.add(Conv1D(filters=64, kernel_size=23, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1D(filters=64, kernel_size=17, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling1D(pool_size=2,strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization(axis=1)) \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_class))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 78, 32)            768       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 78, 32)            17440     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 39, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 39, 32)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 39, 32)            156       \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 39, 64)            47168     \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 39, 64)            69696     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 19, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 19, 64)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 19, 64)            76        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                38944     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                495       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 174,743\n",
            "Trainable params: 174,627\n",
            "Non-trainable params: 116\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpUP50cvVgzg"
      },
      "source": [
        "METRICS = [\r\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\r\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\r\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\r\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'), \r\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\r\n",
        "      tf.keras.metrics.Precision(name='precision'),\r\n",
        "      tf.keras.metrics.Recall(name='recall'),\r\n",
        "      tf.keras.metrics.AUC(name='auc'),\r\n",
        "]\r\n",
        "\r\n",
        "metrics=METRICS"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldBRHXx_50pg",
        "outputId": "e450252c-0023-454c-98a8-d7592c098e9a"
      },
      "source": [
        "from keras.optimizers import Nadam\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "import keras\n",
        "import time\n",
        "time_start = time.time()\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(moniter='val_loss',\n",
        "                                              factor=0.1,\n",
        "                                              patience=10)\n",
        "nadam = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
        "model.compile(loss = \"categorical_crossentropy\",optimizer = \"nadam\", metrics = metrics)\n",
        "\n",
        "#model.compile(\n",
        "#      optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
        "#      loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "#      metrics=metrics)\n",
        "  \n",
        "\n",
        "history = model.fit(X_train_r, y_train, \n",
        "                    epochs=100, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=2,\n",
        "                    validation_data=(X_val_r, y_val),\n",
        "                    callbacks=[reduce_lr])\n",
        "time_end = time.time()\n",
        "train_time = time_end - time_start\n",
        "print(\"train_time:\",train_time)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "118/118 - 61s - loss: 0.2799 - tp: 789330.0000 - fp: 32487.0000 - tn: 12281759.0000 - fn: 90259.0000 - accuracy: 0.9907 - precision: 0.9605 - recall: 0.8974 - auc: 0.9945 - val_loss: 0.1206 - val_tp: 181710.0000 - val_fp: 1604.0000 - val_tn: 2637172.0000 - val_fn: 6774.0000 - val_accuracy: 0.9970 - val_precision: 0.9912 - val_recall: 0.9641 - val_auc: 0.9998\n",
            "Epoch 2/100\n",
            "118/118 - 49s - loss: 0.0595 - tp: 861848.0000 - fp: 12981.0000 - tn: 12301265.0000 - fn: 17741.0000 - accuracy: 0.9977 - precision: 0.9852 - recall: 0.9798 - auc: 0.9993 - val_loss: 0.0382 - val_tp: 185850.0000 - val_fp: 1965.0000 - val_tn: 2636811.0000 - val_fn: 2634.0000 - val_accuracy: 0.9984 - val_precision: 0.9895 - val_recall: 0.9860 - val_auc: 0.9999\n",
            "Epoch 3/100\n",
            "118/118 - 48s - loss: 0.0599 - tp: 862100.0000 - fp: 13339.0000 - tn: 12300907.0000 - fn: 17489.0000 - accuracy: 0.9977 - precision: 0.9848 - recall: 0.9801 - auc: 0.9993 - val_loss: 0.0331 - val_tp: 186369.0000 - val_fp: 1917.0000 - val_tn: 2636859.0000 - val_fn: 2115.0000 - val_accuracy: 0.9986 - val_precision: 0.9898 - val_recall: 0.9888 - val_auc: 0.9998\n",
            "Epoch 4/100\n",
            "118/118 - 48s - loss: 0.0381 - tp: 867839.0000 - fp: 9785.0000 - tn: 12304461.0000 - fn: 11750.0000 - accuracy: 0.9984 - precision: 0.9889 - recall: 0.9866 - auc: 0.9997 - val_loss: 0.0327 - val_tp: 186560.0000 - val_fp: 1832.0000 - val_tn: 2636944.0000 - val_fn: 1924.0000 - val_accuracy: 0.9987 - val_precision: 0.9903 - val_recall: 0.9898 - val_auc: 0.9999\n",
            "Epoch 5/100\n",
            "118/118 - 48s - loss: 0.0337 - tp: 869203.0000 - fp: 9010.0000 - tn: 12305236.0000 - fn: 10386.0000 - accuracy: 0.9985 - precision: 0.9897 - recall: 0.9882 - auc: 0.9997 - val_loss: 0.0263 - val_tp: 186835.0000 - val_fp: 1582.0000 - val_tn: 2637194.0000 - val_fn: 1649.0000 - val_accuracy: 0.9989 - val_precision: 0.9916 - val_recall: 0.9913 - val_auc: 0.9999\n",
            "Epoch 6/100\n",
            "118/118 - 48s - loss: 0.0313 - tp: 870039.0000 - fp: 8436.0000 - tn: 12305810.0000 - fn: 9550.0000 - accuracy: 0.9986 - precision: 0.9904 - recall: 0.9891 - auc: 0.9998 - val_loss: 0.0252 - val_tp: 186787.0000 - val_fp: 1669.0000 - val_tn: 2637107.0000 - val_fn: 1697.0000 - val_accuracy: 0.9988 - val_precision: 0.9911 - val_recall: 0.9910 - val_auc: 0.9999\n",
            "Epoch 7/100\n",
            "118/118 - 48s - loss: 0.0298 - tp: 870383.0000 - fp: 8232.0000 - tn: 12306014.0000 - fn: 9206.0000 - accuracy: 0.9987 - precision: 0.9906 - recall: 0.9895 - auc: 0.9998 - val_loss: 0.0230 - val_tp: 186806.0000 - val_fp: 1641.0000 - val_tn: 2637135.0000 - val_fn: 1678.0000 - val_accuracy: 0.9988 - val_precision: 0.9913 - val_recall: 0.9911 - val_auc: 0.9999\n",
            "Epoch 8/100\n",
            "118/118 - 48s - loss: 0.0279 - tp: 870889.0000 - fp: 7836.0000 - tn: 12306410.0000 - fn: 8700.0000 - accuracy: 0.9987 - precision: 0.9911 - recall: 0.9901 - auc: 0.9998 - val_loss: 0.0210 - val_tp: 187127.0000 - val_fp: 1321.0000 - val_tn: 2637455.0000 - val_fn: 1357.0000 - val_accuracy: 0.9991 - val_precision: 0.9930 - val_recall: 0.9928 - val_auc: 0.9999\n",
            "Epoch 9/100\n",
            "118/118 - 48s - loss: 0.0263 - tp: 871376.0000 - fp: 7500.0000 - tn: 12306746.0000 - fn: 8213.0000 - accuracy: 0.9988 - precision: 0.9915 - recall: 0.9907 - auc: 0.9998 - val_loss: 0.0296 - val_tp: 186742.0000 - val_fp: 1708.0000 - val_tn: 2637068.0000 - val_fn: 1742.0000 - val_accuracy: 0.9988 - val_precision: 0.9909 - val_recall: 0.9908 - val_auc: 0.9996\n",
            "Epoch 10/100\n",
            "118/118 - 48s - loss: 0.0273 - tp: 871248.0000 - fp: 7629.0000 - tn: 12306617.0000 - fn: 8341.0000 - accuracy: 0.9988 - precision: 0.9913 - recall: 0.9905 - auc: 0.9998 - val_loss: 0.0268 - val_tp: 186906.0000 - val_fp: 1553.0000 - val_tn: 2637223.0000 - val_fn: 1578.0000 - val_accuracy: 0.9989 - val_precision: 0.9918 - val_recall: 0.9916 - val_auc: 0.9995\n",
            "Epoch 11/100\n",
            "118/118 - 48s - loss: 0.0248 - tp: 871970.0000 - fp: 7067.0000 - tn: 12307179.0000 - fn: 7619.0000 - accuracy: 0.9989 - precision: 0.9920 - recall: 0.9913 - auc: 0.9998 - val_loss: 0.0215 - val_tp: 187014.0000 - val_fp: 1440.0000 - val_tn: 2637336.0000 - val_fn: 1470.0000 - val_accuracy: 0.9990 - val_precision: 0.9924 - val_recall: 0.9922 - val_auc: 0.9999\n",
            "Epoch 12/100\n",
            "118/118 - 48s - loss: 0.0241 - tp: 872034.0000 - fp: 6924.0000 - tn: 12307322.0000 - fn: 7555.0000 - accuracy: 0.9989 - precision: 0.9921 - recall: 0.9914 - auc: 0.9999 - val_loss: 0.0208 - val_tp: 187147.0000 - val_fp: 1321.0000 - val_tn: 2637455.0000 - val_fn: 1337.0000 - val_accuracy: 0.9991 - val_precision: 0.9930 - val_recall: 0.9929 - val_auc: 0.9999\n",
            "Epoch 13/100\n",
            "118/118 - 48s - loss: 0.0240 - tp: 872174.0000 - fp: 6834.0000 - tn: 12307412.0000 - fn: 7415.0000 - accuracy: 0.9989 - precision: 0.9922 - recall: 0.9916 - auc: 0.9998 - val_loss: 0.0281 - val_tp: 186564.0000 - val_fp: 1892.0000 - val_tn: 2636884.0000 - val_fn: 1920.0000 - val_accuracy: 0.9987 - val_precision: 0.9900 - val_recall: 0.9898 - val_auc: 0.9999\n",
            "Epoch 14/100\n",
            "118/118 - 48s - loss: 0.0232 - tp: 872391.0000 - fp: 6707.0000 - tn: 12307539.0000 - fn: 7198.0000 - accuracy: 0.9989 - precision: 0.9924 - recall: 0.9918 - auc: 0.9999 - val_loss: 0.0207 - val_tp: 187141.0000 - val_fp: 1327.0000 - val_tn: 2637449.0000 - val_fn: 1343.0000 - val_accuracy: 0.9991 - val_precision: 0.9930 - val_recall: 0.9929 - val_auc: 0.9998\n",
            "Epoch 15/100\n",
            "118/118 - 48s - loss: 0.0226 - tp: 872586.0000 - fp: 6514.0000 - tn: 12307732.0000 - fn: 7003.0000 - accuracy: 0.9990 - precision: 0.9926 - recall: 0.9920 - auc: 0.9999 - val_loss: 0.0202 - val_tp: 187112.0000 - val_fp: 1341.0000 - val_tn: 2637435.0000 - val_fn: 1372.0000 - val_accuracy: 0.9990 - val_precision: 0.9929 - val_recall: 0.9927 - val_auc: 0.9999\n",
            "Epoch 16/100\n",
            "118/118 - 48s - loss: 0.0216 - tp: 872848.0000 - fp: 6270.0000 - tn: 12307976.0000 - fn: 6741.0000 - accuracy: 0.9990 - precision: 0.9929 - recall: 0.9923 - auc: 0.9999 - val_loss: 0.0186 - val_tp: 187283.0000 - val_fp: 1188.0000 - val_tn: 2637588.0000 - val_fn: 1201.0000 - val_accuracy: 0.9992 - val_precision: 0.9937 - val_recall: 0.9936 - val_auc: 0.9999\n",
            "Epoch 17/100\n",
            "118/118 - 48s - loss: 0.0221 - tp: 872720.0000 - fp: 6422.0000 - tn: 12307824.0000 - fn: 6869.0000 - accuracy: 0.9990 - precision: 0.9927 - recall: 0.9922 - auc: 0.9999 - val_loss: 0.0181 - val_tp: 187305.0000 - val_fp: 1163.0000 - val_tn: 2637613.0000 - val_fn: 1179.0000 - val_accuracy: 0.9992 - val_precision: 0.9938 - val_recall: 0.9937 - val_auc: 0.9999\n",
            "Epoch 18/100\n",
            "118/118 - 48s - loss: 0.0214 - tp: 872967.0000 - fp: 6202.0000 - tn: 12308044.0000 - fn: 6622.0000 - accuracy: 0.9990 - precision: 0.9929 - recall: 0.9925 - auc: 0.9999 - val_loss: 0.0198 - val_tp: 187196.0000 - val_fp: 1272.0000 - val_tn: 2637504.0000 - val_fn: 1288.0000 - val_accuracy: 0.9991 - val_precision: 0.9933 - val_recall: 0.9932 - val_auc: 0.9999\n",
            "Epoch 19/100\n",
            "118/118 - 48s - loss: 0.0212 - tp: 872946.0000 - fp: 6216.0000 - tn: 12308030.0000 - fn: 6643.0000 - accuracy: 0.9990 - precision: 0.9929 - recall: 0.9924 - auc: 0.9999 - val_loss: 0.0185 - val_tp: 187238.0000 - val_fp: 1234.0000 - val_tn: 2637542.0000 - val_fn: 1246.0000 - val_accuracy: 0.9991 - val_precision: 0.9935 - val_recall: 0.9934 - val_auc: 0.9999\n",
            "Epoch 20/100\n",
            "118/118 - 48s - loss: 0.0205 - tp: 873126.0000 - fp: 6098.0000 - tn: 12308148.0000 - fn: 6463.0000 - accuracy: 0.9990 - precision: 0.9931 - recall: 0.9927 - auc: 0.9999 - val_loss: 0.0198 - val_tp: 187163.0000 - val_fp: 1311.0000 - val_tn: 2637465.0000 - val_fn: 1321.0000 - val_accuracy: 0.9991 - val_precision: 0.9930 - val_recall: 0.9930 - val_auc: 0.9999\n",
            "Epoch 21/100\n",
            "118/118 - 48s - loss: 0.0204 - tp: 873143.0000 - fp: 6056.0000 - tn: 12308190.0000 - fn: 6446.0000 - accuracy: 0.9991 - precision: 0.9931 - recall: 0.9927 - auc: 0.9999 - val_loss: 0.0179 - val_tp: 187314.0000 - val_fp: 1151.0000 - val_tn: 2637625.0000 - val_fn: 1170.0000 - val_accuracy: 0.9992 - val_precision: 0.9939 - val_recall: 0.9938 - val_auc: 0.9999\n",
            "Epoch 22/100\n",
            "118/118 - 48s - loss: 0.0198 - tp: 873336.0000 - fp: 5934.0000 - tn: 12308312.0000 - fn: 6253.0000 - accuracy: 0.9991 - precision: 0.9933 - recall: 0.9929 - auc: 0.9999 - val_loss: 0.0210 - val_tp: 187133.0000 - val_fp: 1334.0000 - val_tn: 2637442.0000 - val_fn: 1351.0000 - val_accuracy: 0.9991 - val_precision: 0.9929 - val_recall: 0.9928 - val_auc: 0.9998\n",
            "Epoch 23/100\n",
            "118/118 - 48s - loss: 0.0195 - tp: 873434.0000 - fp: 5797.0000 - tn: 12308449.0000 - fn: 6155.0000 - accuracy: 0.9991 - precision: 0.9934 - recall: 0.9930 - auc: 0.9999 - val_loss: 0.0176 - val_tp: 187340.0000 - val_fp: 1125.0000 - val_tn: 2637651.0000 - val_fn: 1144.0000 - val_accuracy: 0.9992 - val_precision: 0.9940 - val_recall: 0.9939 - val_auc: 0.9999\n",
            "Epoch 24/100\n",
            "118/118 - 48s - loss: 0.0195 - tp: 873505.0000 - fp: 5769.0000 - tn: 12308477.0000 - fn: 6084.0000 - accuracy: 0.9991 - precision: 0.9934 - recall: 0.9931 - auc: 0.9999 - val_loss: 0.0196 - val_tp: 187203.0000 - val_fp: 1260.0000 - val_tn: 2637516.0000 - val_fn: 1281.0000 - val_accuracy: 0.9991 - val_precision: 0.9933 - val_recall: 0.9932 - val_auc: 0.9999\n",
            "Epoch 25/100\n",
            "118/118 - 48s - loss: 0.0196 - tp: 873436.0000 - fp: 5831.0000 - tn: 12308415.0000 - fn: 6153.0000 - accuracy: 0.9991 - precision: 0.9934 - recall: 0.9930 - auc: 0.9999 - val_loss: 0.0197 - val_tp: 187129.0000 - val_fp: 1331.0000 - val_tn: 2637445.0000 - val_fn: 1355.0000 - val_accuracy: 0.9990 - val_precision: 0.9929 - val_recall: 0.9928 - val_auc: 0.9999\n",
            "Epoch 26/100\n",
            "118/118 - 48s - loss: 0.0193 - tp: 873468.0000 - fp: 5792.0000 - tn: 12308454.0000 - fn: 6121.0000 - accuracy: 0.9991 - precision: 0.9934 - recall: 0.9930 - auc: 0.9999 - val_loss: 0.0176 - val_tp: 187259.0000 - val_fp: 1206.0000 - val_tn: 2637570.0000 - val_fn: 1225.0000 - val_accuracy: 0.9991 - val_precision: 0.9936 - val_recall: 0.9935 - val_auc: 0.9999\n",
            "Epoch 27/100\n",
            "118/118 - 48s - loss: 0.1178 - tp: 848872.0000 - fp: 21118.0000 - tn: 12293128.0000 - fn: 30717.0000 - accuracy: 0.9961 - precision: 0.9757 - recall: 0.9651 - auc: 0.9973 - val_loss: 0.0930 - val_tp: 183671.0000 - val_fp: 3930.0000 - val_tn: 2634846.0000 - val_fn: 4813.0000 - val_accuracy: 0.9969 - val_precision: 0.9791 - val_recall: 0.9745 - val_auc: 0.9970\n",
            "Epoch 28/100\n",
            "118/118 - 48s - loss: 0.0449 - tp: 865712.0000 - fp: 11646.0000 - tn: 12302600.0000 - fn: 13877.0000 - accuracy: 0.9981 - precision: 0.9867 - recall: 0.9842 - auc: 0.9996 - val_loss: 0.0323 - val_tp: 186357.0000 - val_fp: 1977.0000 - val_tn: 2636799.0000 - val_fn: 2127.0000 - val_accuracy: 0.9985 - val_precision: 0.9895 - val_recall: 0.9887 - val_auc: 0.9999\n",
            "Epoch 29/100\n",
            "118/118 - 48s - loss: 0.0296 - tp: 870460.0000 - fp: 8229.0000 - tn: 12306017.0000 - fn: 9129.0000 - accuracy: 0.9987 - precision: 0.9906 - recall: 0.9896 - auc: 0.9998 - val_loss: 0.0288 - val_tp: 186431.0000 - val_fp: 2015.0000 - val_tn: 2636761.0000 - val_fn: 2053.0000 - val_accuracy: 0.9986 - val_precision: 0.9893 - val_recall: 0.9891 - val_auc: 0.9999\n",
            "Epoch 30/100\n",
            "118/118 - 48s - loss: 0.0252 - tp: 871895.0000 - fp: 7093.0000 - tn: 12307153.0000 - fn: 7694.0000 - accuracy: 0.9989 - precision: 0.9919 - recall: 0.9913 - auc: 0.9998 - val_loss: 0.0205 - val_tp: 187112.0000 - val_fp: 1341.0000 - val_tn: 2637435.0000 - val_fn: 1372.0000 - val_accuracy: 0.9990 - val_precision: 0.9929 - val_recall: 0.9927 - val_auc: 0.9999\n",
            "Epoch 31/100\n",
            "118/118 - 48s - loss: 0.0227 - tp: 872572.0000 - fp: 6516.0000 - tn: 12307730.0000 - fn: 7017.0000 - accuracy: 0.9990 - precision: 0.9926 - recall: 0.9920 - auc: 0.9999 - val_loss: 0.0202 - val_tp: 187168.0000 - val_fp: 1281.0000 - val_tn: 2637495.0000 - val_fn: 1316.0000 - val_accuracy: 0.9991 - val_precision: 0.9932 - val_recall: 0.9930 - val_auc: 0.9999\n",
            "Epoch 32/100\n",
            "118/118 - 48s - loss: 0.0216 - tp: 872922.0000 - fp: 6241.0000 - tn: 12308005.0000 - fn: 6667.0000 - accuracy: 0.9990 - precision: 0.9929 - recall: 0.9924 - auc: 0.9999 - val_loss: 0.0183 - val_tp: 187261.0000 - val_fp: 1194.0000 - val_tn: 2637582.0000 - val_fn: 1223.0000 - val_accuracy: 0.9991 - val_precision: 0.9937 - val_recall: 0.9935 - val_auc: 0.9999\n",
            "Epoch 33/100\n",
            "118/118 - 48s - loss: 0.0208 - tp: 873086.0000 - fp: 6090.0000 - tn: 12308156.0000 - fn: 6503.0000 - accuracy: 0.9990 - precision: 0.9931 - recall: 0.9926 - auc: 0.9999 - val_loss: 0.0220 - val_tp: 186916.0000 - val_fp: 1554.0000 - val_tn: 2637222.0000 - val_fn: 1568.0000 - val_accuracy: 0.9989 - val_precision: 0.9918 - val_recall: 0.9917 - val_auc: 0.9999\n",
            "Epoch 34/100\n",
            "118/118 - 48s - loss: 0.0198 - tp: 873405.0000 - fp: 5846.0000 - tn: 12308400.0000 - fn: 6184.0000 - accuracy: 0.9991 - precision: 0.9934 - recall: 0.9930 - auc: 0.9999 - val_loss: 0.0173 - val_tp: 187353.0000 - val_fp: 1115.0000 - val_tn: 2637661.0000 - val_fn: 1131.0000 - val_accuracy: 0.9992 - val_precision: 0.9941 - val_recall: 0.9940 - val_auc: 0.9999\n",
            "Epoch 35/100\n",
            "118/118 - 48s - loss: 0.0195 - tp: 873443.0000 - fp: 5804.0000 - tn: 12308442.0000 - fn: 6146.0000 - accuracy: 0.9991 - precision: 0.9934 - recall: 0.9930 - auc: 0.9999 - val_loss: 0.0169 - val_tp: 187383.0000 - val_fp: 1083.0000 - val_tn: 2637693.0000 - val_fn: 1101.0000 - val_accuracy: 0.9992 - val_precision: 0.9943 - val_recall: 0.9942 - val_auc: 0.9999\n",
            "Epoch 36/100\n",
            "118/118 - 48s - loss: 0.0193 - tp: 873575.0000 - fp: 5653.0000 - tn: 12308593.0000 - fn: 6014.0000 - accuracy: 0.9991 - precision: 0.9936 - recall: 0.9932 - auc: 0.9999 - val_loss: 0.0169 - val_tp: 187368.0000 - val_fp: 1098.0000 - val_tn: 2637678.0000 - val_fn: 1116.0000 - val_accuracy: 0.9992 - val_precision: 0.9942 - val_recall: 0.9941 - val_auc: 0.9999\n",
            "Epoch 37/100\n",
            "118/118 - 48s - loss: 0.0192 - tp: 873610.0000 - fp: 5625.0000 - tn: 12308621.0000 - fn: 5979.0000 - accuracy: 0.9991 - precision: 0.9936 - recall: 0.9932 - auc: 0.9999 - val_loss: 0.0168 - val_tp: 187371.0000 - val_fp: 1090.0000 - val_tn: 2637686.0000 - val_fn: 1113.0000 - val_accuracy: 0.9992 - val_precision: 0.9942 - val_recall: 0.9941 - val_auc: 0.9999\n",
            "Epoch 38/100\n",
            "118/118 - 48s - loss: 0.0189 - tp: 873663.0000 - fp: 5604.0000 - tn: 12308642.0000 - fn: 5926.0000 - accuracy: 0.9991 - precision: 0.9936 - recall: 0.9933 - auc: 0.9999 - val_loss: 0.0167 - val_tp: 187392.0000 - val_fp: 1073.0000 - val_tn: 2637703.0000 - val_fn: 1092.0000 - val_accuracy: 0.9992 - val_precision: 0.9943 - val_recall: 0.9942 - val_auc: 0.9999\n",
            "Epoch 39/100\n",
            "118/118 - 48s - loss: 0.0190 - tp: 873680.0000 - fp: 5578.0000 - tn: 12308668.0000 - fn: 5909.0000 - accuracy: 0.9991 - precision: 0.9937 - recall: 0.9933 - auc: 0.9999 - val_loss: 0.0166 - val_tp: 187413.0000 - val_fp: 1055.0000 - val_tn: 2637721.0000 - val_fn: 1071.0000 - val_accuracy: 0.9992 - val_precision: 0.9944 - val_recall: 0.9943 - val_auc: 0.9999\n",
            "Epoch 40/100\n",
            "118/118 - 48s - loss: 0.0189 - tp: 873691.0000 - fp: 5537.0000 - tn: 12308709.0000 - fn: 5898.0000 - accuracy: 0.9991 - precision: 0.9937 - recall: 0.9933 - auc: 0.9999 - val_loss: 0.0165 - val_tp: 187408.0000 - val_fp: 1057.0000 - val_tn: 2637719.0000 - val_fn: 1076.0000 - val_accuracy: 0.9992 - val_precision: 0.9944 - val_recall: 0.9943 - val_auc: 0.9999\n",
            "Epoch 41/100\n",
            "118/118 - 48s - loss: 0.0189 - tp: 873660.0000 - fp: 5582.0000 - tn: 12308664.0000 - fn: 5929.0000 - accuracy: 0.9991 - precision: 0.9937 - recall: 0.9933 - auc: 0.9999 - val_loss: 0.0164 - val_tp: 187414.0000 - val_fp: 1053.0000 - val_tn: 2637723.0000 - val_fn: 1070.0000 - val_accuracy: 0.9992 - val_precision: 0.9944 - val_recall: 0.9943 - val_auc: 0.9999\n",
            "Epoch 42/100\n",
            "118/118 - 48s - loss: 0.0187 - tp: 873766.0000 - fp: 5490.0000 - tn: 12308756.0000 - fn: 5823.0000 - accuracy: 0.9991 - precision: 0.9938 - recall: 0.9934 - auc: 0.9999 - val_loss: 0.0165 - val_tp: 187406.0000 - val_fp: 1060.0000 - val_tn: 2637716.0000 - val_fn: 1078.0000 - val_accuracy: 0.9992 - val_precision: 0.9944 - val_recall: 0.9943 - val_auc: 0.9999\n",
            "Epoch 43/100\n",
            "118/118 - 48s - loss: 0.0188 - tp: 873697.0000 - fp: 5572.0000 - tn: 12308674.0000 - fn: 5892.0000 - accuracy: 0.9991 - precision: 0.9937 - recall: 0.9933 - auc: 0.9999 - val_loss: 0.0163 - val_tp: 187422.0000 - val_fp: 1040.0000 - val_tn: 2637736.0000 - val_fn: 1062.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 44/100\n",
            "118/118 - 48s - loss: 0.0185 - tp: 873749.0000 - fp: 5530.0000 - tn: 12308716.0000 - fn: 5840.0000 - accuracy: 0.9991 - precision: 0.9937 - recall: 0.9934 - auc: 0.9999 - val_loss: 0.0163 - val_tp: 187432.0000 - val_fp: 1034.0000 - val_tn: 2637742.0000 - val_fn: 1052.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 45/100\n",
            "118/118 - 48s - loss: 0.0183 - tp: 873913.0000 - fp: 5398.0000 - tn: 12308848.0000 - fn: 5676.0000 - accuracy: 0.9992 - precision: 0.9939 - recall: 0.9935 - auc: 0.9999 - val_loss: 0.0163 - val_tp: 187427.0000 - val_fp: 1040.0000 - val_tn: 2637736.0000 - val_fn: 1057.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 46/100\n",
            "118/118 - 48s - loss: 0.0184 - tp: 873874.0000 - fp: 5377.0000 - tn: 12308869.0000 - fn: 5715.0000 - accuracy: 0.9992 - precision: 0.9939 - recall: 0.9935 - auc: 0.9999 - val_loss: 0.0162 - val_tp: 187420.0000 - val_fp: 1049.0000 - val_tn: 2637727.0000 - val_fn: 1064.0000 - val_accuracy: 0.9993 - val_precision: 0.9944 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 47/100\n",
            "118/118 - 48s - loss: 0.0183 - tp: 873875.0000 - fp: 5403.0000 - tn: 12308843.0000 - fn: 5714.0000 - accuracy: 0.9992 - precision: 0.9939 - recall: 0.9935 - auc: 0.9999 - val_loss: 0.0162 - val_tp: 187434.0000 - val_fp: 1034.0000 - val_tn: 2637742.0000 - val_fn: 1050.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 48/100\n",
            "118/118 - 48s - loss: 0.0180 - tp: 873938.0000 - fp: 5375.0000 - tn: 12308871.0000 - fn: 5651.0000 - accuracy: 0.9992 - precision: 0.9939 - recall: 0.9936 - auc: 0.9999 - val_loss: 0.0162 - val_tp: 187435.0000 - val_fp: 1035.0000 - val_tn: 2637741.0000 - val_fn: 1049.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 49/100\n",
            "118/118 - 48s - loss: 0.0182 - tp: 873856.0000 - fp: 5411.0000 - tn: 12308835.0000 - fn: 5733.0000 - accuracy: 0.9992 - precision: 0.9938 - recall: 0.9935 - auc: 0.9999 - val_loss: 0.0161 - val_tp: 187437.0000 - val_fp: 1033.0000 - val_tn: 2637743.0000 - val_fn: 1047.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 50/100\n",
            "118/118 - 48s - loss: 0.0182 - tp: 873976.0000 - fp: 5300.0000 - tn: 12308946.0000 - fn: 5613.0000 - accuracy: 0.9992 - precision: 0.9940 - recall: 0.9936 - auc: 0.9999 - val_loss: 0.0160 - val_tp: 187451.0000 - val_fp: 1020.0000 - val_tn: 2637756.0000 - val_fn: 1033.0000 - val_accuracy: 0.9993 - val_precision: 0.9946 - val_recall: 0.9945 - val_auc: 0.9999\n",
            "Epoch 51/100\n",
            "118/118 - 48s - loss: 0.0181 - tp: 873927.0000 - fp: 5373.0000 - tn: 12308873.0000 - fn: 5662.0000 - accuracy: 0.9992 - precision: 0.9939 - recall: 0.9936 - auc: 0.9999 - val_loss: 0.0161 - val_tp: 187433.0000 - val_fp: 1037.0000 - val_tn: 2637739.0000 - val_fn: 1051.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 52/100\n",
            "118/118 - 48s - loss: 0.0180 - tp: 873960.0000 - fp: 5325.0000 - tn: 12308921.0000 - fn: 5629.0000 - accuracy: 0.9992 - precision: 0.9939 - recall: 0.9936 - auc: 0.9999 - val_loss: 0.0159 - val_tp: 187444.0000 - val_fp: 1025.0000 - val_tn: 2637751.0000 - val_fn: 1040.0000 - val_accuracy: 0.9993 - val_precision: 0.9946 - val_recall: 0.9945 - val_auc: 0.9999\n",
            "Epoch 53/100\n",
            "118/118 - 48s - loss: 0.0178 - tp: 874051.0000 - fp: 5259.0000 - tn: 12308987.0000 - fn: 5538.0000 - accuracy: 0.9992 - precision: 0.9940 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.0161 - val_tp: 187436.0000 - val_fp: 1034.0000 - val_tn: 2637742.0000 - val_fn: 1048.0000 - val_accuracy: 0.9993 - val_precision: 0.9945 - val_recall: 0.9944 - val_auc: 0.9999\n",
            "Epoch 54/100\n",
            "118/118 - 48s - loss: 0.0177 - tp: 874006.0000 - fp: 5324.0000 - tn: 12308922.0000 - fn: 5583.0000 - accuracy: 0.9992 - precision: 0.9939 - recall: 0.9937 - auc: 0.9999 - val_loss: 0.0158 - val_tp: 187453.0000 - val_fp: 1021.0000 - val_tn: 2637755.0000 - val_fn: 1031.0000 - val_accuracy: 0.9993 - val_precision: 0.9946 - val_recall: 0.9945 - val_auc: 0.9999\n",
            "Epoch 55/100\n",
            "118/118 - 48s - loss: 0.0175 - tp: 874121.0000 - fp: 5188.0000 - tn: 12309058.0000 - fn: 5468.0000 - accuracy: 0.9992 - precision: 0.9941 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.0160 - val_tp: 187448.0000 - val_fp: 1025.0000 - val_tn: 2637751.0000 - val_fn: 1036.0000 - val_accuracy: 0.9993 - val_precision: 0.9946 - val_recall: 0.9945 - val_auc: 0.9999\n",
            "Epoch 56/100\n",
            "118/118 - 48s - loss: 0.0175 - tp: 874104.0000 - fp: 5224.0000 - tn: 12309022.0000 - fn: 5485.0000 - accuracy: 0.9992 - precision: 0.9941 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.0157 - val_tp: 187473.0000 - val_fp: 1000.0000 - val_tn: 2637776.0000 - val_fn: 1011.0000 - val_accuracy: 0.9993 - val_precision: 0.9947 - val_recall: 0.9946 - val_auc: 0.9999\n",
            "Epoch 57/100\n",
            "118/118 - 48s - loss: 0.0176 - tp: 874103.0000 - fp: 5205.0000 - tn: 12309041.0000 - fn: 5486.0000 - accuracy: 0.9992 - precision: 0.9941 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.0156 - val_tp: 187472.0000 - val_fp: 1000.0000 - val_tn: 2637776.0000 - val_fn: 1012.0000 - val_accuracy: 0.9993 - val_precision: 0.9947 - val_recall: 0.9946 - val_auc: 0.9999\n",
            "Epoch 58/100\n",
            "118/118 - 48s - loss: 0.0173 - tp: 874171.0000 - fp: 5163.0000 - tn: 12309083.0000 - fn: 5418.0000 - accuracy: 0.9992 - precision: 0.9941 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.0157 - val_tp: 187466.0000 - val_fp: 1008.0000 - val_tn: 2637768.0000 - val_fn: 1018.0000 - val_accuracy: 0.9993 - val_precision: 0.9947 - val_recall: 0.9946 - val_auc: 0.9999\n",
            "Epoch 59/100\n",
            "118/118 - 48s - loss: 0.0173 - tp: 874172.0000 - fp: 5158.0000 - tn: 12309088.0000 - fn: 5417.0000 - accuracy: 0.9992 - precision: 0.9941 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.0156 - val_tp: 187490.0000 - val_fp: 983.0000 - val_tn: 2637793.0000 - val_fn: 994.0000 - val_accuracy: 0.9993 - val_precision: 0.9948 - val_recall: 0.9947 - val_auc: 0.9999\n",
            "Epoch 60/100\n",
            "118/118 - 48s - loss: 0.0174 - tp: 874175.0000 - fp: 5176.0000 - tn: 12309070.0000 - fn: 5414.0000 - accuracy: 0.9992 - precision: 0.9941 - recall: 0.9938 - auc: 0.9999 - val_loss: 0.0157 - val_tp: 187468.0000 - val_fp: 1007.0000 - val_tn: 2637769.0000 - val_fn: 1016.0000 - val_accuracy: 0.9993 - val_precision: 0.9947 - val_recall: 0.9946 - val_auc: 0.9999\n",
            "Epoch 61/100\n",
            "118/118 - 48s - loss: 0.0172 - tp: 874228.0000 - fp: 5126.0000 - tn: 12309120.0000 - fn: 5361.0000 - accuracy: 0.9992 - precision: 0.9942 - recall: 0.9939 - auc: 0.9999 - val_loss: 0.0155 - val_tp: 187483.0000 - val_fp: 990.0000 - val_tn: 2637786.0000 - val_fn: 1001.0000 - val_accuracy: 0.9993 - val_precision: 0.9947 - val_recall: 0.9947 - val_auc: 0.9999\n",
            "Epoch 62/100\n",
            "118/118 - 48s - loss: 0.0171 - tp: 874218.0000 - fp: 5105.0000 - tn: 12309141.0000 - fn: 5371.0000 - accuracy: 0.9992 - precision: 0.9942 - recall: 0.9939 - auc: 0.9999 - val_loss: 0.0154 - val_tp: 187505.0000 - val_fp: 968.0000 - val_tn: 2637808.0000 - val_fn: 979.0000 - val_accuracy: 0.9993 - val_precision: 0.9949 - val_recall: 0.9948 - val_auc: 0.9999\n",
            "Epoch 63/100\n",
            "118/118 - 48s - loss: 0.0170 - tp: 874221.0000 - fp: 5111.0000 - tn: 12309135.0000 - fn: 5368.0000 - accuracy: 0.9992 - precision: 0.9942 - recall: 0.9939 - auc: 0.9999 - val_loss: 0.0154 - val_tp: 187500.0000 - val_fp: 974.0000 - val_tn: 2637802.0000 - val_fn: 984.0000 - val_accuracy: 0.9993 - val_precision: 0.9948 - val_recall: 0.9948 - val_auc: 0.9999\n",
            "Epoch 64/100\n",
            "118/118 - 48s - loss: 0.0171 - tp: 874248.0000 - fp: 5109.0000 - tn: 12309137.0000 - fn: 5341.0000 - accuracy: 0.9992 - precision: 0.9942 - recall: 0.9939 - auc: 0.9999 - val_loss: 0.0153 - val_tp: 187477.0000 - val_fp: 999.0000 - val_tn: 2637777.0000 - val_fn: 1007.0000 - val_accuracy: 0.9993 - val_precision: 0.9947 - val_recall: 0.9947 - val_auc: 0.9999\n",
            "Epoch 65/100\n",
            "118/118 - 48s - loss: 0.0169 - tp: 874315.0000 - fp: 5030.0000 - tn: 12309216.0000 - fn: 5274.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9940 - auc: 0.9999 - val_loss: 0.0158 - val_tp: 187449.0000 - val_fp: 1017.0000 - val_tn: 2637759.0000 - val_fn: 1035.0000 - val_accuracy: 0.9993 - val_precision: 0.9946 - val_recall: 0.9945 - val_auc: 0.9999\n",
            "Epoch 66/100\n",
            "118/118 - 48s - loss: 0.0170 - tp: 874291.0000 - fp: 5055.0000 - tn: 12309191.0000 - fn: 5298.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9940 - auc: 0.9999 - val_loss: 0.0152 - val_tp: 187516.0000 - val_fp: 955.0000 - val_tn: 2637821.0000 - val_fn: 968.0000 - val_accuracy: 0.9993 - val_precision: 0.9949 - val_recall: 0.9949 - val_auc: 0.9999\n",
            "Epoch 67/100\n",
            "118/118 - 48s - loss: 0.0167 - tp: 874345.0000 - fp: 5013.0000 - tn: 12309233.0000 - fn: 5244.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9940 - auc: 0.9999 - val_loss: 0.0153 - val_tp: 187478.0000 - val_fp: 996.0000 - val_tn: 2637780.0000 - val_fn: 1006.0000 - val_accuracy: 0.9993 - val_precision: 0.9947 - val_recall: 0.9947 - val_auc: 0.9999\n",
            "Epoch 68/100\n",
            "118/118 - 48s - loss: 0.0167 - tp: 874363.0000 - fp: 5025.0000 - tn: 12309221.0000 - fn: 5226.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9941 - auc: 0.9999 - val_loss: 0.0150 - val_tp: 187514.0000 - val_fp: 958.0000 - val_tn: 2637818.0000 - val_fn: 970.0000 - val_accuracy: 0.9993 - val_precision: 0.9949 - val_recall: 0.9949 - val_auc: 0.9999\n",
            "Epoch 69/100\n",
            "118/118 - 48s - loss: 0.0167 - tp: 874359.0000 - fp: 5011.0000 - tn: 12309235.0000 - fn: 5230.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9941 - auc: 0.9999 - val_loss: 0.0149 - val_tp: 187523.0000 - val_fp: 946.0000 - val_tn: 2637830.0000 - val_fn: 961.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9949 - val_auc: 0.9999\n",
            "Epoch 70/100\n",
            "118/118 - 48s - loss: 0.0164 - tp: 874387.0000 - fp: 4990.0000 - tn: 12309256.0000 - fn: 5202.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9941 - auc: 0.9999 - val_loss: 0.0150 - val_tp: 187500.0000 - val_fp: 974.0000 - val_tn: 2637802.0000 - val_fn: 984.0000 - val_accuracy: 0.9993 - val_precision: 0.9948 - val_recall: 0.9948 - val_auc: 0.9999\n",
            "Epoch 71/100\n",
            "118/118 - 48s - loss: 0.0165 - tp: 874451.0000 - fp: 4919.0000 - tn: 12309327.0000 - fn: 5138.0000 - accuracy: 0.9992 - precision: 0.9944 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0147 - val_tp: 187524.0000 - val_fp: 952.0000 - val_tn: 2637824.0000 - val_fn: 960.0000 - val_accuracy: 0.9993 - val_precision: 0.9949 - val_recall: 0.9949 - val_auc: 0.9999\n",
            "Epoch 72/100\n",
            "118/118 - 48s - loss: 0.0164 - tp: 874382.0000 - fp: 5003.0000 - tn: 12309243.0000 - fn: 5207.0000 - accuracy: 0.9992 - precision: 0.9943 - recall: 0.9941 - auc: 0.9999 - val_loss: 0.0149 - val_tp: 187528.0000 - val_fp: 946.0000 - val_tn: 2637830.0000 - val_fn: 956.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9949 - val_auc: 0.9999\n",
            "Epoch 73/100\n",
            "118/118 - 48s - loss: 0.0163 - tp: 874458.0000 - fp: 4921.0000 - tn: 12309325.0000 - fn: 5131.0000 - accuracy: 0.9992 - precision: 0.9944 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0148 - val_tp: 187510.0000 - val_fp: 967.0000 - val_tn: 2637809.0000 - val_fn: 974.0000 - val_accuracy: 0.9993 - val_precision: 0.9949 - val_recall: 0.9948 - val_auc: 0.9999\n",
            "Epoch 74/100\n",
            "118/118 - 48s - loss: 0.0161 - tp: 874475.0000 - fp: 4900.0000 - tn: 12309346.0000 - fn: 5114.0000 - accuracy: 0.9992 - precision: 0.9944 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0147 - val_tp: 187533.0000 - val_fp: 943.0000 - val_tn: 2637833.0000 - val_fn: 951.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 75/100\n",
            "118/118 - 47s - loss: 0.0163 - tp: 874450.0000 - fp: 4911.0000 - tn: 12309335.0000 - fn: 5139.0000 - accuracy: 0.9992 - precision: 0.9944 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0148 - val_tp: 187547.0000 - val_fp: 929.0000 - val_tn: 2637847.0000 - val_fn: 937.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 76/100\n",
            "118/118 - 47s - loss: 0.0162 - tp: 874449.0000 - fp: 4919.0000 - tn: 12309327.0000 - fn: 5140.0000 - accuracy: 0.9992 - precision: 0.9944 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0145 - val_tp: 187538.0000 - val_fp: 937.0000 - val_tn: 2637839.0000 - val_fn: 946.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 77/100\n",
            "118/118 - 47s - loss: 0.0161 - tp: 874515.0000 - fp: 4875.0000 - tn: 12309371.0000 - fn: 5074.0000 - accuracy: 0.9992 - precision: 0.9945 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0148 - val_tp: 187530.0000 - val_fp: 945.0000 - val_tn: 2637831.0000 - val_fn: 954.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9949 - val_auc: 0.9999\n",
            "Epoch 78/100\n",
            "118/118 - 47s - loss: 0.0160 - tp: 874465.0000 - fp: 4924.0000 - tn: 12309322.0000 - fn: 5124.0000 - accuracy: 0.9992 - precision: 0.9944 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0146 - val_tp: 187540.0000 - val_fp: 936.0000 - val_tn: 2637840.0000 - val_fn: 944.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 79/100\n",
            "118/118 - 47s - loss: 0.0159 - tp: 874515.0000 - fp: 4879.0000 - tn: 12309367.0000 - fn: 5074.0000 - accuracy: 0.9992 - precision: 0.9945 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0146 - val_tp: 187539.0000 - val_fp: 939.0000 - val_tn: 2637837.0000 - val_fn: 945.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 80/100\n",
            "118/118 - 47s - loss: 0.0158 - tp: 874558.0000 - fp: 4853.0000 - tn: 12309393.0000 - fn: 5031.0000 - accuracy: 0.9993 - precision: 0.9945 - recall: 0.9943 - auc: 0.9999 - val_loss: 0.0144 - val_tp: 187555.0000 - val_fp: 923.0000 - val_tn: 2637853.0000 - val_fn: 929.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9951 - val_auc: 0.9999\n",
            "Epoch 81/100\n",
            "118/118 - 47s - loss: 0.0159 - tp: 874518.0000 - fp: 4879.0000 - tn: 12309367.0000 - fn: 5071.0000 - accuracy: 0.9992 - precision: 0.9945 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0144 - val_tp: 187546.0000 - val_fp: 933.0000 - val_tn: 2637843.0000 - val_fn: 938.0000 - val_accuracy: 0.9993 - val_precision: 0.9950 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 82/100\n",
            "118/118 - 47s - loss: 0.0158 - tp: 874617.0000 - fp: 4780.0000 - tn: 12309466.0000 - fn: 4972.0000 - accuracy: 0.9993 - precision: 0.9946 - recall: 0.9943 - auc: 0.9999 - val_loss: 0.0143 - val_tp: 187551.0000 - val_fp: 924.0000 - val_tn: 2637852.0000 - val_fn: 933.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 83/100\n",
            "118/118 - 47s - loss: 0.0155 - tp: 874581.0000 - fp: 4807.0000 - tn: 12309439.0000 - fn: 5008.0000 - accuracy: 0.9993 - precision: 0.9945 - recall: 0.9943 - auc: 0.9999 - val_loss: 0.0143 - val_tp: 187550.0000 - val_fp: 923.0000 - val_tn: 2637853.0000 - val_fn: 934.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 84/100\n",
            "118/118 - 47s - loss: 0.0156 - tp: 874559.0000 - fp: 4801.0000 - tn: 12309445.0000 - fn: 5030.0000 - accuracy: 0.9993 - precision: 0.9945 - recall: 0.9943 - auc: 0.9999 - val_loss: 0.0144 - val_tp: 187549.0000 - val_fp: 929.0000 - val_tn: 2637847.0000 - val_fn: 935.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 85/100\n",
            "118/118 - 47s - loss: 0.0156 - tp: 874571.0000 - fp: 4804.0000 - tn: 12309442.0000 - fn: 5018.0000 - accuracy: 0.9993 - precision: 0.9945 - recall: 0.9943 - auc: 0.9999 - val_loss: 0.0142 - val_tp: 187563.0000 - val_fp: 913.0000 - val_tn: 2637863.0000 - val_fn: 921.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9951 - val_auc: 0.9999\n",
            "Epoch 86/100\n",
            "118/118 - 47s - loss: 0.0155 - tp: 874659.0000 - fp: 4722.0000 - tn: 12309524.0000 - fn: 4930.0000 - accuracy: 0.9993 - precision: 0.9946 - recall: 0.9944 - auc: 0.9999 - val_loss: 0.0142 - val_tp: 187547.0000 - val_fp: 932.0000 - val_tn: 2637844.0000 - val_fn: 937.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 87/100\n",
            "118/118 - 47s - loss: 0.0155 - tp: 874712.0000 - fp: 4714.0000 - tn: 12309532.0000 - fn: 4877.0000 - accuracy: 0.9993 - precision: 0.9946 - recall: 0.9945 - auc: 0.9999 - val_loss: 0.0140 - val_tp: 187562.0000 - val_fp: 914.0000 - val_tn: 2637862.0000 - val_fn: 922.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9951 - val_auc: 0.9999\n",
            "Epoch 88/100\n",
            "118/118 - 47s - loss: 0.0154 - tp: 874701.0000 - fp: 4694.0000 - tn: 12309552.0000 - fn: 4888.0000 - accuracy: 0.9993 - precision: 0.9947 - recall: 0.9944 - auc: 0.9999 - val_loss: 0.0141 - val_tp: 187564.0000 - val_fp: 911.0000 - val_tn: 2637865.0000 - val_fn: 920.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9951 - val_auc: 0.9999\n",
            "Epoch 89/100\n",
            "118/118 - 47s - loss: 0.0152 - tp: 874700.0000 - fp: 4692.0000 - tn: 12309554.0000 - fn: 4889.0000 - accuracy: 0.9993 - precision: 0.9947 - recall: 0.9944 - auc: 0.9999 - val_loss: 0.0141 - val_tp: 187548.0000 - val_fp: 927.0000 - val_tn: 2637849.0000 - val_fn: 936.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 90/100\n",
            "118/118 - 47s - loss: 0.0152 - tp: 874726.0000 - fp: 4684.0000 - tn: 12309562.0000 - fn: 4863.0000 - accuracy: 0.9993 - precision: 0.9947 - recall: 0.9945 - auc: 0.9999 - val_loss: 0.0141 - val_tp: 187577.0000 - val_fp: 902.0000 - val_tn: 2637874.0000 - val_fn: 907.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9952 - val_auc: 0.9999\n",
            "Epoch 91/100\n",
            "118/118 - 47s - loss: 0.0152 - tp: 874787.0000 - fp: 4616.0000 - tn: 12309630.0000 - fn: 4802.0000 - accuracy: 0.9993 - precision: 0.9948 - recall: 0.9945 - auc: 0.9999 - val_loss: 0.0139 - val_tp: 187570.0000 - val_fp: 909.0000 - val_tn: 2637867.0000 - val_fn: 914.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9952 - val_auc: 0.9999\n",
            "Epoch 92/100\n",
            "118/118 - 47s - loss: 0.0152 - tp: 874748.0000 - fp: 4663.0000 - tn: 12309583.0000 - fn: 4841.0000 - accuracy: 0.9993 - precision: 0.9947 - recall: 0.9945 - auc: 0.9999 - val_loss: 0.0141 - val_tp: 187551.0000 - val_fp: 927.0000 - val_tn: 2637849.0000 - val_fn: 933.0000 - val_accuracy: 0.9993 - val_precision: 0.9951 - val_recall: 0.9950 - val_auc: 0.9999\n",
            "Epoch 93/100\n",
            "118/118 - 47s - loss: 0.0150 - tp: 874829.0000 - fp: 4587.0000 - tn: 12309659.0000 - fn: 4760.0000 - accuracy: 0.9993 - precision: 0.9948 - recall: 0.9946 - auc: 0.9999 - val_loss: 0.0138 - val_tp: 187575.0000 - val_fp: 899.0000 - val_tn: 2637877.0000 - val_fn: 909.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9952 - val_auc: 0.9999\n",
            "Epoch 94/100\n",
            "118/118 - 47s - loss: 0.0150 - tp: 874768.0000 - fp: 4636.0000 - tn: 12309610.0000 - fn: 4821.0000 - accuracy: 0.9993 - precision: 0.9947 - recall: 0.9945 - auc: 0.9999 - val_loss: 0.0137 - val_tp: 187585.0000 - val_fp: 894.0000 - val_tn: 2637882.0000 - val_fn: 899.0000 - val_accuracy: 0.9994 - val_precision: 0.9953 - val_recall: 0.9952 - val_auc: 0.9999\n",
            "Epoch 95/100\n",
            "118/118 - 47s - loss: 0.0150 - tp: 874788.0000 - fp: 4626.0000 - tn: 12309620.0000 - fn: 4801.0000 - accuracy: 0.9993 - precision: 0.9947 - recall: 0.9945 - auc: 0.9999 - val_loss: 0.0140 - val_tp: 187568.0000 - val_fp: 906.0000 - val_tn: 2637870.0000 - val_fn: 916.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9951 - val_auc: 0.9999\n",
            "Epoch 96/100\n",
            "118/118 - 47s - loss: 0.0151 - tp: 874803.0000 - fp: 4623.0000 - tn: 12309623.0000 - fn: 4786.0000 - accuracy: 0.9993 - precision: 0.9947 - recall: 0.9946 - auc: 0.9999 - val_loss: 0.0137 - val_tp: 187594.0000 - val_fp: 882.0000 - val_tn: 2637894.0000 - val_fn: 890.0000 - val_accuracy: 0.9994 - val_precision: 0.9953 - val_recall: 0.9953 - val_auc: 0.9999\n",
            "Epoch 97/100\n",
            "118/118 - 47s - loss: 0.0148 - tp: 874858.0000 - fp: 4567.0000 - tn: 12309679.0000 - fn: 4731.0000 - accuracy: 0.9993 - precision: 0.9948 - recall: 0.9946 - auc: 0.9999 - val_loss: 0.0138 - val_tp: 187590.0000 - val_fp: 889.0000 - val_tn: 2637887.0000 - val_fn: 894.0000 - val_accuracy: 0.9994 - val_precision: 0.9953 - val_recall: 0.9953 - val_auc: 0.9999\n",
            "Epoch 98/100\n",
            "118/118 - 47s - loss: 0.0149 - tp: 874817.0000 - fp: 4586.0000 - tn: 12309660.0000 - fn: 4772.0000 - accuracy: 0.9993 - precision: 0.9948 - recall: 0.9946 - auc: 0.9999 - val_loss: 0.0137 - val_tp: 187579.0000 - val_fp: 900.0000 - val_tn: 2637876.0000 - val_fn: 905.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9952 - val_auc: 0.9999\n",
            "Epoch 99/100\n",
            "118/118 - 47s - loss: 0.0148 - tp: 874800.0000 - fp: 4598.0000 - tn: 12309648.0000 - fn: 4789.0000 - accuracy: 0.9993 - precision: 0.9948 - recall: 0.9946 - auc: 0.9999 - val_loss: 0.0138 - val_tp: 187595.0000 - val_fp: 883.0000 - val_tn: 2637893.0000 - val_fn: 889.0000 - val_accuracy: 0.9994 - val_precision: 0.9953 - val_recall: 0.9953 - val_auc: 0.9999\n",
            "Epoch 100/100\n",
            "118/118 - 47s - loss: 0.0148 - tp: 874840.0000 - fp: 4553.0000 - tn: 12309693.0000 - fn: 4749.0000 - accuracy: 0.9993 - precision: 0.9948 - recall: 0.9946 - auc: 0.9999 - val_loss: 0.0136 - val_tp: 187594.0000 - val_fp: 885.0000 - val_tn: 2637891.0000 - val_fn: 890.0000 - val_accuracy: 0.9994 - val_precision: 0.9953 - val_recall: 0.9953 - val_auc: 0.9999\n",
            "train_time: 4795.223598718643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT635dAfpOVN"
      },
      "source": [
        "## Get the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSo0TpT5Z04X",
        "outputId": "e287f0fb-905a-4513-fe1f-4c317caff4af"
      },
      "source": [
        "# evaluate model\n",
        "accuracy = model.evaluate(X_test_r, y_test, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 [==============================] - 4s 147ms/step - loss: 0.0137 - tp: 187569.0000 - fp: 900.0000 - tn: 2637862.0000 - fn: 914.0000 - accuracy: 0.9994 - precision: 0.9952 - recall: 0.9952 - auc: 0.9999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGNmOrhH1CL"
      },
      "source": [
        "y_pred=model.predict(X_test_r)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltyd2KVLIBCK",
        "outputId": "45df362c-7d1e-4b61-e024-ab433a076961"
      },
      "source": [
        "display_metrics(y_test_ada, np.argmax(y_pred, axis = 1), labels_d)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 1.00\n",
            "\n",
            "Micro Precision: 1.00\n",
            "Micro Recall: 1.00\n",
            "Micro F1-score: 1.00\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.85\n",
            "Macro Recall: 0.90\n",
            "Macro F1-score: 0.86\n",
            "\n",
            "Weighted Precision: 1.00\n",
            "Weighted Recall: 1.00\n",
            "Weighted F1-score: 1.00\n",
            "\n",
            "Classification Report\n",
            "\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       1.00      0.99      1.00    105019\n",
            "                       Bot       0.93      0.97      0.95       280\n",
            "                      DDoS       1.00      1.00      1.00     19271\n",
            "             DoS GoldenEye       0.99      1.00      1.00      1542\n",
            "                  DoS Hulk       1.00      1.00      1.00     34547\n",
            "          DoS Slowhttptest       1.00      0.99      1.00       828\n",
            "             DoS slowloris       0.99      0.99      0.99       834\n",
            "               FTP-Patator       1.00      1.00      1.00      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.33      1.00      0.50         1\n",
            "                  PortScan       0.98      0.99      0.98     23846\n",
            "               SSH-Patator       0.99      1.00      0.99       826\n",
            "  Web Attack � Brute Force       0.83      0.82      0.82       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.71      0.76      0.74        93\n",
            "\n",
            "                  accuracy                           1.00    188483\n",
            "                 macro avg       0.85      0.90      0.86    188483\n",
            "              weighted avg       1.00      1.00      1.00    188483\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbhp6oW_Z04X"
      },
      "source": [
        ""
      ]
    }
  ]
}