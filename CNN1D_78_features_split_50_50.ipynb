{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " CNN1D_78_features_split_50_50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwangliberty/AIoTDesign-Frontend/blob/master/CNN1D_78_features_split_50_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq5p9swvZ04G"
      },
      "source": [
        "# Intrusion Detection using CNN1N for CICIDS 2017 Data Set with 78 Features "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXg4HMXOZ04H"
      },
      "source": [
        "We use the pre-processing dataset from mlp4nids (Multi-layer perceptron for network intrusion detection) https://github.com/ArnaudRosay/mlp4nids. The train, test and validation sets have connection-based new features. The data splitting rate is 50:25:25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SOKT1sRZ04I"
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH9hOnpmzv6-"
      },
      "source": [
        "def display_metrics(y_test, y_pred, label_names):\n",
        "  print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "  print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
        "  print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
        "  print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
        "\n",
        "  print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
        "  print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
        "  print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
        "\n",
        "  print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
        "  print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
        "  print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
        "\n",
        "  print('\\nClassification Report\\n')\n",
        "  print(classification_report(y_test, y_pred, target_names=label_names))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCwZZFMTZ04J"
      },
      "source": [
        "def display_all(df):\n",
        "    with pd.option_context(\"display.max_rows\", 100, \"display.max_columns\", 100): \n",
        "        print(df)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceDogrv3Z04J"
      },
      "source": [
        "def make_value2index(attacks):\n",
        "    #make dictionary\n",
        "    attacks = sorted(attacks)\n",
        "    d = {}\n",
        "    counter=0\n",
        "    for attack in attacks:\n",
        "        d[attack] = counter\n",
        "        counter+=1\n",
        "    return d"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht3b8hIQZ04K"
      },
      "source": [
        "# chganges label from string to integer/index\n",
        "def encode_label(Y_str):\n",
        "    labels_d = make_value2index(np.unique(Y_str))\n",
        "    Y = [labels_d[y_str] for y_str  in Y_str]\n",
        "    Y = np.array(Y)\n",
        "    return np.array(Y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMisXWZWZ04K"
      },
      "source": [
        "## Step 1. Loading csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwxZ7DrXZ04L"
      },
      "source": [
        "# All columns\n",
        "col_names = np.array(['dst sport count', 'src dport count', 'dst src count', 'dport count', 'sport count', 'dst host count','src host count','Source Port', 'Destination Port',\n",
        "                      'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\n",
        "                      'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
        "                      'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
        "                      'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total',\n",
        "                      'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
        "                      'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\n",
        "                      'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\n",
        "                      'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
        "                      'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
        "                      'Avg Bwd Segment Size','Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
        "                      'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\n",
        "                      'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
        "                      'Idle Std', 'Idle Max', 'Idle Min', 'Label'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoCkMRAcaIA6"
      },
      "source": [
        "### Option 1. Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uaw_A5kaHSj",
        "outputId": "953ea303-7bc2-4843-e865-f4f238e4a945"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qUtBnilZ04M"
      },
      "source": [
        "# load three csv files generated by mlp4nids (Multi-layer perceptron for network intrusion detection )\n",
        "# first load the train set\n",
        "df_train = pd.read_csv('/content/drive/My Drive/CICIDS2017/train_set_ext78.csv',names=col_names, skiprows=1)  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBn8DsjhX_U4",
        "outputId": "16442aad-4d1a-4312-e161-6711b434b5d2"
      },
      "source": [
        "print('Train set size: ', df_train.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set size:  (556548, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXYvaCAjZ04P",
        "outputId": "368c06cb-54ce-4631-bce7-93165ba25525"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/CICIDS2017/test_set_ext78.csv',names=col_names, skiprows=1)  \n",
        "print('Test set size: ', df_test.shape)\n",
        "\n",
        "df_val = pd.read_csv('/content/drive/My Drive/CICIDS2017/crossval_set_ext78.csv',names=col_names, skiprows=1)  \n",
        "print('Validation set size: ', df_val.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set size:  (278271, 79)\n",
            "Validation set size:  (278271, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cbbuInpXhvz"
      },
      "source": [
        "### Option 2. Load from local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLcmd-A8Xhv0"
      },
      "source": [
        "dataroot = '../data/cicids2017clean/train_set_ext.csv'\n",
        "df_train = pd.read_csv(dataroot, names=col_names, skiprows=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9oqAbFyXhv0"
      },
      "source": [
        "dataroot = '../data/cicids2017clean/crossval_set_ext.csv'\n",
        "df_val = pd.read_csv(dataroot, names=col_names, skiprows=1) \n",
        "dataroot = '../data/cicids2017clean/test_set_ext.csv'\n",
        "df_test = pd.read_csv(dataroot, names=col_names, skiprows=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls46tMA9Xhv0"
      },
      "source": [
        "## Step 2. Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "q-oBvrtQXhv0",
        "outputId": "29dcc12e-7d4e-41b7-df82-b60ebbcbaf92"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>480307</th>\n",
              "      <td>1</td>\n",
              "      <td>36</td>\n",
              "      <td>36</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>81</td>\n",
              "      <td>56014</td>\n",
              "      <td>53</td>\n",
              "      <td>17</td>\n",
              "      <td>60843</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>226</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>113</td>\n",
              "      <td>113</td>\n",
              "      <td>113.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5259.438226</td>\n",
              "      <td>65.742978</td>\n",
              "      <td>20281.0</td>\n",
              "      <td>3.512166e+04</td>\n",
              "      <td>60836</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>32.871489</td>\n",
              "      <td>32.871489</td>\n",
              "      <td>47</td>\n",
              "      <td>113</td>\n",
              "      <td>73.400000</td>\n",
              "      <td>36.149689</td>\n",
              "      <td>1306.800000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>91.75</td>\n",
              "      <td>47.0</td>\n",
              "      <td>113.0</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>2</td>\n",
              "      <td>226</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2273904</th>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>96</td>\n",
              "      <td>33606</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>251</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DoS Hulk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2173332</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>54288</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>181818.181800</td>\n",
              "      <td>45454.545450</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>44</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>22727.272730</td>\n",
              "      <td>22727.272730</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>4.618802</td>\n",
              "      <td>21.333333</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>229</td>\n",
              "      <td>235</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DoS slowloris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2267207</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>50768</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>1000000.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>251</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DoS Hulk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90817</th>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>62083</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>3795333</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.323556</td>\n",
              "      <td>1.053926</td>\n",
              "      <td>1265111.0</td>\n",
              "      <td>2.190632e+06</td>\n",
              "      <td>3794635</td>\n",
              "      <td>348</td>\n",
              "      <td>3795333</td>\n",
              "      <td>1265111.0</td>\n",
              "      <td>2190632.043</td>\n",
              "      <td>3794635</td>\n",
              "      <td>348</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>1.053926</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.50</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>256</td>\n",
              "      <td>-1</td>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>DDoS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         dst sport count  src dport count  ...  Idle Min          Label\n",
              "480307                 1               36  ...         0         BENIGN\n",
              "2273904                1               96  ...         0       DoS Hulk\n",
              "2173332                1                1  ...         0  DoS slowloris\n",
              "2267207                1              100  ...         0       DoS Hulk\n",
              "90817                  1              100  ...         0           DDoS\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miDxhmNyZ04N"
      },
      "source": [
        "Count the number of attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpKy7b9fZ04O",
        "scrolled": true,
        "outputId": "63053c29-9b14-4ee1-9fb9-dfcf0d5159d2"
      },
      "source": [
        "df_train['Label'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        278274\n",
              "DoS Hulk                      115062\n",
              "PortScan                       79402\n",
              "DDoS                           64012\n",
              "DoS GoldenEye                   5146\n",
              "FTP-Patator                     3967\n",
              "SSH-Patator                     2948\n",
              "DoS slowloris                   2898\n",
              "DoS Slowhttptest                2749\n",
              "Bot                              978\n",
              "Web Attack � Brute Force         753\n",
              "Web Attack � XSS                 326\n",
              "Infiltration                      18\n",
              "Web Attack � Sql Injection        10\n",
              "Heartbleed                         5\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "TP5wXlnNtCXd",
        "outputId": "e8181bd5-0791-4b46-c44e-64678b938af3"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>...</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>count</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>556548.000000</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "      <td>5.565480e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>mean</td>\n",
              "      <td>63.986114</td>\n",
              "      <td>71.911368</td>\n",
              "      <td>41059.562686</td>\n",
              "      <td>7182.692884</td>\n",
              "      <td>8.358620</td>\n",
              "      <td>2.159931e+07</td>\n",
              "      <td>7.561386</td>\n",
              "      <td>8.259167</td>\n",
              "      <td>6.822941e+02</td>\n",
              "      <td>1.265955e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>4.883591</td>\n",
              "      <td>25.540766</td>\n",
              "      <td>1.082361e+05</td>\n",
              "      <td>3.242660e+04</td>\n",
              "      <td>1.571849e+05</td>\n",
              "      <td>8.865328e+04</td>\n",
              "      <td>1.640646e+07</td>\n",
              "      <td>1.206008e+06</td>\n",
              "      <td>1.730500e+07</td>\n",
              "      <td>1.552621e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>std</td>\n",
              "      <td>40.704131</td>\n",
              "      <td>36.408934</td>\n",
              "      <td>20762.257722</td>\n",
              "      <td>16999.053361</td>\n",
              "      <td>4.518634</td>\n",
              "      <td>3.824665e+07</td>\n",
              "      <td>641.917381</td>\n",
              "      <td>865.356666</td>\n",
              "      <td>8.207379e+03</td>\n",
              "      <td>1.934124e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>612.739185</td>\n",
              "      <td>6.418384</td>\n",
              "      <td>7.164700e+05</td>\n",
              "      <td>3.567006e+05</td>\n",
              "      <td>9.588739e+05</td>\n",
              "      <td>6.668469e+05</td>\n",
              "      <td>3.283531e+07</td>\n",
              "      <td>7.260774e+06</td>\n",
              "      <td>3.390042e+07</td>\n",
              "      <td>3.259279e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>min</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25%</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>33830.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.120000e+02</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50%</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>49512.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.867450e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.600000e+01</td>\n",
              "      <td>1.120000e+02</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75%</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>57000.000000</td>\n",
              "      <td>1034.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.104332e+07</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.380000e+02</td>\n",
              "      <td>1.159500e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>9.530000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.530000e+02</td>\n",
              "      <td>8.820000e+02</td>\n",
              "      <td>9.553880e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.803576e+06</td>\n",
              "      <td>7.462839e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>max</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65532.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.199999e+08</td>\n",
              "      <td>207964.000000</td>\n",
              "      <td>284602.000000</td>\n",
              "      <td>2.866110e+06</td>\n",
              "      <td>6.270000e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>198636.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>1.100000e+08</td>\n",
              "      <td>7.050000e+07</td>\n",
              "      <td>1.100000e+08</td>\n",
              "      <td>1.100000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>7.420000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 73 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       dst host count  src host count    Source Port  Destination Port  \\\n",
              "count   556548.000000   556548.000000  556548.000000     556548.000000   \n",
              "mean        63.986114       71.911368   41059.562686       7182.692884   \n",
              "std         40.704131       36.408934   20762.257722      16999.053361   \n",
              "min          1.000000        1.000000       0.000000          0.000000   \n",
              "25%         19.000000       42.000000   33830.000000         80.000000   \n",
              "50%         96.000000       97.000000   49512.000000         80.000000   \n",
              "75%        100.000000      100.000000   57000.000000       1034.000000   \n",
              "max        100.000000      100.000000   65535.000000      65532.000000   \n",
              "\n",
              "            Protocol  Flow Duration  Total Fwd Packets  \\\n",
              "count  556548.000000   5.565480e+05      556548.000000   \n",
              "mean        8.358620   2.159931e+07           7.561386   \n",
              "std         4.518634   3.824665e+07         641.917381   \n",
              "min         0.000000  -1.300000e+01           1.000000   \n",
              "25%         6.000000   1.120000e+02           1.000000   \n",
              "50%         6.000000   6.867450e+04           2.000000   \n",
              "75%         6.000000   1.104332e+07           6.000000   \n",
              "max        17.000000   1.199999e+08      207964.000000   \n",
              "\n",
              "       Total Backward Packets  Total Length of Fwd Packets  \\\n",
              "count           556548.000000                 5.565480e+05   \n",
              "mean                 8.259167                 6.822941e+02   \n",
              "std                865.356666                 8.207379e+03   \n",
              "min                  0.000000                 0.000000e+00   \n",
              "25%                  1.000000                 6.000000e+00   \n",
              "50%                  2.000000                 5.600000e+01   \n",
              "75%                  6.000000                 3.380000e+02   \n",
              "max             284602.000000                 2.866110e+06   \n",
              "\n",
              "       Total Length of Bwd Packets  ...  act_data_pkt_fwd  \\\n",
              "count                 5.565480e+05  ...     556548.000000   \n",
              "mean                  1.265955e+04  ...          4.883591   \n",
              "std                   1.934124e+06  ...        612.739185   \n",
              "min                   0.000000e+00  ...          0.000000   \n",
              "25%                   6.000000e+00  ...          0.000000   \n",
              "50%                   1.120000e+02  ...          1.000000   \n",
              "75%                   1.159500e+04  ...          2.000000   \n",
              "max                   6.270000e+08  ...     198636.000000   \n",
              "\n",
              "       min_seg_size_forward   Active Mean    Active Std    Active Max  \\\n",
              "count         556548.000000  5.565480e+05  5.565480e+05  5.565480e+05   \n",
              "mean              25.540766  1.082361e+05  3.242660e+04  1.571849e+05   \n",
              "std                6.418384  7.164700e+05  3.567006e+05  9.588739e+05   \n",
              "min                0.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "25%               20.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "50%               20.000000  0.000000e+00  0.000000e+00  0.000000e+00   \n",
              "75%               32.000000  9.530000e+02  0.000000e+00  9.530000e+02   \n",
              "max               60.000000  1.100000e+08  7.050000e+07  1.100000e+08   \n",
              "\n",
              "         Active Min     Idle Mean      Idle Std      Idle Max      Idle Min  \n",
              "count  5.565480e+05  5.565480e+05  5.565480e+05  5.565480e+05  5.565480e+05  \n",
              "mean   8.865328e+04  1.640646e+07  1.206008e+06  1.730500e+07  1.552621e+07  \n",
              "std    6.668469e+05  3.283531e+07  7.260774e+06  3.390042e+07  3.259279e+07  \n",
              "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
              "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
              "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
              "75%    8.820000e+02  9.553880e+06  0.000000e+00  9.803576e+06  7.462839e+06  \n",
              "max    1.100000e+08  1.200000e+08  7.420000e+07  1.200000e+08  1.200000e+08  \n",
              "\n",
              "[8 rows x 73 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2X3KG4zZ04P"
      },
      "source": [
        "Read test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5hWm9Q-Z04Q",
        "outputId": "b3e5fc1b-1860-45ea-c804-97b540553d1b"
      },
      "source": [
        "print('Test set: ')\n",
        "df_test['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        139135\n",
              "DoS Hulk                       57531\n",
              "PortScan                       39701\n",
              "DDoS                           32006\n",
              "DoS GoldenEye                   2573\n",
              "FTP-Patator                     1983\n",
              "SSH-Patator                     1474\n",
              "DoS slowloris                   1449\n",
              "DoS Slowhttptest                1374\n",
              "Bot                              489\n",
              "Web Attack � Brute Force         376\n",
              "Web Attack � XSS                 163\n",
              "Infiltration                       9\n",
              "Web Attack � Sql Injection         5\n",
              "Heartbleed                         3\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "i5H5oCfvtMm-",
        "outputId": "12508bc0-27a7-4644-bf98-47b34e526bd5"
      },
      "source": [
        "df_test.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>45364.905750</td>\n",
              "      <td>5840.633640</td>\n",
              "      <td>7.480749</td>\n",
              "      <td>2.018494e+07</td>\n",
              "      <td>13.425781</td>\n",
              "      <td>15.071391</td>\n",
              "      <td>5.018160e+02</td>\n",
              "      <td>2.777075e+04</td>\n",
              "      <td>185.079276</td>\n",
              "      <td>9.858127</td>\n",
              "      <td>42.498337</td>\n",
              "      <td>62.543191</td>\n",
              "      <td>1437.918892</td>\n",
              "      <td>16.702825</td>\n",
              "      <td>472.989076</td>\n",
              "      <td>598.916973</td>\n",
              "      <td>1.319690e+06</td>\n",
              "      <td>9.153090e+04</td>\n",
              "      <td>2.091054e+06</td>\n",
              "      <td>4.928267e+06</td>\n",
              "      <td>1.541155e+07</td>\n",
              "      <td>2.119001e+05</td>\n",
              "      <td>1.981716e+07</td>\n",
              "      <td>4.173283e+06</td>\n",
              "      <td>5.569102e+06</td>\n",
              "      <td>1.522487e+07</td>\n",
              "      <td>1.619357e+06</td>\n",
              "      <td>1.058695e+07</td>\n",
              "      <td>2.418274e+06</td>\n",
              "      <td>2.028897e+06</td>\n",
              "      <td>6.305801e+06</td>\n",
              "      <td>1.360565e+06</td>\n",
              "      <td>0.055008</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.183946e+02</td>\n",
              "      <td>3.384120e+02</td>\n",
              "      <td>8.541160e+04</td>\n",
              "      <td>6.162424e+03</td>\n",
              "      <td>7.706957</td>\n",
              "      <td>1472.163140</td>\n",
              "      <td>241.332367</td>\n",
              "      <td>466.822599</td>\n",
              "      <td>8.970325e+05</td>\n",
              "      <td>0.058659</td>\n",
              "      <td>0.055008</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.423420</td>\n",
              "      <td>0.383936</td>\n",
              "      <td>0.024473</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.515485</td>\n",
              "      <td>266.229446</td>\n",
              "      <td>42.498337</td>\n",
              "      <td>472.989076</td>\n",
              "      <td>13.425781</td>\n",
              "      <td>5.018160e+02</td>\n",
              "      <td>15.071391</td>\n",
              "      <td>2.777075e+04</td>\n",
              "      <td>10570.921080</td>\n",
              "      <td>1731.267470</td>\n",
              "      <td>10.076965</td>\n",
              "      <td>26.450577</td>\n",
              "      <td>9.950258e+04</td>\n",
              "      <td>4.357601e+04</td>\n",
              "      <td>1.635863e+05</td>\n",
              "      <td>7.265777e+04</td>\n",
              "      <td>1.389976e+07</td>\n",
              "      <td>9.310342e+05</td>\n",
              "      <td>1.461183e+07</td>\n",
              "      <td>1.319746e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>17986.051427</td>\n",
              "      <td>15731.041102</td>\n",
              "      <td>3.759347</td>\n",
              "      <td>3.747672e+07</td>\n",
              "      <td>1208.778536</td>\n",
              "      <td>1591.037162</td>\n",
              "      <td>7.898116e+03</td>\n",
              "      <td>3.604963e+06</td>\n",
              "      <td>392.614677</td>\n",
              "      <td>61.235977</td>\n",
              "      <td>99.578231</td>\n",
              "      <td>132.298567</td>\n",
              "      <td>2586.487090</td>\n",
              "      <td>46.983524</td>\n",
              "      <td>797.823718</td>\n",
              "      <td>1144.520735</td>\n",
              "      <td>2.365354e+07</td>\n",
              "      <td>2.939540e+05</td>\n",
              "      <td>5.446991e+06</td>\n",
              "      <td>1.046406e+07</td>\n",
              "      <td>3.156539e+07</td>\n",
              "      <td>3.035605e+06</td>\n",
              "      <td>3.741861e+07</td>\n",
              "      <td>1.178049e+07</td>\n",
              "      <td>1.262896e+07</td>\n",
              "      <td>3.161073e+07</td>\n",
              "      <td>1.066533e+07</td>\n",
              "      <td>2.913323e+07</td>\n",
              "      <td>1.045182e+07</td>\n",
              "      <td>7.731527e+06</td>\n",
              "      <td>2.046630e+07</td>\n",
              "      <td>9.753000e+06</td>\n",
              "      <td>0.227996</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.524765e+04</td>\n",
              "      <td>3.182466e+04</td>\n",
              "      <td>2.889885e+05</td>\n",
              "      <td>3.511581e+04</td>\n",
              "      <td>17.933308</td>\n",
              "      <td>2584.335069</td>\n",
              "      <td>383.113699</td>\n",
              "      <td>824.111902</td>\n",
              "      <td>2.290032e+06</td>\n",
              "      <td>0.234986</td>\n",
              "      <td>0.227996</td>\n",
              "      <td>0.008891</td>\n",
              "      <td>0.494102</td>\n",
              "      <td>0.486344</td>\n",
              "      <td>0.154512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008891</td>\n",
              "      <td>0.551013</td>\n",
              "      <td>420.649091</td>\n",
              "      <td>99.578231</td>\n",
              "      <td>797.823718</td>\n",
              "      <td>1208.778536</td>\n",
              "      <td>7.898116e+03</td>\n",
              "      <td>1591.037162</td>\n",
              "      <td>3.604963e+06</td>\n",
              "      <td>17760.016938</td>\n",
              "      <td>7434.284715</td>\n",
              "      <td>1153.408495</td>\n",
              "      <td>6.864564</td>\n",
              "      <td>7.423962e+05</td>\n",
              "      <td>4.382250e+05</td>\n",
              "      <td>1.087195e+06</td>\n",
              "      <td>6.664087e+05</td>\n",
              "      <td>3.055265e+07</td>\n",
              "      <td>6.557272e+06</td>\n",
              "      <td>3.158812e+07</td>\n",
              "      <td>3.024680e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+07</td>\n",
              "      <td>-2.000000e+06</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>39814.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.000000e+01</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.187093e+01</td>\n",
              "      <td>7.809336e-01</td>\n",
              "      <td>7.100000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.800000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>5.793178e-01</td>\n",
              "      <td>8.503405e-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.309401</td>\n",
              "      <td>5.333333e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>251.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>50634.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.538300e+04</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.700000e+01</td>\n",
              "      <td>6.100000e+01</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.900480</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.179980e+03</td>\n",
              "      <td>6.026881e+01</td>\n",
              "      <td>2.694690e+04</td>\n",
              "      <td>1.009884e+04</td>\n",
              "      <td>5.489350e+04</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>7.013000e+03</td>\n",
              "      <td>3.503500e+03</td>\n",
              "      <td>3.351686e+02</td>\n",
              "      <td>6.663000e+03</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.200000e+01</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>3.205693e+01</td>\n",
              "      <td>7.639334e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>18.622567</td>\n",
              "      <td>3.468000e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>59.750000</td>\n",
              "      <td>10.900480</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.700000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.100000e+01</td>\n",
              "      <td>304.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>58142.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.936814e+06</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.560000e+02</td>\n",
              "      <td>4.532000e+03</td>\n",
              "      <td>321.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>54.333333</td>\n",
              "      <td>111.538871</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>542.958333</td>\n",
              "      <td>663.236171</td>\n",
              "      <td>7.400125e+04</td>\n",
              "      <td>2.631579e+04</td>\n",
              "      <td>1.557685e+06</td>\n",
              "      <td>2.991012e+06</td>\n",
              "      <td>8.012042e+06</td>\n",
              "      <td>7.200000e+01</td>\n",
              "      <td>8.004861e+06</td>\n",
              "      <td>2.007233e+06</td>\n",
              "      <td>2.359285e+06</td>\n",
              "      <td>6.955281e+06</td>\n",
              "      <td>1.450000e+02</td>\n",
              "      <td>2.174638e+05</td>\n",
              "      <td>4.452351e+04</td>\n",
              "      <td>5.501563e+04</td>\n",
              "      <td>1.481998e+05</td>\n",
              "      <td>4.500000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.720000e+02</td>\n",
              "      <td>1.520000e+02</td>\n",
              "      <td>1.388889e+04</td>\n",
              "      <td>6.120382e+01</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>298.055556</td>\n",
              "      <td>533.916876</td>\n",
              "      <td>2.850672e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>315.055556</td>\n",
              "      <td>54.333333</td>\n",
              "      <td>542.958333</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.560000e+02</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.532000e+03</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>5.000000e+00</td>\n",
              "      <td>5.853280e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.860882e+06</td>\n",
              "      <td>5.499876e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>65534.000000</td>\n",
              "      <td>65534.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.199999e+08</td>\n",
              "      <td>219759.000000</td>\n",
              "      <td>291922.000000</td>\n",
              "      <td>1.323378e+06</td>\n",
              "      <td>6.554530e+08</td>\n",
              "      <td>23360.000000</td>\n",
              "      <td>2065.000000</td>\n",
              "      <td>4638.923469</td>\n",
              "      <td>7125.596846</td>\n",
              "      <td>17376.000000</td>\n",
              "      <td>2146.000000</td>\n",
              "      <td>3884.924556</td>\n",
              "      <td>6715.738331</td>\n",
              "      <td>2.071000e+09</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>1.143926e+08</td>\n",
              "      <td>8.478172e+07</td>\n",
              "      <td>1.199946e+08</td>\n",
              "      <td>1.143926e+08</td>\n",
              "      <td>1.199998e+08</td>\n",
              "      <td>1.199610e+08</td>\n",
              "      <td>8.460293e+07</td>\n",
              "      <td>1.199948e+08</td>\n",
              "      <td>1.199610e+08</td>\n",
              "      <td>1.199996e+08</td>\n",
              "      <td>1.199741e+08</td>\n",
              "      <td>8.441801e+07</td>\n",
              "      <td>1.199741e+08</td>\n",
              "      <td>1.199741e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.644908e+06</td>\n",
              "      <td>5.838440e+06</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>389.000000</td>\n",
              "      <td>23360.000000</td>\n",
              "      <td>1877.272727</td>\n",
              "      <td>4414.547151</td>\n",
              "      <td>1.948823e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2068.000000</td>\n",
              "      <td>4638.923469</td>\n",
              "      <td>3884.924556</td>\n",
              "      <td>219759.000000</td>\n",
              "      <td>1.323378e+06</td>\n",
              "      <td>291922.000000</td>\n",
              "      <td>6.554530e+08</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>213557.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>1.016597e+08</td>\n",
              "      <td>6.434950e+07</td>\n",
              "      <td>1.016597e+08</td>\n",
              "      <td>1.016597e+08</td>\n",
              "      <td>1.199946e+08</td>\n",
              "      <td>7.353239e+07</td>\n",
              "      <td>1.199946e+08</td>\n",
              "      <td>1.199946e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Source Port  Destination Port  ...      Idle Max      Idle Min\n",
              "count  278270.000000     278270.000000  ...  2.782700e+05  2.782700e+05\n",
              "mean    45364.905750       5840.633640  ...  1.461183e+07  1.319746e+07\n",
              "std     17986.051427      15731.041102  ...  3.158812e+07  3.024680e+07\n",
              "min         0.000000          0.000000  ...  0.000000e+00  0.000000e+00\n",
              "25%     39814.000000         80.000000  ...  0.000000e+00  0.000000e+00\n",
              "50%     50634.000000         80.000000  ...  0.000000e+00  0.000000e+00\n",
              "75%     58142.000000        443.000000  ...  5.860882e+06  5.499876e+06\n",
              "max     65534.000000      65534.000000  ...  1.199946e+08  1.199946e+08\n",
              "\n",
              "[8 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0-lHNicZ04Q",
        "outputId": "04ed9641-b558-40d6-be3d-aa6715a78e50"
      },
      "source": [
        "print('Validation set: ')\n",
        "df_val['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        139135\n",
              "DoS Hulk                       57531\n",
              "PortScan                       39701\n",
              "DDoS                           32006\n",
              "DoS GoldenEye                   2573\n",
              "FTP-Patator                     1983\n",
              "SSH-Patator                     1474\n",
              "DoS slowloris                   1449\n",
              "DoS Slowhttptest                1374\n",
              "Bot                              489\n",
              "Web Attack � Brute Force         376\n",
              "Web Attack � XSS                 163\n",
              "Infiltration                       9\n",
              "Web Attack � Sql Injection         5\n",
              "Heartbleed                         3\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "jdr4JCpftQvk",
        "outputId": "b9e26e02-ecf1-487b-d241-8ebd703c7c31"
      },
      "source": [
        "df_val.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.0</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>278270.000000</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "      <td>2.782700e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>42404.657796</td>\n",
              "      <td>4584.284134</td>\n",
              "      <td>8.772361</td>\n",
              "      <td>2.267720e+07</td>\n",
              "      <td>5.697168</td>\n",
              "      <td>5.401071</td>\n",
              "      <td>363.328418</td>\n",
              "      <td>6.993901e+03</td>\n",
              "      <td>146.271053</td>\n",
              "      <td>12.216883</td>\n",
              "      <td>37.118951</td>\n",
              "      <td>48.506259</td>\n",
              "      <td>1644.006185</td>\n",
              "      <td>31.044985</td>\n",
              "      <td>545.020851</td>\n",
              "      <td>677.301293</td>\n",
              "      <td>1.026168e+06</td>\n",
              "      <td>7.647836e+04</td>\n",
              "      <td>2.035292e+06</td>\n",
              "      <td>5.660128e+06</td>\n",
              "      <td>1.867983e+07</td>\n",
              "      <td>1.176209e+05</td>\n",
              "      <td>2.242947e+07</td>\n",
              "      <td>4.097971e+06</td>\n",
              "      <td>7.275898e+06</td>\n",
              "      <td>1.857577e+07</td>\n",
              "      <td>8.532117e+05</td>\n",
              "      <td>1.033244e+07</td>\n",
              "      <td>2.108780e+06</td>\n",
              "      <td>2.497470e+06</td>\n",
              "      <td>6.852268e+06</td>\n",
              "      <td>8.777106e+05</td>\n",
              "      <td>0.032285</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.853584e+04</td>\n",
              "      <td>-6.184786e+03</td>\n",
              "      <td>6.922916e+04</td>\n",
              "      <td>7.292921e+03</td>\n",
              "      <td>11.819104</td>\n",
              "      <td>1667.675854</td>\n",
              "      <td>265.849753</td>\n",
              "      <td>521.021331</td>\n",
              "      <td>1.032910e+06</td>\n",
              "      <td>0.063622</td>\n",
              "      <td>0.032285</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.325008</td>\n",
              "      <td>0.360617</td>\n",
              "      <td>0.052697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>0.635189</td>\n",
              "      <td>293.529747</td>\n",
              "      <td>37.118951</td>\n",
              "      <td>545.020851</td>\n",
              "      <td>5.697168</td>\n",
              "      <td>363.328418</td>\n",
              "      <td>5.401071</td>\n",
              "      <td>6.994360e+03</td>\n",
              "      <td>8300.353962</td>\n",
              "      <td>1196.878449</td>\n",
              "      <td>2.850606</td>\n",
              "      <td>-6.302925e+03</td>\n",
              "      <td>1.011663e+05</td>\n",
              "      <td>3.866528e+04</td>\n",
              "      <td>1.584032e+05</td>\n",
              "      <td>7.772919e+04</td>\n",
              "      <td>1.758377e+07</td>\n",
              "      <td>9.337417e+05</td>\n",
              "      <td>1.829755e+07</td>\n",
              "      <td>1.689405e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>18921.321337</td>\n",
              "      <td>13260.493797</td>\n",
              "      <td>4.780477</td>\n",
              "      <td>3.957518e+07</td>\n",
              "      <td>67.142466</td>\n",
              "      <td>87.166823</td>\n",
              "      <td>3246.913595</td>\n",
              "      <td>2.585565e+05</td>\n",
              "      <td>380.776699</td>\n",
              "      <td>29.589643</td>\n",
              "      <td>80.881268</td>\n",
              "      <td>118.838474</td>\n",
              "      <td>2798.340693</td>\n",
              "      <td>63.404307</td>\n",
              "      <td>851.938455</td>\n",
              "      <td>1229.566919</td>\n",
              "      <td>1.848896e+07</td>\n",
              "      <td>2.733855e+05</td>\n",
              "      <td>4.353752e+06</td>\n",
              "      <td>1.081619e+07</td>\n",
              "      <td>3.532609e+07</td>\n",
              "      <td>1.940212e+06</td>\n",
              "      <td>3.955407e+07</td>\n",
              "      <td>9.992215e+06</td>\n",
              "      <td>1.450108e+07</td>\n",
              "      <td>3.536583e+07</td>\n",
              "      <td>7.979563e+06</td>\n",
              "      <td>2.928691e+07</td>\n",
              "      <td>9.212534e+06</td>\n",
              "      <td>9.080364e+06</td>\n",
              "      <td>2.268132e+07</td>\n",
              "      <td>8.098570e+06</td>\n",
              "      <td>0.176757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.255039e+06</td>\n",
              "      <td>8.563325e+05</td>\n",
              "      <td>2.681766e+05</td>\n",
              "      <td>3.540818e+04</td>\n",
              "      <td>21.282926</td>\n",
              "      <td>2802.004249</td>\n",
              "      <td>395.033818</td>\n",
              "      <td>872.649085</td>\n",
              "      <td>2.337799e+06</td>\n",
              "      <td>0.244078</td>\n",
              "      <td>0.176757</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.468379</td>\n",
              "      <td>0.480181</td>\n",
              "      <td>0.223428</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010554</td>\n",
              "      <td>0.543604</td>\n",
              "      <td>431.308583</td>\n",
              "      <td>80.881268</td>\n",
              "      <td>851.938455</td>\n",
              "      <td>67.142466</td>\n",
              "      <td>3246.913595</td>\n",
              "      <td>87.166823</td>\n",
              "      <td>2.586082e+05</td>\n",
              "      <td>13668.065695</td>\n",
              "      <td>6710.083319</td>\n",
              "      <td>32.991321</td>\n",
              "      <td>7.286969e+05</td>\n",
              "      <td>8.404515e+05</td>\n",
              "      <td>4.487356e+05</td>\n",
              "      <td>1.167019e+06</td>\n",
              "      <td>7.582087e+05</td>\n",
              "      <td>3.455426e+07</td>\n",
              "      <td>6.638199e+06</td>\n",
              "      <td>3.540421e+07</td>\n",
              "      <td>3.437331e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+07</td>\n",
              "      <td>-2.000000e+06</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.929350e+09</td>\n",
              "      <td>-1.677705e+08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-8.388531e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>35454.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.700000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.197319e+02</td>\n",
              "      <td>6.190867e-01</td>\n",
              "      <td>6.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>8.500000e+01</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>4.824028e-01</td>\n",
              "      <td>6.077324e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.464102</td>\n",
              "      <td>1.200000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>49688.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.852000e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>1.380000e+02</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.111790e+03</td>\n",
              "      <td>7.889413e+01</td>\n",
              "      <td>1.977895e+04</td>\n",
              "      <td>1.062092e+04</td>\n",
              "      <td>4.508800e+04</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>7.600000e+01</td>\n",
              "      <td>6.900000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.400000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.400000e+01</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>3.994567e+01</td>\n",
              "      <td>7.588463e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>59.600000</td>\n",
              "      <td>28.481573</td>\n",
              "      <td>8.112000e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>75.500000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.380000e+02</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>55812.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.181203e+07</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>6.899000e+03</td>\n",
              "      <td>231.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>79.203964</td>\n",
              "      <td>2052.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>702.750000</td>\n",
              "      <td>757.420270</td>\n",
              "      <td>1.224490e+05</td>\n",
              "      <td>2.597403e+04</td>\n",
              "      <td>1.982858e+06</td>\n",
              "      <td>3.728053e+06</td>\n",
              "      <td>9.999176e+06</td>\n",
              "      <td>5.500000e+01</td>\n",
              "      <td>1.070000e+07</td>\n",
              "      <td>2.714097e+06</td>\n",
              "      <td>3.740416e+06</td>\n",
              "      <td>1.000000e+07</td>\n",
              "      <td>4.800000e+01</td>\n",
              "      <td>1.524908e+05</td>\n",
              "      <td>3.187914e+04</td>\n",
              "      <td>5.662772e+04</td>\n",
              "      <td>1.364448e+05</td>\n",
              "      <td>4.600000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.640000e+02</td>\n",
              "      <td>1.320000e+02</td>\n",
              "      <td>1.333333e+04</td>\n",
              "      <td>8.474576e+03</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>2313.000000</td>\n",
              "      <td>384.862121</td>\n",
              "      <td>682.325913</td>\n",
              "      <td>4.655687e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>408.011858</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>702.750000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>317.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.899000e+03</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>6.520000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>6.520000e+02</td>\n",
              "      <td>5.047500e+02</td>\n",
              "      <td>9.604032e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.992129e+06</td>\n",
              "      <td>7.454226e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65389.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>16412.000000</td>\n",
              "      <td>20326.000000</td>\n",
              "      <td>624920.000000</td>\n",
              "      <td>7.490000e+07</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>2325.000000</td>\n",
              "      <td>5177.256410</td>\n",
              "      <td>5199.042702</td>\n",
              "      <td>15928.000000</td>\n",
              "      <td>1983.000000</td>\n",
              "      <td>5800.500000</td>\n",
              "      <td>8194.660487</td>\n",
              "      <td>2.070000e+09</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>8.480000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.190000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.370000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.340000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.335800e+05</td>\n",
              "      <td>6.504400e+05</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1306.000000</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>2265.586207</td>\n",
              "      <td>4731.522394</td>\n",
              "      <td>2.240000e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2328.000000</td>\n",
              "      <td>5177.256410</td>\n",
              "      <td>5800.500000</td>\n",
              "      <td>16412.000000</td>\n",
              "      <td>624920.000000</td>\n",
              "      <td>20326.000000</td>\n",
              "      <td>7.487024e+07</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>6697.000000</td>\n",
              "      <td>5.600000e+01</td>\n",
              "      <td>1.060000e+08</td>\n",
              "      <td>5.040000e+07</td>\n",
              "      <td>1.060000e+08</td>\n",
              "      <td>1.060000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>7.660000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Source Port  Destination Port  ...      Idle Max      Idle Min\n",
              "count  278270.000000     278270.000000  ...  2.782700e+05  2.782700e+05\n",
              "mean    42404.657796       4584.284134  ...  1.829755e+07  1.689405e+07\n",
              "std     18921.321337      13260.493797  ...  3.540421e+07  3.437331e+07\n",
              "min         0.000000          0.000000  ...  0.000000e+00  0.000000e+00\n",
              "25%     35454.000000         53.000000  ...  0.000000e+00  0.000000e+00\n",
              "50%     49688.000000         80.000000  ...  0.000000e+00  0.000000e+00\n",
              "75%     55812.000000        443.000000  ...  9.992129e+06  7.454226e+06\n",
              "max     65535.000000      65389.000000  ...  1.200000e+08  1.200000e+08\n",
              "\n",
              "[8 rows x 71 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0O9ZuKoXhv3"
      },
      "source": [
        "## Step 3. Encode Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwXKhZOjXhv3"
      },
      "source": [
        "Encoding the labels, and generate numpy array. Note that the label has not been encoded as one-hot coding. We will use one-hot code later. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyAnny9yZ04R"
      },
      "source": [
        "### Step 3.1 Encoding train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsR6_hJDZ04R"
      },
      "source": [
        "df_label = df_train['Label']\n",
        "data = df_train.drop(columns=['Label'])\n",
        "Xtrain = data.values\n",
        "y_train = encode_label(df_label.values)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XlV2AK3Z04S"
      },
      "source": [
        "### Step 3.2. Encoding test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVSrGExFZ04S",
        "scrolled": true
      },
      "source": [
        "df_label = df_test['Label']\n",
        "data = df_test.drop(columns=['Label'])\n",
        "Xtest = data.values\n",
        "y_test = encode_label(df_label.values)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO3PgredZ04T"
      },
      "source": [
        "### Step 3.3 Encoding validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ2wDKpZZ04T"
      },
      "source": [
        "df_label = df_val['Label']\n",
        "data = df_val.drop(columns=['Label'])\n",
        "Xval = data.values\n",
        "y_val = encode_label(df_label.values)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viMki-R0Z04Q"
      },
      "source": [
        "## Step 4. Normalization or Standardization\n",
        "\n",
        "The continuous feature values are normalized into the same feature space. This is important when using features that have different measurements, and is a general requirement of many machine learning algorithms. We implement the two methods to see the impact on the final classifications. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ERJidxXhv5"
      },
      "source": [
        "## Option 1. Normalization\n",
        "\n",
        "The values of the datasets are normalized using the Min-Max scaling technique, bringing them all within a range of [0,1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c523vLd-Z04R"
      },
      "source": [
        "### Step 4.1 Normalizing train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5izaj07Z04R"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbYQFmfgZ04S",
        "scrolled": true,
        "outputId": "6de856d7-25cd-4a76-d092-be7170475cff"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.66048676e-01, 5.93603125e-03, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [7.29167620e-01, 1.22077764e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 7.12500000e-01, 7.12500000e-01],\n",
              "       [7.86144808e-01, 6.76005616e-03, 3.52941176e-01, ...,\n",
              "        8.96864890e-03, 4.90833333e-01, 4.83333333e-01],\n",
              "       ...,\n",
              "       [2.53009842e-01, 1.22077764e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [7.85610742e-01, 8.08765183e-04, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [8.26276036e-01, 1.22077764e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ5x1QxAXhv5"
      },
      "source": [
        "### Step 4.2. Normalizing validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_BpWSsXhv6",
        "outputId": "90111a78-a086-461d-a4c4-0979e500e1f8"
      },
      "source": [
        "X_val = scaler.fit_transform(Xval)\n",
        "X_val"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.37994965e-01, 1.22344737e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [8.41290913e-01, 6.12488339e-02, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [2.87327382e-02, 6.77483980e-03, 3.52941176e-01, ...,\n",
              "        5.68691207e-05, 8.33333333e-02, 8.32947583e-02],\n",
              "       ...,\n",
              "       [9.30510414e-01, 8.10533882e-04, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [6.50492103e-01, 8.68494701e-02, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [4.24353399e-01, 1.22344737e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TItkmTF1Z04S"
      },
      "source": [
        "### Step 4.3. Normalizing test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXmp2w2bZ04T",
        "outputId": "e8c141dc-efba-4c1c-d4ec-7d451e0de593"
      },
      "source": [
        "X_test = scaler.fit_transform(Xtest)\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.45487838e-01, 9.66383862e-01, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [9.17142247e-01, 1.22074038e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [7.92001099e-01, 7.97448653e-02, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       ...,\n",
              "       [9.04507584e-01, 1.22074038e-03, 3.52941176e-01, ...,\n",
              "        0.00000000e+00, 8.33370661e-01, 8.33370661e-01],\n",
              "       [9.22345653e-01, 8.08740501e-04, 1.00000000e+00, ...,\n",
              "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
              "       [5.45030061e-01, 6.75984985e-03, 3.52941176e-01, ...,\n",
              "        5.01804492e-03, 4.88761059e-01, 4.84412289e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge2XVkhTXhv6"
      },
      "source": [
        "## Option 2. Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu459dh3Xhv7"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJud1h5Xhv7",
        "outputId": "a1232852-f527-4cab-df11-79c122eb33ab"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_val = scaler.fit_transform(Xval)\n",
        "X_test = scaler.fit_transform(Xtest)\n",
        "\n",
        "X_train"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.46360917, -0.21367668, -0.60970034, ..., -0.16609924,\n",
              "        -0.51046627, -0.47636976],\n",
              "       [-0.46360917,  1.19349981,  0.79867464, ..., -0.16609924,\n",
              "        -0.51046627, -0.47636976],\n",
              "       [-0.46360917, -1.03452964, -1.43125242, ..., -0.16609924,\n",
              "        -0.51046627, -0.47636976],\n",
              "       ...,\n",
              "       [-0.32230411, -1.03452964, -1.31388783, ..., -0.16609924,\n",
              "        -0.51046627, -0.47636976],\n",
              "       [-0.46360917, -0.82345316, -1.21999617, ..., -0.16609924,\n",
              "        -0.51046627, -0.47636976],\n",
              "       [-0.46360917, -0.28403551, -0.68011909, ..., -0.16609924,\n",
              "        -0.51046627, -0.47636976]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reoNDQZhZ04T"
      },
      "source": [
        "## Step 5 One-hot encoding for labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So8gvIF8Z04T"
      },
      "source": [
        "y_train, y_test and y_val have to be one-hot-encoded. That means they must have dimension (number_of_samples, 15), where 15 denotes number of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc97u4oZZ04U"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfeM_ZzsXhv8"
      },
      "source": [
        "Save the labels for AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0GfC_zXhv8"
      },
      "source": [
        "y_train_ada = y_train\n",
        "y_test_ada = y_test\n",
        "y_val_ada = y_val"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQVqV19KZ04U"
      },
      "source": [
        "y_train = to_categorical(y_train, 15)\n",
        "y_test = to_categorical(y_test, 15)\n",
        "y_val = to_categorical(y_val, 15)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd9_XX_5Xhv8"
      },
      "source": [
        "## Step 6. Define the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqOSi1KcXhv8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#importing confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxRNywIXXhwC"
      },
      "source": [
        "Get the attacks' names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9AlIiTKXhwC"
      },
      "source": [
        "labels_d = make_value2index(df_test['Label'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1vqAhE1XhwC",
        "outputId": "a03041ae-1418-4431-da09-22277766cd37"
      },
      "source": [
        "print(labels_d)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'BENIGN': 139134, 'Bot': 139623, 'DDoS': 171629, 'DoS GoldenEye': 174202, 'DoS Hulk': 231733, 'DoS Slowhttptest': 233107, 'DoS slowloris': 234556, 'FTP-Patator': 236539, 'Heartbleed': 236542, 'Infiltration': 236551, 'PortScan': 276252, 'SSH-Patator': 277726, 'Web Attack � Brute Force': 278102, 'Web Attack � Sql Injection': 278107, 'Web Attack � XSS': 278270}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erUa8gpIZ04U"
      },
      "source": [
        "# CNN1D Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTmLBZDpZ04U"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Flatten, Dense, Activation,Dropout,MaxPooling1D\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLXy3meMZ04U",
        "outputId": "08ae8f84-1737-495f-c1f1-b2a2c074c0f9"
      },
      "source": [
        "#hyper-params\n",
        "batch_size = 7500 # increasing batch size with more gpu added\n",
        "input_dim = X_train.shape[1]\n",
        "num_class = 15                   # 15 intrusion classes, including benign traffic class\n",
        "num_epochs = 100\n",
        "learning_rates = 1e-4\n",
        "regularizations = 1e-3\n",
        "optim = tf.keras.optimizers.Adam(lr=learning_rates, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "print(input_dim)\n",
        "print(num_class)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNRbsq6CZ04V",
        "outputId": "103e6a61-b903-4fac-deda-0948349c0205"
      },
      "source": [
        "#X_train_r = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train_r = np.zeros((len(X_train), input_dim, 1))\n",
        "X_train_r[:, :, 0] = X_train[:, :input_dim]\n",
        "print(X_train_r.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(556548, 78, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjmIpn1HZ04W",
        "outputId": "50fd1a91-8a60-40cc-c6c7-673cc3042bd3"
      },
      "source": [
        "X_test_r = np.zeros((len(X_test), input_dim, 1))\n",
        "X_test_r[:, :, 0] = X_test[:, :input_dim]\n",
        "print(X_test_r.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(278271, 78, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_KlI1VeZ04W",
        "outputId": "a17032da-a81d-47d6-b607-415ba28a514f"
      },
      "source": [
        "X_val_r = np.zeros((len(X_val), input_dim, 1))\n",
        "X_val_r[:, :, 0] = X_val[:, :input_dim]\n",
        "print(X_val_r.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(278271, 78, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpTZU5OPZ04W",
        "outputId": "6fbeb11b-c365-4e4d-e9f7-9af1154166b4"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "model.add(Conv1D(filters=32, kernel_size=23, activation='relu', padding='same', kernel_initializer='he_uniform', input_shape=(78,1)))\n",
        "model.add(Conv1D(filters=32, kernel_size=17, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling1D(pool_size=2,strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "\n",
        "model.add(Conv1D(filters=64, kernel_size=23, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
        "model.add(Conv1D(filters=64, kernel_size=17, activation='relu', padding='same', kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling1D(pool_size=2,strides=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization(axis=1)) \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_class))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 78, 32)            768       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 78, 32)            17440     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 39, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 39, 32)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 39, 32)            156       \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 39, 64)            47168     \n",
            "_________________________________________________________________\n",
            "conv1d_7 (Conv1D)            (None, 39, 64)            69696     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 19, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 19, 64)            0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 19, 64)            76        \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1216)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                38944     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15)                495       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 174,743\n",
            "Trainable params: 174,627\n",
            "Non-trainable params: 116\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpUP50cvVgzg"
      },
      "source": [
        "METRICS = [\r\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\r\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\r\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\r\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'), \r\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\r\n",
        "      tf.keras.metrics.Precision(name='precision'),\r\n",
        "      tf.keras.metrics.Recall(name='recall'),\r\n",
        "      tf.keras.metrics.AUC(name='auc'),\r\n",
        "]\r\n",
        "\r\n",
        "metrics=METRICS"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldBRHXx_50pg",
        "outputId": "ba880a1f-de9e-45c2-f6d2-82d6eaa84007"
      },
      "source": [
        "from keras.optimizers import Nadam\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "import keras\n",
        "import time\n",
        "time_start = time.time()\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(moniter='val_loss',\n",
        "                                              factor=0.1,\n",
        "                                              patience=10)\n",
        "nadam = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
        "model.compile(loss = \"categorical_crossentropy\",optimizer = \"nadam\", metrics = metrics)\n",
        "\n",
        "#model.compile(\n",
        "#      optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
        "#      loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "#      metrics=metrics)\n",
        "  \n",
        "\n",
        "history = model.fit(X_train_r, y_train, \n",
        "                    epochs=100, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=2,\n",
        "                    validation_data=(X_val_r, y_val),\n",
        "                    callbacks=[reduce_lr])\n",
        "time_end = time.time()\n",
        "train_time = time_end - time_start\n",
        "print(\"train_time:\",train_time)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "75/75 - 19s - loss: 0.3332 - tp: 757863.0000 - fp: 22247.0000 - tn: 11665219.0000 - fn: 76956.0000 - accuracy: 0.9921 - precision: 0.9715 - recall: 0.9078 - auc: 0.9928 - val_loss: 0.2329 - val_tp: 257006.0000 - val_fp: 2431.0000 - val_tn: 3893363.0000 - val_fn: 21265.0000 - val_accuracy: 0.9943 - val_precision: 0.9906 - val_recall: 0.9236 - val_auc: 0.9995\n",
            "Epoch 2/100\n",
            "75/75 - 14s - loss: 0.0417 - tp: 548889.0000 - fp: 4675.0000 - tn: 7786997.0000 - fn: 7659.0000 - accuracy: 0.9985 - precision: 0.9916 - recall: 0.9862 - auc: 0.9995 - val_loss: 0.0775 - val_tp: 269645.0000 - val_fp: 5284.0000 - val_tn: 3890510.0000 - val_fn: 8626.0000 - val_accuracy: 0.9967 - val_precision: 0.9808 - val_recall: 0.9690 - val_auc: 0.9998\n",
            "Epoch 3/100\n",
            "75/75 - 14s - loss: 0.0250 - tp: 552080.0000 - fp: 3036.0000 - tn: 7788636.0000 - fn: 4468.0000 - accuracy: 0.9991 - precision: 0.9945 - recall: 0.9920 - auc: 0.9997 - val_loss: 0.0719 - val_tp: 270904.0000 - val_fp: 5922.0000 - val_tn: 3889872.0000 - val_fn: 7367.0000 - val_accuracy: 0.9968 - val_precision: 0.9786 - val_recall: 0.9735 - val_auc: 0.9993\n",
            "Epoch 4/100\n",
            "75/75 - 14s - loss: 0.0190 - tp: 553177.0000 - fp: 2417.0000 - tn: 7789255.0000 - fn: 3371.0000 - accuracy: 0.9993 - precision: 0.9956 - recall: 0.9939 - auc: 0.9998 - val_loss: 0.0754 - val_tp: 271193.0000 - val_fp: 6159.0000 - val_tn: 3889635.0000 - val_fn: 7078.0000 - val_accuracy: 0.9968 - val_precision: 0.9778 - val_recall: 0.9746 - val_auc: 0.9996\n",
            "Epoch 5/100\n",
            "75/75 - 14s - loss: 0.2460 - tp: 519231.0000 - fp: 18088.0000 - tn: 7773584.0000 - fn: 37317.0000 - accuracy: 0.9934 - precision: 0.9663 - recall: 0.9329 - auc: 0.9919 - val_loss: 0.0733 - val_tp: 270275.0000 - val_fp: 6302.0000 - val_tn: 3889492.0000 - val_fn: 7996.0000 - val_accuracy: 0.9966 - val_precision: 0.9772 - val_recall: 0.9713 - val_auc: 0.9992\n",
            "Epoch 6/100\n",
            "75/75 - 14s - loss: 0.0272 - tp: 551431.0000 - fp: 3363.0000 - tn: 7788309.0000 - fn: 5117.0000 - accuracy: 0.9990 - precision: 0.9939 - recall: 0.9908 - auc: 0.9997 - val_loss: 0.0790 - val_tp: 270959.0000 - val_fp: 6229.0000 - val_tn: 3889565.0000 - val_fn: 7312.0000 - val_accuracy: 0.9968 - val_precision: 0.9775 - val_recall: 0.9737 - val_auc: 0.9994\n",
            "Epoch 7/100\n",
            "75/75 - 14s - loss: 0.0189 - tp: 553109.0000 - fp: 2474.0000 - tn: 7789198.0000 - fn: 3439.0000 - accuracy: 0.9993 - precision: 0.9955 - recall: 0.9938 - auc: 0.9998 - val_loss: 0.0759 - val_tp: 271364.0000 - val_fp: 5874.0000 - val_tn: 3889920.0000 - val_fn: 6907.0000 - val_accuracy: 0.9969 - val_precision: 0.9788 - val_recall: 0.9752 - val_auc: 0.9993\n",
            "Epoch 8/100\n",
            "75/75 - 14s - loss: 0.0155 - tp: 553809.0000 - fp: 2001.0000 - tn: 7789671.0000 - fn: 2739.0000 - accuracy: 0.9994 - precision: 0.9964 - recall: 0.9951 - auc: 0.9998 - val_loss: 0.0615 - val_tp: 272153.0000 - val_fp: 5717.0000 - val_tn: 3890077.0000 - val_fn: 6118.0000 - val_accuracy: 0.9972 - val_precision: 0.9794 - val_recall: 0.9780 - val_auc: 0.9991\n",
            "Epoch 9/100\n",
            "75/75 - 14s - loss: 0.0131 - tp: 554244.0000 - fp: 1747.0000 - tn: 7789925.0000 - fn: 2304.0000 - accuracy: 0.9995 - precision: 0.9969 - recall: 0.9959 - auc: 0.9998 - val_loss: 0.0516 - val_tp: 272678.0000 - val_fp: 5267.0000 - val_tn: 3890527.0000 - val_fn: 5593.0000 - val_accuracy: 0.9974 - val_precision: 0.9811 - val_recall: 0.9799 - val_auc: 0.9992\n",
            "Epoch 10/100\n",
            "75/75 - 14s - loss: 0.0117 - tp: 554453.0000 - fp: 1624.0000 - tn: 7790048.0000 - fn: 2095.0000 - accuracy: 0.9996 - precision: 0.9971 - recall: 0.9962 - auc: 0.9999 - val_loss: 0.0585 - val_tp: 272090.0000 - val_fp: 5762.0000 - val_tn: 3890032.0000 - val_fn: 6181.0000 - val_accuracy: 0.9971 - val_precision: 0.9793 - val_recall: 0.9778 - val_auc: 0.9993\n",
            "Epoch 11/100\n",
            "75/75 - 14s - loss: 0.0107 - tp: 554621.0000 - fp: 1463.0000 - tn: 7790209.0000 - fn: 1927.0000 - accuracy: 0.9996 - precision: 0.9974 - recall: 0.9965 - auc: 0.9999 - val_loss: 0.0498 - val_tp: 272472.0000 - val_fp: 5281.0000 - val_tn: 3890513.0000 - val_fn: 5799.0000 - val_accuracy: 0.9973 - val_precision: 0.9810 - val_recall: 0.9792 - val_auc: 0.9993\n",
            "Epoch 12/100\n",
            "75/75 - 14s - loss: 0.0096 - tp: 554817.0000 - fp: 1316.0000 - tn: 7790356.0000 - fn: 1731.0000 - accuracy: 0.9996 - precision: 0.9976 - recall: 0.9969 - auc: 0.9999 - val_loss: 0.0609 - val_tp: 271893.0000 - val_fp: 6087.0000 - val_tn: 3889707.0000 - val_fn: 6378.0000 - val_accuracy: 0.9970 - val_precision: 0.9781 - val_recall: 0.9771 - val_auc: 0.9992\n",
            "Epoch 13/100\n",
            "75/75 - 14s - loss: 0.0089 - tp: 554925.0000 - fp: 1254.0000 - tn: 7790418.0000 - fn: 1623.0000 - accuracy: 0.9997 - precision: 0.9977 - recall: 0.9971 - auc: 0.9999 - val_loss: 0.0516 - val_tp: 274574.0000 - val_fp: 3449.0000 - val_tn: 3892345.0000 - val_fn: 3697.0000 - val_accuracy: 0.9983 - val_precision: 0.9876 - val_recall: 0.9867 - val_auc: 0.9986\n",
            "Epoch 14/100\n",
            "75/75 - 14s - loss: 0.0081 - tp: 555096.0000 - fp: 1125.0000 - tn: 7790547.0000 - fn: 1452.0000 - accuracy: 0.9997 - precision: 0.9980 - recall: 0.9974 - auc: 0.9999 - val_loss: 0.0507 - val_tp: 273974.0000 - val_fp: 4164.0000 - val_tn: 3891630.0000 - val_fn: 4297.0000 - val_accuracy: 0.9980 - val_precision: 0.9850 - val_recall: 0.9846 - val_auc: 0.9992\n",
            "Epoch 15/100\n",
            "75/75 - 14s - loss: 0.0076 - tp: 555160.0000 - fp: 1112.0000 - tn: 7790560.0000 - fn: 1388.0000 - accuracy: 0.9997 - precision: 0.9980 - recall: 0.9975 - auc: 0.9999 - val_loss: 0.0650 - val_tp: 273521.0000 - val_fp: 4549.0000 - val_tn: 3891245.0000 - val_fn: 4750.0000 - val_accuracy: 0.9978 - val_precision: 0.9836 - val_recall: 0.9829 - val_auc: 0.9975\n",
            "Epoch 16/100\n",
            "75/75 - 14s - loss: 0.0078 - tp: 555121.0000 - fp: 1134.0000 - tn: 7790538.0000 - fn: 1427.0000 - accuracy: 0.9997 - precision: 0.9980 - recall: 0.9974 - auc: 0.9999 - val_loss: 0.0765 - val_tp: 271922.0000 - val_fp: 6192.0000 - val_tn: 3889602.0000 - val_fn: 6349.0000 - val_accuracy: 0.9970 - val_precision: 0.9777 - val_recall: 0.9772 - val_auc: 0.9977\n",
            "Epoch 17/100\n",
            "75/75 - 14s - loss: 0.0070 - tp: 555258.0000 - fp: 1031.0000 - tn: 7790641.0000 - fn: 1290.0000 - accuracy: 0.9997 - precision: 0.9981 - recall: 0.9977 - auc: 0.9999 - val_loss: 0.0532 - val_tp: 273767.0000 - val_fp: 4218.0000 - val_tn: 3891576.0000 - val_fn: 4504.0000 - val_accuracy: 0.9979 - val_precision: 0.9848 - val_recall: 0.9838 - val_auc: 0.9991\n",
            "Epoch 18/100\n",
            "75/75 - 14s - loss: 0.0064 - tp: 555341.0000 - fp: 943.0000 - tn: 7790729.0000 - fn: 1207.0000 - accuracy: 0.9997 - precision: 0.9983 - recall: 0.9978 - auc: 0.9999 - val_loss: 0.0669 - val_tp: 274866.0000 - val_fp: 3213.0000 - val_tn: 3892581.0000 - val_fn: 3405.0000 - val_accuracy: 0.9984 - val_precision: 0.9884 - val_recall: 0.9878 - val_auc: 0.9969\n",
            "Epoch 19/100\n",
            "75/75 - 14s - loss: 0.0061 - tp: 555394.0000 - fp: 910.0000 - tn: 7790762.0000 - fn: 1154.0000 - accuracy: 0.9998 - precision: 0.9984 - recall: 0.9979 - auc: 0.9999 - val_loss: 0.0662 - val_tp: 272289.0000 - val_fp: 5655.0000 - val_tn: 3890139.0000 - val_fn: 5982.0000 - val_accuracy: 0.9972 - val_precision: 0.9797 - val_recall: 0.9785 - val_auc: 0.9983\n",
            "Epoch 20/100\n",
            "75/75 - 14s - loss: 0.0058 - tp: 555443.0000 - fp: 866.0000 - tn: 7790806.0000 - fn: 1105.0000 - accuracy: 0.9998 - precision: 0.9984 - recall: 0.9980 - auc: 0.9999 - val_loss: 0.0600 - val_tp: 275207.0000 - val_fp: 2910.0000 - val_tn: 3892884.0000 - val_fn: 3064.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9890 - val_auc: 0.9976\n",
            "Epoch 21/100\n",
            "75/75 - 14s - loss: 0.0057 - tp: 555492.0000 - fp: 847.0000 - tn: 7790825.0000 - fn: 1056.0000 - accuracy: 0.9998 - precision: 0.9985 - recall: 0.9981 - auc: 0.9999 - val_loss: 0.0531 - val_tp: 275258.0000 - val_fp: 2800.0000 - val_tn: 3892994.0000 - val_fn: 3013.0000 - val_accuracy: 0.9986 - val_precision: 0.9899 - val_recall: 0.9892 - val_auc: 0.9980\n",
            "Epoch 22/100\n",
            "75/75 - 14s - loss: 0.0049 - tp: 555587.0000 - fp: 751.0000 - tn: 7790921.0000 - fn: 961.0000 - accuracy: 0.9998 - precision: 0.9987 - recall: 0.9983 - auc: 0.9999 - val_loss: 0.0579 - val_tp: 275218.0000 - val_fp: 2910.0000 - val_tn: 3892884.0000 - val_fn: 3053.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9890 - val_auc: 0.9978\n",
            "Epoch 23/100\n",
            "75/75 - 14s - loss: 0.0047 - tp: 555625.0000 - fp: 724.0000 - tn: 7790948.0000 - fn: 923.0000 - accuracy: 0.9998 - precision: 0.9987 - recall: 0.9983 - auc: 0.9999 - val_loss: 0.0586 - val_tp: 275245.0000 - val_fp: 2881.0000 - val_tn: 3892913.0000 - val_fn: 3026.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9976\n",
            "Epoch 24/100\n",
            "75/75 - 14s - loss: 0.0046 - tp: 555673.0000 - fp: 693.0000 - tn: 7790979.0000 - fn: 875.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9984 - auc: 1.0000 - val_loss: 0.0651 - val_tp: 275232.0000 - val_fp: 2919.0000 - val_tn: 3892875.0000 - val_fn: 3039.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 25/100\n",
            "75/75 - 14s - loss: 0.0044 - tp: 555678.0000 - fp: 703.0000 - tn: 7790969.0000 - fn: 870.0000 - accuracy: 0.9998 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - val_loss: 0.0628 - val_tp: 275229.0000 - val_fp: 2895.0000 - val_tn: 3892899.0000 - val_fn: 3042.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9973\n",
            "Epoch 26/100\n",
            "75/75 - 14s - loss: 0.0045 - tp: 555679.0000 - fp: 682.0000 - tn: 7790990.0000 - fn: 869.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9984 - auc: 0.9999 - val_loss: 0.0632 - val_tp: 275185.0000 - val_fp: 2941.0000 - val_tn: 3892853.0000 - val_fn: 3086.0000 - val_accuracy: 0.9986 - val_precision: 0.9894 - val_recall: 0.9889 - val_auc: 0.9972\n",
            "Epoch 27/100\n",
            "75/75 - 14s - loss: 0.0043 - tp: 555658.0000 - fp: 702.0000 - tn: 7790970.0000 - fn: 890.0000 - accuracy: 0.9998 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - val_loss: 0.0590 - val_tp: 275236.0000 - val_fp: 2918.0000 - val_tn: 3892876.0000 - val_fn: 3035.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9976\n",
            "Epoch 28/100\n",
            "75/75 - 14s - loss: 0.0045 - tp: 555669.0000 - fp: 718.0000 - tn: 7790954.0000 - fn: 879.0000 - accuracy: 0.9998 - precision: 0.9987 - recall: 0.9984 - auc: 1.0000 - val_loss: 0.0616 - val_tp: 275263.0000 - val_fp: 2879.0000 - val_tn: 3892915.0000 - val_fn: 3008.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9974\n",
            "Epoch 29/100\n",
            "75/75 - 14s - loss: 0.0044 - tp: 555692.0000 - fp: 696.0000 - tn: 7790976.0000 - fn: 856.0000 - accuracy: 0.9998 - precision: 0.9987 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0628 - val_tp: 275231.0000 - val_fp: 2890.0000 - val_tn: 3892904.0000 - val_fn: 3040.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9973\n",
            "Epoch 30/100\n",
            "75/75 - 14s - loss: 0.0043 - tp: 555688.0000 - fp: 687.0000 - tn: 7790985.0000 - fn: 860.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0631 - val_tp: 275217.0000 - val_fp: 2890.0000 - val_tn: 3892904.0000 - val_fn: 3054.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9890 - val_auc: 0.9973\n",
            "Epoch 31/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555745.0000 - fp: 652.0000 - tn: 7791020.0000 - fn: 803.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0612 - val_tp: 275267.0000 - val_fp: 2891.0000 - val_tn: 3892903.0000 - val_fn: 3004.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9974\n",
            "Epoch 32/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555735.0000 - fp: 643.0000 - tn: 7791029.0000 - fn: 813.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0636 - val_tp: 275219.0000 - val_fp: 2919.0000 - val_tn: 3892875.0000 - val_fn: 3052.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9890 - val_auc: 0.9973\n",
            "Epoch 33/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555718.0000 - fp: 675.0000 - tn: 7790997.0000 - fn: 830.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0655 - val_tp: 275211.0000 - val_fp: 2928.0000 - val_tn: 3892866.0000 - val_fn: 3060.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9890 - val_auc: 0.9972\n",
            "Epoch 34/100\n",
            "75/75 - 14s - loss: 0.0043 - tp: 555712.0000 - fp: 657.0000 - tn: 7791015.0000 - fn: 836.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0654 - val_tp: 275224.0000 - val_fp: 2921.0000 - val_tn: 3892873.0000 - val_fn: 3047.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 35/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555745.0000 - fp: 632.0000 - tn: 7791040.0000 - fn: 803.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0646 - val_tp: 275226.0000 - val_fp: 2923.0000 - val_tn: 3892871.0000 - val_fn: 3045.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9973\n",
            "Epoch 36/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555732.0000 - fp: 649.0000 - tn: 7791023.0000 - fn: 816.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0648 - val_tp: 275233.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3038.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9973\n",
            "Epoch 37/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555738.0000 - fp: 637.0000 - tn: 7791035.0000 - fn: 810.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0656 - val_tp: 275234.0000 - val_fp: 2909.0000 - val_tn: 3892885.0000 - val_fn: 3037.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 38/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555731.0000 - fp: 655.0000 - tn: 7791017.0000 - fn: 817.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0646 - val_tp: 275234.0000 - val_fp: 2911.0000 - val_tn: 3892883.0000 - val_fn: 3037.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9973\n",
            "Epoch 39/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555768.0000 - fp: 630.0000 - tn: 7791042.0000 - fn: 780.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0658 - val_tp: 275225.0000 - val_fp: 2921.0000 - val_tn: 3892873.0000 - val_fn: 3046.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9973\n",
            "Epoch 40/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555703.0000 - fp: 680.0000 - tn: 7790992.0000 - fn: 845.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0662 - val_tp: 275242.0000 - val_fp: 2906.0000 - val_tn: 3892888.0000 - val_fn: 3029.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 41/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555743.0000 - fp: 625.0000 - tn: 7791047.0000 - fn: 805.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0662 - val_tp: 275254.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3017.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 42/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555751.0000 - fp: 633.0000 - tn: 7791039.0000 - fn: 797.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0663 - val_tp: 275249.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3022.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 43/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555723.0000 - fp: 655.0000 - tn: 7791017.0000 - fn: 825.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275247.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3024.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 44/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555731.0000 - fp: 659.0000 - tn: 7791013.0000 - fn: 817.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275250.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 45/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555744.0000 - fp: 650.0000 - tn: 7791022.0000 - fn: 804.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0663 - val_tp: 275253.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3018.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 46/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555741.0000 - fp: 657.0000 - tn: 7791015.0000 - fn: 807.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275256.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3015.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 47/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555744.0000 - fp: 639.0000 - tn: 7791033.0000 - fn: 804.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275256.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3015.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 48/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555754.0000 - fp: 635.0000 - tn: 7791037.0000 - fn: 794.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275245.0000 - val_fp: 2905.0000 - val_tn: 3892889.0000 - val_fn: 3026.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 49/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555744.0000 - fp: 663.0000 - tn: 7791009.0000 - fn: 804.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275253.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3018.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 50/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555737.0000 - fp: 649.0000 - tn: 7791023.0000 - fn: 811.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275249.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3022.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 51/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555733.0000 - fp: 633.0000 - tn: 7791039.0000 - fn: 815.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275251.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3020.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 52/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555740.0000 - fp: 637.0000 - tn: 7791035.0000 - fn: 808.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0662 - val_tp: 275247.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3024.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 53/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555760.0000 - fp: 619.0000 - tn: 7791053.0000 - fn: 788.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0663 - val_tp: 275249.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3022.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 54/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555747.0000 - fp: 636.0000 - tn: 7791036.0000 - fn: 801.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275251.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3020.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 55/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555752.0000 - fp: 632.0000 - tn: 7791040.0000 - fn: 796.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275250.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 56/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555747.0000 - fp: 653.0000 - tn: 7791019.0000 - fn: 801.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275250.0000 - val_fp: 2901.0000 - val_tn: 3892893.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 57/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555750.0000 - fp: 643.0000 - tn: 7791029.0000 - fn: 798.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275251.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3020.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 58/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555696.0000 - fp: 667.0000 - tn: 7791005.0000 - fn: 852.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275250.0000 - val_fp: 2901.0000 - val_tn: 3892893.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 59/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555754.0000 - fp: 618.0000 - tn: 7791054.0000 - fn: 794.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275247.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3024.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 60/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555746.0000 - fp: 650.0000 - tn: 7791022.0000 - fn: 802.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275248.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3023.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 61/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555742.0000 - fp: 623.0000 - tn: 7791049.0000 - fn: 806.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275245.0000 - val_fp: 2906.0000 - val_tn: 3892888.0000 - val_fn: 3026.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 62/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555754.0000 - fp: 618.0000 - tn: 7791054.0000 - fn: 794.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275250.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 63/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555729.0000 - fp: 645.0000 - tn: 7791027.0000 - fn: 819.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0667 - val_tp: 275250.0000 - val_fp: 2907.0000 - val_tn: 3892887.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 64/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555737.0000 - fp: 646.0000 - tn: 7791026.0000 - fn: 811.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275253.0000 - val_fp: 2901.0000 - val_tn: 3892893.0000 - val_fn: 3018.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 65/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555743.0000 - fp: 648.0000 - tn: 7791024.0000 - fn: 805.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0669 - val_tp: 275247.0000 - val_fp: 2900.0000 - val_tn: 3892894.0000 - val_fn: 3024.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 66/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555748.0000 - fp: 653.0000 - tn: 7791019.0000 - fn: 800.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275245.0000 - val_fp: 2907.0000 - val_tn: 3892887.0000 - val_fn: 3026.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 67/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555744.0000 - fp: 657.0000 - tn: 7791015.0000 - fn: 804.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275248.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3023.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 68/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555755.0000 - fp: 630.0000 - tn: 7791042.0000 - fn: 793.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275250.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 69/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555738.0000 - fp: 638.0000 - tn: 7791034.0000 - fn: 810.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275250.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 70/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555736.0000 - fp: 639.0000 - tn: 7791033.0000 - fn: 812.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275246.0000 - val_fp: 2905.0000 - val_tn: 3892889.0000 - val_fn: 3025.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 71/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555747.0000 - fp: 613.0000 - tn: 7791059.0000 - fn: 801.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275246.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3025.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 72/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555778.0000 - fp: 632.0000 - tn: 7791040.0000 - fn: 770.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275250.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 73/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555757.0000 - fp: 636.0000 - tn: 7791036.0000 - fn: 791.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275251.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3020.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 74/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555732.0000 - fp: 635.0000 - tn: 7791037.0000 - fn: 816.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0667 - val_tp: 275247.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3024.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 75/100\n",
            "75/75 - 14s - loss: 0.0043 - tp: 555704.0000 - fp: 673.0000 - tn: 7790999.0000 - fn: 844.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275256.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3015.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 76/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555767.0000 - fp: 635.0000 - tn: 7791037.0000 - fn: 781.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275254.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3017.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 77/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555750.0000 - fp: 636.0000 - tn: 7791036.0000 - fn: 798.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275254.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3017.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 78/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555753.0000 - fp: 621.0000 - tn: 7791051.0000 - fn: 795.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275252.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3019.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 79/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555735.0000 - fp: 635.0000 - tn: 7791037.0000 - fn: 813.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275250.0000 - val_fp: 2901.0000 - val_tn: 3892893.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 80/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555705.0000 - fp: 664.0000 - tn: 7791008.0000 - fn: 843.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275253.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3018.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 81/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555762.0000 - fp: 623.0000 - tn: 7791049.0000 - fn: 786.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275252.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3019.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 82/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555739.0000 - fp: 632.0000 - tn: 7791040.0000 - fn: 809.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275251.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3020.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 83/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555722.0000 - fp: 668.0000 - tn: 7791004.0000 - fn: 826.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275250.0000 - val_fp: 2906.0000 - val_tn: 3892888.0000 - val_fn: 3021.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 84/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555772.0000 - fp: 631.0000 - tn: 7791041.0000 - fn: 776.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275255.0000 - val_fp: 2905.0000 - val_tn: 3892889.0000 - val_fn: 3016.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 85/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555763.0000 - fp: 634.0000 - tn: 7791038.0000 - fn: 785.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275249.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3022.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 86/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555755.0000 - fp: 620.0000 - tn: 7791052.0000 - fn: 793.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 0.9999 - val_loss: 0.0665 - val_tp: 275254.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3017.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 87/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555753.0000 - fp: 627.0000 - tn: 7791045.0000 - fn: 795.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275253.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3018.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 88/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555740.0000 - fp: 645.0000 - tn: 7791027.0000 - fn: 808.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275252.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3019.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 89/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555742.0000 - fp: 647.0000 - tn: 7791025.0000 - fn: 806.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275254.0000 - val_fp: 2901.0000 - val_tn: 3892893.0000 - val_fn: 3017.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 90/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555757.0000 - fp: 636.0000 - tn: 7791036.0000 - fn: 791.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275255.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3016.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 91/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555733.0000 - fp: 655.0000 - tn: 7791017.0000 - fn: 815.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275253.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3018.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 92/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555767.0000 - fp: 611.0000 - tn: 7791061.0000 - fn: 781.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275256.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3015.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 93/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555760.0000 - fp: 640.0000 - tn: 7791032.0000 - fn: 788.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275256.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3015.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 94/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555742.0000 - fp: 651.0000 - tn: 7791021.0000 - fn: 806.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275253.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3018.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 95/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555710.0000 - fp: 679.0000 - tn: 7790993.0000 - fn: 838.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275251.0000 - val_fp: 2903.0000 - val_tn: 3892891.0000 - val_fn: 3020.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 96/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555757.0000 - fp: 629.0000 - tn: 7791043.0000 - fn: 791.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275255.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3016.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 97/100\n",
            "75/75 - 14s - loss: 0.0041 - tp: 555739.0000 - fp: 659.0000 - tn: 7791013.0000 - fn: 809.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275255.0000 - val_fp: 2904.0000 - val_tn: 3892890.0000 - val_fn: 3016.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 98/100\n",
            "75/75 - 14s - loss: 0.0042 - tp: 555729.0000 - fp: 667.0000 - tn: 7791005.0000 - fn: 819.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9985 - auc: 1.0000 - val_loss: 0.0664 - val_tp: 275249.0000 - val_fp: 2905.0000 - val_tn: 3892889.0000 - val_fn: 3022.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "Epoch 99/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555775.0000 - fp: 600.0000 - tn: 7791072.0000 - fn: 773.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0665 - val_tp: 275252.0000 - val_fp: 2902.0000 - val_tn: 3892892.0000 - val_fn: 3019.0000 - val_accuracy: 0.9986 - val_precision: 0.9896 - val_recall: 0.9892 - val_auc: 0.9972\n",
            "Epoch 100/100\n",
            "75/75 - 14s - loss: 0.0040 - tp: 555754.0000 - fp: 641.0000 - tn: 7791031.0000 - fn: 794.0000 - accuracy: 0.9998 - precision: 0.9988 - recall: 0.9986 - auc: 1.0000 - val_loss: 0.0666 - val_tp: 275248.0000 - val_fp: 2907.0000 - val_tn: 3892887.0000 - val_fn: 3023.0000 - val_accuracy: 0.9986 - val_precision: 0.9895 - val_recall: 0.9891 - val_auc: 0.9972\n",
            "train_time: 1396.6973271369934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT635dAfpOVN"
      },
      "source": [
        "## Get the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSo0TpT5Z04X",
        "outputId": "ae73ae3b-5194-4659-e9c5-6e593be4b4f9"
      },
      "source": [
        "# evaluate model\n",
        "accuracy = model.evaluate(X_test_r, y_test, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 2s 52ms/step - loss: 0.1646 - tp: 272638.0000 - fp: 5453.0000 - tn: 3890341.0000 - fn: 5633.0000 - accuracy: 0.9973 - precision: 0.9804 - recall: 0.9798 - auc: 0.9926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGNmOrhH1CL"
      },
      "source": [
        "y_pred=model.predict(X_test_r)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltyd2KVLIBCK",
        "outputId": "9e7c91c0-45ef-41d7-85b1-05f6a553805b"
      },
      "source": [
        "display_metrics(y_test_ada, np.argmax(y_pred, axis = 1), labels_d)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.98\n",
            "\n",
            "Micro Precision: 0.98\n",
            "Micro Recall: 0.98\n",
            "Micro F1-score: 0.98\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.58\n",
            "Macro Recall: 0.56\n",
            "Macro F1-score: 0.56\n",
            "\n",
            "Weighted Precision: 0.98\n",
            "Weighted Recall: 0.98\n",
            "Weighted F1-score: 0.98\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.99      1.00      0.99    139135\n",
            "                       Bot       0.00      0.00      0.00       489\n",
            "                      DDoS       0.94      1.00      0.97     32006\n",
            "             DoS GoldenEye       0.92      0.93      0.93      2573\n",
            "                  DoS Hulk       1.00      0.96      0.98     57531\n",
            "          DoS Slowhttptest       0.55      0.79      0.65      1374\n",
            "             DoS slowloris       0.85      0.44      0.58      1449\n",
            "               FTP-Patator       1.00      0.94      0.97      1983\n",
            "                Heartbleed       0.00      0.00      0.00         3\n",
            "              Infiltration       0.00      0.00      0.00         9\n",
            "                  PortScan       1.00      1.00      1.00     39701\n",
            "               SSH-Patator       0.97      0.48      0.65      1474\n",
            "  Web Attack � Brute Force       0.55      0.86      0.67       376\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         5\n",
            "          Web Attack � XSS       0.00      0.00      0.00       163\n",
            "\n",
            "                  accuracy                           0.98    278271\n",
            "                 macro avg       0.58      0.56      0.56    278271\n",
            "              weighted avg       0.98      0.98      0.98    278271\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbhp6oW_Z04X"
      },
      "source": [
        ""
      ]
    }
  ]
}