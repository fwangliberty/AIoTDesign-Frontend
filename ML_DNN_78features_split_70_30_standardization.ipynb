{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ML_DNN_78features_split_70_30_standardization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fwangliberty/AIoTDesign-Frontend/blob/master/ML_DNN_78features_split_70_30_standardization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq5p9swvZ04G"
      },
      "source": [
        "# Baseline Models for CICIDS 2017 Data Set with 78 Features "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXg4HMXOZ04H"
      },
      "source": [
        "We use the pre-processing dataset that is augmented by 7 new connection based features, and splitted into 70:15:15.  We use the following classification methods: PCA+RF,Naive Bayes model, Decision Tree Classifier, Random Foresty with DecisionTree, Logistic Regression Classifier, Adaboost, Voting, kNN, and DNN. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SOKT1sRZ04I"
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH9hOnpmzv6-"
      },
      "source": [
        "def display_metrics(y_test, y_pred, label_names):\r\n",
        "  print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\r\n",
        "\r\n",
        "  print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\r\n",
        "  print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\r\n",
        "  print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\r\n",
        "\r\n",
        "  print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\r\n",
        "  print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\r\n",
        "  print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\r\n",
        "\r\n",
        "  print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\r\n",
        "  print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\r\n",
        "  print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\r\n",
        "\r\n",
        "  print('\\nClassification Report\\n')\r\n",
        "  print(classification_report(y_test, y_pred, target_names=label_names))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCwZZFMTZ04J"
      },
      "source": [
        "def display_all(df):\n",
        "    with pd.option_context(\"display.max_rows\", 100, \"display.max_columns\", 100): \n",
        "        print(df)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceDogrv3Z04J"
      },
      "source": [
        "def make_value2index(attacks):\n",
        "    #make dictionary\n",
        "    attacks = sorted(attacks)\n",
        "    d = {}\n",
        "    counter=0\n",
        "    for attack in attacks:\n",
        "        d[attack] = counter\n",
        "        counter+=1\n",
        "    return d"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ht3b8hIQZ04K"
      },
      "source": [
        "# chganges label from string to integer/index\n",
        "def encode_label(Y_str):\n",
        "    labels_d = make_value2index(np.unique(Y_str))\n",
        "    Y = [labels_d[y_str] for y_str  in Y_str]\n",
        "    Y = np.array(Y)\n",
        "    return np.array(Y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMisXWZWZ04K"
      },
      "source": [
        "## Step 1. Loading csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwxZ7DrXZ04L"
      },
      "source": [
        "# All columns\n",
        "col_names = np.array(['dst sport count', 'src dport count', 'dst src count', 'dport count', 'sport count', 'dst host count','src host count','Source Port', 'Destination Port',\n",
        "                      'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\n",
        "                      'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
        "                      'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
        "                      'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total',\n",
        "                      'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
        "                      'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\n",
        "                      'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\n",
        "                      'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
        "                      'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
        "                      'Avg Bwd Segment Size','Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
        "                      'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\n",
        "                      'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
        "                      'Idle Std', 'Idle Max', 'Idle Min', 'Label'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoCkMRAcaIA6"
      },
      "source": [
        "### Option 1. Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uaw_A5kaHSj",
        "outputId": "da415d1d-a61f-4d1c-8d17-3c83509a1f2f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qUtBnilZ04M"
      },
      "source": [
        "# load three csv files generated by mlp4nids (Multi-layer perceptron for network intrusion detection )\n",
        "# first load the train set\n",
        "df_train = pd.read_csv('/content/drive/My Drive/CICIDS2017/train_set_ext78_2.csv',names=col_names, skiprows=1)  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBn8DsjhX_U4",
        "outputId": "9fb8a317-c584-415d-866f-5b42e2b44f84"
      },
      "source": [
        "print('Train set size: ', df_train.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set size:  (879589, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXYvaCAjZ04P",
        "outputId": "cee681e3-6c40-429d-bd1b-950fa5f4a25f"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/CICIDS2017/test_set_ext78_2.csv',names=col_names, skiprows=1)  \n",
        "print('Test set size: ', df_test.shape)\n",
        "\n",
        "df_val = pd.read_csv('/content/drive/My Drive/CICIDS2017/crossval_set_ext78_2.csv',names=col_names, skiprows=1)  \n",
        "print('Validation set size: ', df_val.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set size:  (188483, 79)\n",
            "Validation set size:  (188484, 79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cbbuInpXhvz"
      },
      "source": [
        "### Option 2. Load from local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLcmd-A8Xhv0"
      },
      "source": [
        "dataroot = '../data/cicids2017clean/train_set_ext78_2.csv'\n",
        "df_train = pd.read_csv(dataroot, names=col_names, skiprows=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9oqAbFyXhv0"
      },
      "source": [
        "dataroot = '../data/cicids2017clean/crossval_set_ext78_2.csv'\n",
        "df_val = pd.read_csv(dataroot, names=col_names, skiprows=1) \n",
        "dataroot = '../data/cicids2017clean/test_set_ext78_2.csv'\n",
        "df_test = pd.read_csv(dataroot, names=col_names, skiprows=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls46tMA9Xhv0"
      },
      "source": [
        "## Step 2. Exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "q-oBvrtQXhv0",
        "outputId": "b0bd1075-8e7f-40a9-951c-10a5a3be7646"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "      <td>61477</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>98136542</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>56</td>\n",
              "      <td>11601</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.656854</td>\n",
              "      <td>5840</td>\n",
              "      <td>0</td>\n",
              "      <td>2320.20</td>\n",
              "      <td>2436.833027</td>\n",
              "      <td>118.783480</td>\n",
              "      <td>0.132468</td>\n",
              "      <td>8.178045e+06</td>\n",
              "      <td>2.460000e+07</td>\n",
              "      <td>85700000</td>\n",
              "      <td>1</td>\n",
              "      <td>97900000</td>\n",
              "      <td>14000000.0</td>\n",
              "      <td>3.190000e+07</td>\n",
              "      <td>85700000</td>\n",
              "      <td>1</td>\n",
              "      <td>286190</td>\n",
              "      <td>71547.5</td>\n",
              "      <td>137766.35380</td>\n",
              "      <td>278139</td>\n",
              "      <td>181</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>112</td>\n",
              "      <td>0.081519</td>\n",
              "      <td>0.050949</td>\n",
              "      <td>0</td>\n",
              "      <td>5840</td>\n",
              "      <td>833.071429</td>\n",
              "      <td>1774.906302</td>\n",
              "      <td>3.150292e+06</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>897.153846</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2320.20</td>\n",
              "      <td>8</td>\n",
              "      <td>56</td>\n",
              "      <td>5</td>\n",
              "      <td>11601</td>\n",
              "      <td>256</td>\n",
              "      <td>229</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>996.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>996</td>\n",
              "      <td>996</td>\n",
              "      <td>48900000.0</td>\n",
              "      <td>51900000.0</td>\n",
              "      <td>85700000</td>\n",
              "      <td>12200000</td>\n",
              "      <td>DDoS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>33</td>\n",
              "      <td>49665</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>121917</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>687</td>\n",
              "      <td>361</td>\n",
              "      <td>681</td>\n",
              "      <td>0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>391.454978</td>\n",
              "      <td>349</td>\n",
              "      <td>0</td>\n",
              "      <td>90.25</td>\n",
              "      <td>172.523187</td>\n",
              "      <td>8596.012041</td>\n",
              "      <td>57.416111</td>\n",
              "      <td>2.031950e+04</td>\n",
              "      <td>2.482528e+04</td>\n",
              "      <td>61854</td>\n",
              "      <td>1</td>\n",
              "      <td>91167</td>\n",
              "      <td>45583.5</td>\n",
              "      <td>2.300996e+04</td>\n",
              "      <td>61854</td>\n",
              "      <td>29313</td>\n",
              "      <td>92688</td>\n",
              "      <td>30896.0</td>\n",
              "      <td>52536.13923</td>\n",
              "      <td>91556</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>88</td>\n",
              "      <td>24.606905</td>\n",
              "      <td>32.809206</td>\n",
              "      <td>0</td>\n",
              "      <td>681</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>253.090046</td>\n",
              "      <td>6.405457e+04</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>149.714286</td>\n",
              "      <td>229.0</td>\n",
              "      <td>90.25</td>\n",
              "      <td>3</td>\n",
              "      <td>687</td>\n",
              "      <td>4</td>\n",
              "      <td>361</td>\n",
              "      <td>8192</td>\n",
              "      <td>5061</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>58</td>\n",
              "      <td>1</td>\n",
              "      <td>59</td>\n",
              "      <td>7</td>\n",
              "      <td>59588</td>\n",
              "      <td>53</td>\n",
              "      <td>17</td>\n",
              "      <td>30773</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>74</td>\n",
              "      <td>262</td>\n",
              "      <td>37</td>\n",
              "      <td>37</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>131</td>\n",
              "      <td>131</td>\n",
              "      <td>131.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10918.662464</td>\n",
              "      <td>129.984077</td>\n",
              "      <td>1.025767e+04</td>\n",
              "      <td>1.776074e+04</td>\n",
              "      <td>30766</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "      <td>64.992038</td>\n",
              "      <td>64.992038</td>\n",
              "      <td>37</td>\n",
              "      <td>131</td>\n",
              "      <td>74.600000</td>\n",
              "      <td>51.485920</td>\n",
              "      <td>2.650800e+03</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>93.250000</td>\n",
              "      <td>37.0</td>\n",
              "      <td>131.00</td>\n",
              "      <td>2</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "      <td>262</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>50918</td>\n",
              "      <td>6</td>\n",
              "      <td>118</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16949.152540</td>\n",
              "      <td>1.180000e+02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>118</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>8474.576271</td>\n",
              "      <td>8474.576271</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>905</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>55989</td>\n",
              "      <td>80</td>\n",
              "      <td>6</td>\n",
              "      <td>47</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42553.191490</td>\n",
              "      <td>4.700000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>47</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>42553.191490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>259</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>BENIGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dst sport count  src dport count  dst src count  ...  Idle Max  Idle Min   Label\n",
              "0                2              100            100  ...  85700000  12200000    DDoS\n",
              "1                2               23             13  ...         0         0  BENIGN\n",
              "2                1                2              3  ...         0         0  BENIGN\n",
              "3                2                1              2  ...         0         0  BENIGN\n",
              "4                2                4              2  ...         0         0  BENIGN\n",
              "\n",
              "[5 rows x 79 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miDxhmNyZ04N"
      },
      "source": [
        "Count the number of attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpKy7b9fZ04O",
        "scrolled": true,
        "outputId": "a0bf5b8b-bb3d-4b0f-82a7-b8f12a8da904"
      },
      "source": [
        "df_train['Label'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        490029\n",
              "DoS Hulk                      161134\n",
              "PortScan                      110992\n",
              "DDoS                           89590\n",
              "DoS GoldenEye                   7220\n",
              "FTP-Patator                     5621\n",
              "SSH-Patator                     4153\n",
              "DoS slowloris                   4049\n",
              "DoS Slowhttptest                3833\n",
              "Bot                             1401\n",
              "Web Attack � Brute Force        1059\n",
              "Web Attack � XSS                 463\n",
              "Infiltration                      25\n",
              "Web Attack � Sql Injection        12\n",
              "Heartbleed                         8\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "o2Z-8ReCLIG0",
        "outputId": "85b89e15-60e8-4db3-c416-956795b50c57"
      },
      "source": [
        "df_train.describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>879589.000000</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "      <td>8.795890e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.655316</td>\n",
              "      <td>37.867227</td>\n",
              "      <td>49.836973</td>\n",
              "      <td>48.006394</td>\n",
              "      <td>10.465226</td>\n",
              "      <td>55.566170</td>\n",
              "      <td>57.243626</td>\n",
              "      <td>42882.302844</td>\n",
              "      <td>6397.910447</td>\n",
              "      <td>8.693028</td>\n",
              "      <td>1.923037e+07</td>\n",
              "      <td>8.214027</td>\n",
              "      <td>8.823871</td>\n",
              "      <td>4.403727e+02</td>\n",
              "      <td>1.417082e+04</td>\n",
              "      <td>179.036862</td>\n",
              "      <td>13.701055</td>\n",
              "      <td>48.020170</td>\n",
              "      <td>61.747571</td>\n",
              "      <td>1463.559232</td>\n",
              "      <td>29.061780</td>\n",
              "      <td>487.495944</td>\n",
              "      <td>600.398140</td>\n",
              "      <td>1.154200e+06</td>\n",
              "      <td>7.835547e+04</td>\n",
              "      <td>1.785500e+06</td>\n",
              "      <td>4.593409e+06</td>\n",
              "      <td>1.505781e+07</td>\n",
              "      <td>1.817909e+05</td>\n",
              "      <td>1.895005e+07</td>\n",
              "      <td>3.497445e+06</td>\n",
              "      <td>5.784826e+06</td>\n",
              "      <td>1.493529e+07</td>\n",
              "      <td>8.764154e+05</td>\n",
              "      <td>9.546793e+06</td>\n",
              "      <td>1.832198e+06</td>\n",
              "      <td>2.096462e+06</td>\n",
              "      <td>5.847373e+06</td>\n",
              "      <td>7.775011e+05</td>\n",
              "      <td>0.035845</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>-1.779193e+03</td>\n",
              "      <td>-1.391305e+03</td>\n",
              "      <td>7.066763e+04</td>\n",
              "      <td>7.731049e+03</td>\n",
              "      <td>11.697604</td>\n",
              "      <td>1520.444635</td>\n",
              "      <td>250.439207</td>\n",
              "      <td>478.990505</td>\n",
              "      <td>9.488540e+05</td>\n",
              "      <td>0.056930</td>\n",
              "      <td>0.035845</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.348102</td>\n",
              "      <td>0.351718</td>\n",
              "      <td>0.068783</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.662657</td>\n",
              "      <td>277.045229</td>\n",
              "      <td>48.020170</td>\n",
              "      <td>487.495944</td>\n",
              "      <td>8.214027</td>\n",
              "      <td>4.403727e+02</td>\n",
              "      <td>8.823871</td>\n",
              "      <td>1.416974e+04</td>\n",
              "      <td>7118.105536</td>\n",
              "      <td>1463.521291</td>\n",
              "      <td>4.322587</td>\n",
              "      <td>-1.156058e+03</td>\n",
              "      <td>8.722149e+04</td>\n",
              "      <td>3.427464e+04</td>\n",
              "      <td>1.409675e+05</td>\n",
              "      <td>6.695474e+04</td>\n",
              "      <td>1.402000e+07</td>\n",
              "      <td>8.088585e+05</td>\n",
              "      <td>1.463478e+07</td>\n",
              "      <td>1.341685e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.810487</td>\n",
              "      <td>40.954725</td>\n",
              "      <td>44.142062</td>\n",
              "      <td>39.181947</td>\n",
              "      <td>25.970811</td>\n",
              "      <td>41.115493</td>\n",
              "      <td>40.505493</td>\n",
              "      <td>19661.354670</td>\n",
              "      <td>16111.251758</td>\n",
              "      <td>4.734203</td>\n",
              "      <td>3.711919e+07</td>\n",
              "      <td>685.761027</td>\n",
              "      <td>912.882257</td>\n",
              "      <td>6.605092e+03</td>\n",
              "      <td>2.075330e+06</td>\n",
              "      <td>610.645248</td>\n",
              "      <td>57.039193</td>\n",
              "      <td>160.224075</td>\n",
              "      <td>237.180304</td>\n",
              "      <td>2657.258586</td>\n",
              "      <td>60.386127</td>\n",
              "      <td>814.918490</td>\n",
              "      <td>1167.665597</td>\n",
              "      <td>2.334998e+07</td>\n",
              "      <td>2.713128e+05</td>\n",
              "      <td>4.929222e+06</td>\n",
              "      <td>9.877418e+06</td>\n",
              "      <td>3.194961e+07</td>\n",
              "      <td>3.274780e+06</td>\n",
              "      <td>3.708712e+07</td>\n",
              "      <td>9.762596e+06</td>\n",
              "      <td>1.305067e+07</td>\n",
              "      <td>3.201589e+07</td>\n",
              "      <td>8.098459e+06</td>\n",
              "      <td>2.816566e+07</td>\n",
              "      <td>8.481475e+06</td>\n",
              "      <td>8.133173e+06</td>\n",
              "      <td>2.054948e+07</td>\n",
              "      <td>7.499528e+06</td>\n",
              "      <td>0.185904</td>\n",
              "      <td>0.008327</td>\n",
              "      <td>1.186150e+06</td>\n",
              "      <td>1.158914e+06</td>\n",
              "      <td>2.652601e+05</td>\n",
              "      <td>3.809361e+04</td>\n",
              "      <td>22.706568</td>\n",
              "      <td>2687.748532</td>\n",
              "      <td>394.185794</td>\n",
              "      <td>848.222439</td>\n",
              "      <td>2.302125e+06</td>\n",
              "      <td>0.231709</td>\n",
              "      <td>0.185904</td>\n",
              "      <td>0.012794</td>\n",
              "      <td>0.476369</td>\n",
              "      <td>0.477507</td>\n",
              "      <td>0.253085</td>\n",
              "      <td>0.008327</td>\n",
              "      <td>0.012794</td>\n",
              "      <td>0.643625</td>\n",
              "      <td>431.918903</td>\n",
              "      <td>160.224075</td>\n",
              "      <td>814.918490</td>\n",
              "      <td>685.761027</td>\n",
              "      <td>6.605092e+03</td>\n",
              "      <td>912.882257</td>\n",
              "      <td>2.075043e+06</td>\n",
              "      <td>13584.239160</td>\n",
              "      <td>7163.856980</td>\n",
              "      <td>537.436126</td>\n",
              "      <td>6.129328e+05</td>\n",
              "      <td>6.487369e+05</td>\n",
              "      <td>3.700512e+05</td>\n",
              "      <td>9.505822e+05</td>\n",
              "      <td>5.900885e+05</td>\n",
              "      <td>3.114625e+07</td>\n",
              "      <td>6.040495e+06</td>\n",
              "      <td>3.199113e+07</td>\n",
              "      <td>3.091560e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+07</td>\n",
              "      <td>-2.000000e+06</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000e+00</td>\n",
              "      <td>-1.300000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.073741e+09</td>\n",
              "      <td>-1.073741e+09</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.368707e+08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>36053.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.100000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.185832e+02</td>\n",
              "      <td>1.130725e+00</td>\n",
              "      <td>5.966667e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.700000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>7.750416e-01</td>\n",
              "      <td>6.135056e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.190890</td>\n",
              "      <td>4.800000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>50214.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.002600e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.100000e+01</td>\n",
              "      <td>1.140000e+02</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.542475e+03</td>\n",
              "      <td>9.014017e+01</td>\n",
              "      <td>1.400680e+04</td>\n",
              "      <td>4.520698e+03</td>\n",
              "      <td>3.163200e+04</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>4.900000e+01</td>\n",
              "      <td>4.900000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.900000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.400000e+01</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>4.788519e+01</td>\n",
              "      <td>1.054819e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>54.200000</td>\n",
              "      <td>21.361960</td>\n",
              "      <td>4.563333e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>69.250000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.100000e+01</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.140000e+02</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.400000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>57335.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.453224e+06</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.100000e+02</td>\n",
              "      <td>4.211000e+03</td>\n",
              "      <td>201.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>48.750000</td>\n",
              "      <td>72.555151</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>453.400000</td>\n",
              "      <td>630.000000</td>\n",
              "      <td>1.363636e+05</td>\n",
              "      <td>2.739726e+04</td>\n",
              "      <td>1.033201e+06</td>\n",
              "      <td>2.212140e+06</td>\n",
              "      <td>5.702855e+06</td>\n",
              "      <td>5.400000e+01</td>\n",
              "      <td>5.871722e+06</td>\n",
              "      <td>1.273712e+06</td>\n",
              "      <td>2.006017e+06</td>\n",
              "      <td>5.487049e+06</td>\n",
              "      <td>4.800000e+01</td>\n",
              "      <td>1.475960e+05</td>\n",
              "      <td>2.948780e+04</td>\n",
              "      <td>4.465791e+04</td>\n",
              "      <td>1.319900e+05</td>\n",
              "      <td>4.500000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.440000e+02</td>\n",
              "      <td>1.320000e+02</td>\n",
              "      <td>1.408451e+04</td>\n",
              "      <td>8.620690e+03</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1472.000000</td>\n",
              "      <td>283.500000</td>\n",
              "      <td>533.098083</td>\n",
              "      <td>2.841936e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>48.750000</td>\n",
              "      <td>453.400000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.100000e+02</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.211000e+03</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.187895e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.187896e+06</td>\n",
              "      <td>5.104746e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65534.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>217797.000000</td>\n",
              "      <td>289585.000000</td>\n",
              "      <td>2.866110e+06</td>\n",
              "      <td>6.396506e+08</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>2065.000000</td>\n",
              "      <td>5939.285714</td>\n",
              "      <td>6692.644993</td>\n",
              "      <td>17376.000000</td>\n",
              "      <td>1983.000000</td>\n",
              "      <td>4370.686524</td>\n",
              "      <td>6715.738331</td>\n",
              "      <td>2.071000e+09</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.480000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.370000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.299341e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.617240e+06</td>\n",
              "      <td>5.791700e+06</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1448.000000</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>2920.000000</td>\n",
              "      <td>4731.522394</td>\n",
              "      <td>2.240000e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>3337.142857</td>\n",
              "      <td>5939.285714</td>\n",
              "      <td>4370.686524</td>\n",
              "      <td>217797.000000</td>\n",
              "      <td>2.866110e+06</td>\n",
              "      <td>289585.000000</td>\n",
              "      <td>6.396506e+08</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>207409.000000</td>\n",
              "      <td>6.000000e+01</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>6.380000e+07</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>1.000000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>7.560000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dst sport count  src dport count  ...      Idle Max      Idle Min\n",
              "count    879589.000000    879589.000000  ...  8.795890e+05  8.795890e+05\n",
              "mean          9.655316        37.867227  ...  1.463478e+07  1.341685e+07\n",
              "std          25.810487        40.954725  ...  3.199113e+07  3.091560e+07\n",
              "min           1.000000         1.000000  ...  0.000000e+00  0.000000e+00\n",
              "25%           1.000000         1.000000  ...  0.000000e+00  0.000000e+00\n",
              "50%           1.000000        16.000000  ...  0.000000e+00  0.000000e+00\n",
              "75%           2.000000        95.000000  ...  5.187896e+06  5.104746e+06\n",
              "max         100.000000       100.000000  ...  1.200000e+08  1.200000e+08\n",
              "\n",
              "[8 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2X3KG4zZ04P"
      },
      "source": [
        "Read test and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5hWm9Q-Z04Q",
        "outputId": "5929e988-67c8-4d96-925d-840c1fb50936"
      },
      "source": [
        "print('Test set: ')\n",
        "df_test['Label'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        105019\n",
              "DoS Hulk                       34547\n",
              "PortScan                       23846\n",
              "DDoS                           19271\n",
              "DoS GoldenEye                   1542\n",
              "FTP-Patator                     1178\n",
              "DoS slowloris                    834\n",
              "DoS Slowhttptest                 828\n",
              "SSH-Patator                      826\n",
              "Bot                              280\n",
              "Web Attack � Brute Force         209\n",
              "Web Attack � XSS                  93\n",
              "Web Attack � Sql Injection         7\n",
              "Heartbleed                         2\n",
              "Infiltration                       1\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "HBrwnK1ZLaRV",
        "outputId": "b5c827a4-09bb-4e70-dfeb-cc4a460cbb00"
      },
      "source": [
        "df_test.describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>188483.000000</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "      <td>1.884830e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.625308</td>\n",
              "      <td>37.861701</td>\n",
              "      <td>49.864025</td>\n",
              "      <td>48.026984</td>\n",
              "      <td>10.434315</td>\n",
              "      <td>55.607434</td>\n",
              "      <td>57.249322</td>\n",
              "      <td>42825.770807</td>\n",
              "      <td>6398.026989</td>\n",
              "      <td>8.699867</td>\n",
              "      <td>1.937297e+07</td>\n",
              "      <td>6.393341</td>\n",
              "      <td>6.290955</td>\n",
              "      <td>425.507547</td>\n",
              "      <td>9.614426e+03</td>\n",
              "      <td>180.326422</td>\n",
              "      <td>13.616549</td>\n",
              "      <td>48.088141</td>\n",
              "      <td>62.258627</td>\n",
              "      <td>1471.358101</td>\n",
              "      <td>29.252240</td>\n",
              "      <td>489.581182</td>\n",
              "      <td>604.521501</td>\n",
              "      <td>1.141231e+06</td>\n",
              "      <td>7.836992e+04</td>\n",
              "      <td>1.791253e+06</td>\n",
              "      <td>4.628396e+06</td>\n",
              "      <td>1.515027e+07</td>\n",
              "      <td>1.736502e+05</td>\n",
              "      <td>1.910116e+07</td>\n",
              "      <td>3.521722e+06</td>\n",
              "      <td>5.821567e+06</td>\n",
              "      <td>1.502940e+07</td>\n",
              "      <td>8.824922e+05</td>\n",
              "      <td>9.685500e+06</td>\n",
              "      <td>1.863613e+06</td>\n",
              "      <td>2.133658e+06</td>\n",
              "      <td>5.939107e+06</td>\n",
              "      <td>7.890398e+05</td>\n",
              "      <td>0.036115</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>-7.244541e+02</td>\n",
              "      <td>-7.290569e+02</td>\n",
              "      <td>7.076928e+04</td>\n",
              "      <td>7.712062e+03</td>\n",
              "      <td>11.748036</td>\n",
              "      <td>1528.642275</td>\n",
              "      <td>251.232699</td>\n",
              "      <td>481.683733</td>\n",
              "      <td>9.575668e+05</td>\n",
              "      <td>0.057278</td>\n",
              "      <td>0.036115</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>0.348620</td>\n",
              "      <td>0.350392</td>\n",
              "      <td>0.068335</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>0.000175</td>\n",
              "      <td>0.662680</td>\n",
              "      <td>277.964550</td>\n",
              "      <td>48.088141</td>\n",
              "      <td>489.581182</td>\n",
              "      <td>6.393341</td>\n",
              "      <td>425.507547</td>\n",
              "      <td>6.290955</td>\n",
              "      <td>9.615250e+03</td>\n",
              "      <td>7121.997130</td>\n",
              "      <td>1479.610888</td>\n",
              "      <td>3.475565</td>\n",
              "      <td>-4.185286e+02</td>\n",
              "      <td>8.921930e+04</td>\n",
              "      <td>3.533351e+04</td>\n",
              "      <td>1.448189e+05</td>\n",
              "      <td>6.831514e+04</td>\n",
              "      <td>1.412079e+07</td>\n",
              "      <td>8.001563e+05</td>\n",
              "      <td>1.473072e+07</td>\n",
              "      <td>1.352238e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>25.759133</td>\n",
              "      <td>40.995800</td>\n",
              "      <td>44.175627</td>\n",
              "      <td>39.217990</td>\n",
              "      <td>25.916640</td>\n",
              "      <td>41.132627</td>\n",
              "      <td>40.537490</td>\n",
              "      <td>19694.805338</td>\n",
              "      <td>16123.793596</td>\n",
              "      <td>4.737968</td>\n",
              "      <td>3.724073e+07</td>\n",
              "      <td>364.106378</td>\n",
              "      <td>421.965728</td>\n",
              "      <td>3858.850242</td>\n",
              "      <td>1.454190e+06</td>\n",
              "      <td>618.937180</td>\n",
              "      <td>55.371692</td>\n",
              "      <td>158.738971</td>\n",
              "      <td>238.828812</td>\n",
              "      <td>2667.682650</td>\n",
              "      <td>62.105876</td>\n",
              "      <td>817.093491</td>\n",
              "      <td>1174.621985</td>\n",
              "      <td>2.348509e+07</td>\n",
              "      <td>2.727351e+05</td>\n",
              "      <td>4.872676e+06</td>\n",
              "      <td>9.915489e+06</td>\n",
              "      <td>3.202428e+07</td>\n",
              "      <td>3.155030e+06</td>\n",
              "      <td>3.721579e+07</td>\n",
              "      <td>9.783012e+06</td>\n",
              "      <td>1.309209e+07</td>\n",
              "      <td>3.209203e+07</td>\n",
              "      <td>8.108421e+06</td>\n",
              "      <td>2.836729e+07</td>\n",
              "      <td>8.531263e+06</td>\n",
              "      <td>8.212071e+06</td>\n",
              "      <td>2.070359e+07</td>\n",
              "      <td>7.526471e+06</td>\n",
              "      <td>0.186576</td>\n",
              "      <td>0.009772</td>\n",
              "      <td>3.865090e+05</td>\n",
              "      <td>3.865304e+05</td>\n",
              "      <td>2.665324e+05</td>\n",
              "      <td>3.733633e+04</td>\n",
              "      <td>23.000785</td>\n",
              "      <td>2699.393195</td>\n",
              "      <td>394.531874</td>\n",
              "      <td>851.827223</td>\n",
              "      <td>2.321479e+06</td>\n",
              "      <td>0.232374</td>\n",
              "      <td>0.186576</td>\n",
              "      <td>0.012824</td>\n",
              "      <td>0.476535</td>\n",
              "      <td>0.477094</td>\n",
              "      <td>0.252321</td>\n",
              "      <td>0.009772</td>\n",
              "      <td>0.013231</td>\n",
              "      <td>0.648263</td>\n",
              "      <td>432.349886</td>\n",
              "      <td>158.738971</td>\n",
              "      <td>817.093491</td>\n",
              "      <td>364.106378</td>\n",
              "      <td>3858.850242</td>\n",
              "      <td>421.965728</td>\n",
              "      <td>1.454292e+06</td>\n",
              "      <td>13565.260196</td>\n",
              "      <td>7247.906478</td>\n",
              "      <td>355.424245</td>\n",
              "      <td>1.932191e+05</td>\n",
              "      <td>6.619472e+05</td>\n",
              "      <td>3.716482e+05</td>\n",
              "      <td>9.742883e+05</td>\n",
              "      <td>5.992893e+05</td>\n",
              "      <td>3.123964e+07</td>\n",
              "      <td>5.987927e+06</td>\n",
              "      <td>3.206597e+07</td>\n",
              "      <td>3.101737e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.000000e+00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.200000e+07</td>\n",
              "      <td>-2.000000e+06</td>\n",
              "      <td>-2.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-2.000000e+00</td>\n",
              "      <td>-1.400000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.677705e+08</td>\n",
              "      <td>-1.677705e+08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-8.388531e+07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>35960.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>8.100000e+01</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.187398e+02</td>\n",
              "      <td>1.091799e+00</td>\n",
              "      <td>6.000000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>7.700000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>7.514426e-01</td>\n",
              "      <td>6.150911e-02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.190890</td>\n",
              "      <td>4.800000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>50181.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.057600e+04</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>1.150000e+02</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.547589e+03</td>\n",
              "      <td>8.879680e+01</td>\n",
              "      <td>1.426800e+04</td>\n",
              "      <td>4.794877e+03</td>\n",
              "      <td>3.180800e+04</td>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>4.900000e+01</td>\n",
              "      <td>4.900000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.900000e+01</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.400000e+01</td>\n",
              "      <td>4.000000e+01</td>\n",
              "      <td>4.670976e+01</td>\n",
              "      <td>1.065553e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>54.666667</td>\n",
              "      <td>21.685248</td>\n",
              "      <td>4.702500e+02</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>70.250000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>65.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.150000e+02</td>\n",
              "      <td>256.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.400000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>57348.000000</td>\n",
              "      <td>443.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.817418e+06</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>311.000000</td>\n",
              "      <td>4.256000e+03</td>\n",
              "      <td>201.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>73.499150</td>\n",
              "      <td>1460.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>454.142512</td>\n",
              "      <td>631.195401</td>\n",
              "      <td>1.355932e+05</td>\n",
              "      <td>2.721088e+04</td>\n",
              "      <td>1.064177e+06</td>\n",
              "      <td>2.267229e+06</td>\n",
              "      <td>5.766194e+06</td>\n",
              "      <td>5.400000e+01</td>\n",
              "      <td>5.912571e+06</td>\n",
              "      <td>1.313678e+06</td>\n",
              "      <td>2.022685e+06</td>\n",
              "      <td>5.549644e+06</td>\n",
              "      <td>4.800000e+01</td>\n",
              "      <td>1.478330e+05</td>\n",
              "      <td>2.953900e+04</td>\n",
              "      <td>4.630722e+04</td>\n",
              "      <td>1.322030e+05</td>\n",
              "      <td>4.600000e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.440000e+02</td>\n",
              "      <td>1.320000e+02</td>\n",
              "      <td>1.395349e+04</td>\n",
              "      <td>8.658009e+03</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1489.000000</td>\n",
              "      <td>284.565336</td>\n",
              "      <td>533.916876</td>\n",
              "      <td>2.850672e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>300.811966</td>\n",
              "      <td>49.000000</td>\n",
              "      <td>454.142512</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>311.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.256000e+03</td>\n",
              "      <td>8192.000000</td>\n",
              "      <td>235.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.281430e+06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.282144e+06</td>\n",
              "      <td>5.158305e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>65533.000000</td>\n",
              "      <td>65524.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.199999e+08</td>\n",
              "      <td>155812.000000</td>\n",
              "      <td>179415.000000</td>\n",
              "      <td>917301.000000</td>\n",
              "      <td>6.270000e+08</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>1983.000000</td>\n",
              "      <td>3917.928571</td>\n",
              "      <td>5796.500690</td>\n",
              "      <td>14480.000000</td>\n",
              "      <td>1702.000000</td>\n",
              "      <td>3927.262213</td>\n",
              "      <td>6715.738331</td>\n",
              "      <td>2.071000e+09</td>\n",
              "      <td>4.000000e+06</td>\n",
              "      <td>1.180000e+08</td>\n",
              "      <td>8.480000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.180000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.340000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>8.270401e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.162564e+06</td>\n",
              "      <td>3.588312e+06</td>\n",
              "      <td>3.000000e+06</td>\n",
              "      <td>2.000000e+06</td>\n",
              "      <td>1359.000000</td>\n",
              "      <td>24820.000000</td>\n",
              "      <td>2119.741935</td>\n",
              "      <td>4731.522394</td>\n",
              "      <td>2.240000e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>2357.000000</td>\n",
              "      <td>3917.928571</td>\n",
              "      <td>3927.262213</td>\n",
              "      <td>155812.000000</td>\n",
              "      <td>917301.000000</td>\n",
              "      <td>179415.000000</td>\n",
              "      <td>6.270406e+08</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>65535.000000</td>\n",
              "      <td>152621.000000</td>\n",
              "      <td>1.380000e+02</td>\n",
              "      <td>1.070000e+08</td>\n",
              "      <td>4.230000e+07</td>\n",
              "      <td>1.070000e+08</td>\n",
              "      <td>1.070000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>7.260000e+07</td>\n",
              "      <td>1.200000e+08</td>\n",
              "      <td>1.200000e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dst sport count  src dport count  ...      Idle Max      Idle Min\n",
              "count    188483.000000    188483.000000  ...  1.884830e+05  1.884830e+05\n",
              "mean          9.625308        37.861701  ...  1.473072e+07  1.352238e+07\n",
              "std          25.759133        40.995800  ...  3.206597e+07  3.101737e+07\n",
              "min           1.000000         1.000000  ...  0.000000e+00  0.000000e+00\n",
              "25%           1.000000         1.000000  ...  0.000000e+00  0.000000e+00\n",
              "50%           1.000000        16.000000  ...  0.000000e+00  0.000000e+00\n",
              "75%           2.000000        95.000000  ...  5.282144e+06  5.158305e+06\n",
              "max         100.000000       100.000000  ...  1.200000e+08  1.200000e+08\n",
              "\n",
              "[8 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0-lHNicZ04Q",
        "outputId": "949aeb2c-f5bb-4718-a8cd-06dd26658fcf"
      },
      "source": [
        "print('Validation set: ')\n",
        "df_val['Label'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation set: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BENIGN                        104952\n",
              "DoS Hulk                       34443\n",
              "PortScan                       23966\n",
              "DDoS                           19164\n",
              "DoS GoldenEye                   1531\n",
              "FTP-Patator                     1136\n",
              "SSH-Patator                      918\n",
              "DoS slowloris                    913\n",
              "DoS Slowhttptest                 838\n",
              "Bot                              275\n",
              "Web Attack � Brute Force         239\n",
              "Web Attack � XSS                  96\n",
              "Infiltration                      10\n",
              "Web Attack � Sql Injection         2\n",
              "Heartbleed                         1\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0O9ZuKoXhv3"
      },
      "source": [
        "## Step 3. Encode Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwXKhZOjXhv3"
      },
      "source": [
        "Encoding the labels, and generate numpy array. Note that the label has not been encoded as one-hot coding. We will use one-hot code later. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyAnny9yZ04R"
      },
      "source": [
        "### Step 3.1 Encoding train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsR6_hJDZ04R"
      },
      "source": [
        "df_label = df_train['Label']\n",
        "data = df_train.drop(columns=['Label'])\n",
        "Xtrain = data.values\n",
        "y_train = encode_label(df_label.values)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XlV2AK3Z04S"
      },
      "source": [
        "### Step 3.2. Encoding test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVSrGExFZ04S",
        "scrolled": true
      },
      "source": [
        "df_label = df_test['Label']\n",
        "data = df_test.drop(columns=['Label'])\n",
        "Xtest = data.values\n",
        "y_test = encode_label(df_label.values)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO3PgredZ04T"
      },
      "source": [
        "### Step 3.3 Encoding validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ2wDKpZZ04T"
      },
      "source": [
        "df_label = df_val['Label']\n",
        "data = df_val.drop(columns=['Label'])\n",
        "Xval = data.values\n",
        "y_val = encode_label(df_label.values)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viMki-R0Z04Q"
      },
      "source": [
        "## Step 4. Normalization or Standardization\n",
        "\n",
        "The continuous feature values are normalized into the same feature space. This is important when using features that have different measurements, and is a general requirement of many machine learning algorithms. We implement the two methods to see the impact on the final classifications. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ERJidxXhv5"
      },
      "source": [
        "## Option 1. Normalization\n",
        "\n",
        "The values of the datasets are normalized using the Min-Max scaling technique, bringing them all within a range of [0,1]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c523vLd-Z04R"
      },
      "source": [
        "### Step 4.1 Normalizing train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5izaj07Z04R"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbYQFmfgZ04S",
        "scrolled": true,
        "outputId": "9c367b0f-6831-4d98-b7e4-065482de3b7f"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_train"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01010101, 1.        , 1.        , ..., 0.68650794, 0.71416667,\n",
              "        0.10166667],\n",
              "       [0.01010101, 0.22222222, 0.12121212, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.01010101, 0.02020202, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.12121212, 0.12121212, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.87878788, 0.87878788, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [1.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ5x1QxAXhv5"
      },
      "source": [
        "### Step 4.2. Normalizing validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-_BpWSsXhv6",
        "outputId": "33b35722-9f82-459e-f53d-d2cbef0687ce"
      },
      "source": [
        "X_val = scaler.fit_transform(Xval)\n",
        "X_val"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.32323232, 0.32323232, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.05050505, 0.05050505, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.02020202, 0.09090909, 0.02020202, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 1.        , 1.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.96969697, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TItkmTF1Z04S"
      },
      "source": [
        "### Step 4.3. Normalizing test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXmp2w2bZ04T",
        "outputId": "49d9cf30-8446-4c0b-fd85-900683b0e7f8"
      },
      "source": [
        "X_test = scaler.fit_transform(Xtest)\n",
        "X_test"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.96969697, 0.96969697, ..., 0.        , 0.71583333,\n",
              "        0.71583333],\n",
              "       [0.        , 0.96969697, 0.96969697, ..., 0.        , 0.6975    ,\n",
              "        0.6975    ],\n",
              "       [0.        , 0.        , 1.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.44444444, 0.08080808, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.78787879, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.28282828, 0.28282828, ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge2XVkhTXhv6"
      },
      "source": [
        "## Option 2. Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu459dh3Xhv7"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOJud1h5Xhv7",
        "outputId": "59487841-36f3-4a81-f28a-b994b7396673"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(Xtrain)\n",
        "X_val = scaler.fit_transform(Xval)\n",
        "X_test = scaler.fit_transform(Xtest)\n",
        "\n",
        "X_train"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.29659729,  1.51710965,  1.13640038, ...,  8.4581104 ,\n",
              "         2.22140524, -0.0393603 ],\n",
              "       [-0.29659729, -0.36301636, -0.83451004, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       [-0.33534125, -0.87577799, -1.06105146, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       ...,\n",
              "       [-0.33534125, -0.60718856, -0.83451004, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       [-0.33534125,  1.224103  ,  0.86455067, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332],\n",
              "       [ 3.50031109, -0.90019522,  1.13640038, ..., -0.13390608,\n",
              "        -0.45746381, -0.43398332]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reoNDQZhZ04T"
      },
      "source": [
        "## Step 5 One-hot encoding for labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So8gvIF8Z04T"
      },
      "source": [
        "y_train, y_test and y_val have to be one-hot-encoded. That means they must have dimension (number_of_samples, 15), where 15 denotes number of classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc97u4oZZ04U"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfeM_ZzsXhv8"
      },
      "source": [
        "Save the labels for AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N0GfC_zXhv8"
      },
      "source": [
        "y_train_ada = y_train\n",
        "y_test_ada = y_test\n",
        "y_val_ada = y_val"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQVqV19KZ04U"
      },
      "source": [
        "y_train = to_categorical(y_train, 15)\n",
        "y_test = to_categorical(y_test, 15)\n",
        "y_val = to_categorical(y_val, 15)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd9_XX_5Xhv8"
      },
      "source": [
        "## Step 6. Define the metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqOSi1KcXhv8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#importing confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUup6sodXhv9"
      },
      "source": [
        "METRICS = [\n",
        "      tf.keras.metrics.TruePositives(name='tp'),\n",
        "      tf.keras.metrics.FalsePositives(name='fp'),\n",
        "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJywwX9iXhv9"
      },
      "source": [
        "#  Model 1: PCA  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTYHuZtxXhv9"
      },
      "source": [
        "X_pca = df_train.drop('Label',axis=1)\n",
        "y_pca = df_train['Label']"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-XWs2_kXhv9"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_pca = scaler.fit_transform(X_pca)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGVxxHw2Xhv9"
      },
      "source": [
        "dfx = pd.DataFrame(data=X_pca,columns=df_train.columns[1:])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "2-gTg4_uXhv-",
        "outputId": "20cb6fc6-2b4e-4595-8fd9-bec6e543c505"
      },
      "source": [
        "dfx.head(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.938079</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>8.178046e-01</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.953868e-05</td>\n",
              "      <td>1.813646e-05</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>0.336096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.530855</td>\n",
              "      <td>0.362854</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>6.815038e-02</td>\n",
              "      <td>0.290094</td>\n",
              "      <td>7.141667e-01</td>\n",
              "      <td>1.166667e-07</td>\n",
              "      <td>8.158333e-01</td>\n",
              "      <td>1.166667e-01</td>\n",
              "      <td>0.381123</td>\n",
              "      <td>7.141667e-01</td>\n",
              "      <td>1.083333e-07</td>\n",
              "      <td>2.384917e-03</td>\n",
              "      <td>5.962292e-04</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>2.317825e-03</td>\n",
              "      <td>1.508333e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>2.717302e-08</td>\n",
              "      <td>2.547471e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.285298</td>\n",
              "      <td>0.375124</td>\n",
              "      <td>1.406381e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.268839</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.530855</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>1.953868e-05</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.813646e-05</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.003510</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.960000e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.960000e-06</td>\n",
              "      <td>9.960000e-06</td>\n",
              "      <td>0.407500</td>\n",
              "      <td>0.686508</td>\n",
              "      <td>0.714167</td>\n",
              "      <td>0.101667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.323232</td>\n",
              "      <td>0.757839</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>1.015983e-03</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>2.396977e-04</td>\n",
              "      <td>5.643706e-07</td>\n",
              "      <td>0.027438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038557</td>\n",
              "      <td>0.058490</td>\n",
              "      <td>0.020085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020649</td>\n",
              "      <td>0.025689</td>\n",
              "      <td>0.005765</td>\n",
              "      <td>0.400011</td>\n",
              "      <td>1.693375e-04</td>\n",
              "      <td>0.000293</td>\n",
              "      <td>5.154583e-04</td>\n",
              "      <td>1.166667e-07</td>\n",
              "      <td>7.597250e-04</td>\n",
              "      <td>3.798625e-04</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>5.154500e-04</td>\n",
              "      <td>2.443750e-04</td>\n",
              "      <td>7.724000e-04</td>\n",
              "      <td>2.574667e-04</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>7.629667e-04</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>8.202302e-06</td>\n",
              "      <td>1.640460e-05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027438</td>\n",
              "      <td>0.044863</td>\n",
              "      <td>0.053490</td>\n",
              "      <td>2.859579e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.044863</td>\n",
              "      <td>0.038557</td>\n",
              "      <td>0.020649</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>2.396977e-04</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>5.643706e-07</td>\n",
              "      <td>0.125015</td>\n",
              "      <td>0.077240</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585859</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.909255</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.564500e-04</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.581897e-05</td>\n",
              "      <td>4.095986e-07</td>\n",
              "      <td>0.001491</td>\n",
              "      <td>0.017918</td>\n",
              "      <td>0.006230</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007539</td>\n",
              "      <td>0.066062</td>\n",
              "      <td>0.029972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005766</td>\n",
              "      <td>0.400026</td>\n",
              "      <td>8.548889e-05</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>2.563917e-04</td>\n",
              "      <td>1.333333e-07</td>\n",
              "      <td>2.500000e-08</td>\n",
              "      <td>2.500000e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.500000e-08</td>\n",
              "      <td>1.250000e-07</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>2.166401e-05</td>\n",
              "      <td>3.249602e-05</td>\n",
              "      <td>0.025552</td>\n",
              "      <td>0.005278</td>\n",
              "      <td>0.025548</td>\n",
              "      <td>0.010881</td>\n",
              "      <td>1.183393e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.027943</td>\n",
              "      <td>0.006230</td>\n",
              "      <td>0.029972</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>2.581897e-05</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>4.095986e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.776971</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.403390</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>1.091667e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.999999e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>2.824859e-03</td>\n",
              "      <td>4.237288e-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.013824</td>\n",
              "      <td>0.003510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.854337</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.408511</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>4.999999e-07</td>\n",
              "      <td>3.916667e-07</td>\n",
              "      <td>3.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.916667e-07</td>\n",
              "      <td>4.916666e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>1.418440e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003967</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.537087</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>5.259139e-01</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>8.750001e-02</td>\n",
              "      <td>0.140330</td>\n",
              "      <td>2.675000e-01</td>\n",
              "      <td>8.318082e-03</td>\n",
              "      <td>5.258333e-01</td>\n",
              "      <td>8.750000e-02</td>\n",
              "      <td>0.142174</td>\n",
              "      <td>2.675000e-01</td>\n",
              "      <td>8.318074e-03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995719</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>3.697268e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.445572</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.014080e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.014080e-02</td>\n",
              "      <td>7.014080e-02</td>\n",
              "      <td>0.155833</td>\n",
              "      <td>0.161376</td>\n",
              "      <td>0.267500</td>\n",
              "      <td>0.066799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.989899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.989899</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.989899</td>\n",
              "      <td>0.989899</td>\n",
              "      <td>0.989899</td>\n",
              "      <td>0.842161</td>\n",
              "      <td>0.050722</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>4.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>6.978099e-07</td>\n",
              "      <td>9.380121e-09</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000969</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000345</td>\n",
              "      <td>0.003026</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005827</td>\n",
              "      <td>0.406897</td>\n",
              "      <td>4.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.916667e-07</td>\n",
              "      <td>5.916666e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.999999e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>5.747126e-03</td>\n",
              "      <td>8.620690e-03</td>\n",
              "      <td>0.001381</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.001142</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>2.380952e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.001498</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.978099e-07</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>9.380121e-09</td>\n",
              "      <td>0.015640</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.879652</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>8.218116e-01</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.189766e-04</td>\n",
              "      <td>1.812708e-05</td>\n",
              "      <td>0.013739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009569</td>\n",
              "      <td>0.020801</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.530580</td>\n",
              "      <td>0.541087</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>8.218117e-02</td>\n",
              "      <td>0.367925</td>\n",
              "      <td>8.216667e-01</td>\n",
              "      <td>1.166667e-07</td>\n",
              "      <td>8.216667e-01</td>\n",
              "      <td>1.641667e-01</td>\n",
              "      <td>0.526882</td>\n",
              "      <td>8.216667e-01</td>\n",
              "      <td>1.083333e-07</td>\n",
              "      <td>3.930917e-04</td>\n",
              "      <td>9.827292e-05</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>2.981500e-04</td>\n",
              "      <td>1.516667e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>2.028040e-08</td>\n",
              "      <td>2.535050e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.350040</td>\n",
              "      <td>0.340639</td>\n",
              "      <td>0.525291</td>\n",
              "      <td>2.757738e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.325156</td>\n",
              "      <td>0.009569</td>\n",
              "      <td>0.530580</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>1.189766e-04</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.812708e-05</td>\n",
              "      <td>0.003845</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.000000e-08</td>\n",
              "      <td>5.000000e-08</td>\n",
              "      <td>0.821667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.821667</td>\n",
              "      <td>0.821667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.939394</td>\n",
              "      <td>0.720714</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>1.092667e-04</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>4.186860e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.002906</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.400061</td>\n",
              "      <td>3.642778e-05</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>1.052250e-04</td>\n",
              "      <td>3.500000e-07</td>\n",
              "      <td>4.041667e-06</td>\n",
              "      <td>4.041667e-06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.041667e-06</td>\n",
              "      <td>4.141666e-06</td>\n",
              "      <td>1.090167e-04</td>\n",
              "      <td>1.090167e-04</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.090167e-04</td>\n",
              "      <td>1.090167e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>5.084789e-05</td>\n",
              "      <td>7.627183e-05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.001233</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>4.821429e-07</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.001348</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>4.186860e-06</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.181818</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.821530</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>5.015780e-01</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>2.093430e-04</td>\n",
              "      <td>7.871485e-06</td>\n",
              "      <td>0.009146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009184</td>\n",
              "      <td>0.012029</td>\n",
              "      <td>0.092829</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.082285</td>\n",
              "      <td>0.093520</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>2.089909e-02</td>\n",
              "      <td>0.139151</td>\n",
              "      <td>4.825000e-01</td>\n",
              "      <td>1.166667e-07</td>\n",
              "      <td>4.866667e-01</td>\n",
              "      <td>4.870064e-02</td>\n",
              "      <td>0.218638</td>\n",
              "      <td>4.825000e-01</td>\n",
              "      <td>1.766666e-06</td>\n",
              "      <td>5.016667e-01</td>\n",
              "      <td>3.856817e-02</td>\n",
              "      <td>0.193991</td>\n",
              "      <td>4.841667e-01</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>6.091886e-08</td>\n",
              "      <td>1.162996e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064988</td>\n",
              "      <td>0.074223</td>\n",
              "      <td>0.101930</td>\n",
              "      <td>1.038387e-02</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.067543</td>\n",
              "      <td>0.009184</td>\n",
              "      <td>0.082285</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>2.093430e-04</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>7.871485e-06</td>\n",
              "      <td>0.125015</td>\n",
              "      <td>0.004440</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.864490e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.864490e-03</td>\n",
              "      <td>2.864490e-03</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.482500</td>\n",
              "      <td>0.482500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   src dport count  dst src count  dport count  ...  Idle Max  Idle Min     Label\n",
              "0         0.010101       1.000000     1.000000  ...  0.686508  0.714167  0.101667\n",
              "1         0.010101       0.222222     0.121212  ...  0.000000  0.000000  0.000000\n",
              "2         0.000000       0.010101     0.020202  ...  0.000000  0.000000  0.000000\n",
              "3         0.010101       0.000000     0.010101  ...  0.000000  0.000000  0.000000\n",
              "4         0.010101       0.030303     0.010101  ...  0.000000  0.000000  0.000000\n",
              "5         0.000000       1.000000     1.000000  ...  0.161376  0.267500  0.066799\n",
              "6         0.989899       0.000000     0.989899  ...  0.000000  0.000000  0.000000\n",
              "7         0.000000       0.969697     0.969697  ...  0.000000  0.821667  0.821667\n",
              "8         0.010101       0.939394     0.939394  ...  0.000000  0.000000  0.000000\n",
              "9         0.010101       0.070707     0.010101  ...  0.000000  0.482500  0.482500\n",
              "\n",
              "[10 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzLYPxy-Xhv-"
      },
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIE01O4yXhv-"
      },
      "source": [
        "pca = PCA(n_components=None)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd2crc5zXhv-"
      },
      "source": [
        "dfx_pca = pca.fit(dfx)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wPwtI_6RXhv-",
        "outputId": "d82172f4-9a70-4ec6-eb0e-c2cb6ea6ad80"
      },
      "source": [
        "plt.figure(figsize=(24,5))\n",
        "plt.scatter(x=[i+1 for i in range(len(dfx_pca.explained_variance_ratio_))],\n",
        "            y=dfx_pca.explained_variance_ratio_,\n",
        "           s=200, alpha=0.75,c='orange',edgecolor='k')\n",
        "plt.grid(True)\n",
        "plt.title(\"Explained variance ratio of the \\nfitted principal component vector\\n\",fontsize=25)\n",
        "plt.xlabel(\"Principal components\",fontsize=15)\n",
        "plt.xticks([i+1 for i in range(len(dfx_pca.explained_variance_ratio_))],fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.ylabel(\"Explained variance ratio\",fontsize=15)\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1728x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeVjWmuZXhv_"
      },
      "source": [
        "The above two plots means that the $1^{st}$ principal component explains about 38% of the total variance in the data and the $2^{nd}$ component explians further 20%. Therefore, if we just consider first two components, they together explain 58% of the total variance. Using the first 10 features should give very hight detection rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8xM86XhXhv_"
      },
      "source": [
        "Transform the scaled data set using the fitted PCA object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srySEJvRXhv_"
      },
      "source": [
        "dfx_trans = pca.transform(dfx)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COMFpsuyXhv_"
      },
      "source": [
        "Put it in a data frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "rtptL8AMXhwA",
        "scrolled": true,
        "outputId": "3f9b5e00-5cc6-46b5-d984-24700a85b1d2"
      },
      "source": [
        "dfx_trans = pd.DataFrame(data=dfx_trans)\n",
        "dfx_trans.head(10)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.000408</td>\n",
              "      <td>0.456157</td>\n",
              "      <td>-0.193931</td>\n",
              "      <td>0.123428</td>\n",
              "      <td>-0.164004</td>\n",
              "      <td>-0.145284</td>\n",
              "      <td>-0.474488</td>\n",
              "      <td>-0.051236</td>\n",
              "      <td>0.117817</td>\n",
              "      <td>-0.036944</td>\n",
              "      <td>0.124120</td>\n",
              "      <td>0.315620</td>\n",
              "      <td>-0.097011</td>\n",
              "      <td>0.050066</td>\n",
              "      <td>-0.190276</td>\n",
              "      <td>0.108648</td>\n",
              "      <td>0.550164</td>\n",
              "      <td>0.112007</td>\n",
              "      <td>0.483786</td>\n",
              "      <td>0.072881</td>\n",
              "      <td>-0.023484</td>\n",
              "      <td>0.025039</td>\n",
              "      <td>-0.156377</td>\n",
              "      <td>0.011712</td>\n",
              "      <td>-0.005523</td>\n",
              "      <td>-0.008902</td>\n",
              "      <td>-0.001733</td>\n",
              "      <td>-0.011331</td>\n",
              "      <td>-0.008608</td>\n",
              "      <td>-0.021437</td>\n",
              "      <td>-0.022180</td>\n",
              "      <td>0.004493</td>\n",
              "      <td>0.002954</td>\n",
              "      <td>0.001991</td>\n",
              "      <td>-0.003361</td>\n",
              "      <td>0.001716</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>-0.002374</td>\n",
              "      <td>0.017730</td>\n",
              "      <td>-0.012738</td>\n",
              "      <td>-0.001900</td>\n",
              "      <td>0.002569</td>\n",
              "      <td>0.005968</td>\n",
              "      <td>-0.005596</td>\n",
              "      <td>-0.006042</td>\n",
              "      <td>0.002670</td>\n",
              "      <td>-0.006021</td>\n",
              "      <td>0.002297</td>\n",
              "      <td>-0.004915</td>\n",
              "      <td>-0.008482</td>\n",
              "      <td>0.002636</td>\n",
              "      <td>0.004319</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>-0.002568</td>\n",
              "      <td>0.003404</td>\n",
              "      <td>-0.000737</td>\n",
              "      <td>0.004008</td>\n",
              "      <td>-0.000079</td>\n",
              "      <td>-0.000031</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>-0.000847</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>-9.287958e-05</td>\n",
              "      <td>-0.001196</td>\n",
              "      <td>-0.000172</td>\n",
              "      <td>-2.666377e-07</td>\n",
              "      <td>1.876301e-06</td>\n",
              "      <td>2.866554e-05</td>\n",
              "      <td>-1.374226e-06</td>\n",
              "      <td>-5.330733e-08</td>\n",
              "      <td>-1.340074e-14</td>\n",
              "      <td>7.924770e-18</td>\n",
              "      <td>-1.821750e-16</td>\n",
              "      <td>7.865599e-17</td>\n",
              "      <td>2.879049e-17</td>\n",
              "      <td>-1.949659e-17</td>\n",
              "      <td>3.082198e-17</td>\n",
              "      <td>-7.641116e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.758438</td>\n",
              "      <td>-0.286833</td>\n",
              "      <td>0.531995</td>\n",
              "      <td>-0.055525</td>\n",
              "      <td>-0.372602</td>\n",
              "      <td>-0.161333</td>\n",
              "      <td>-0.027339</td>\n",
              "      <td>-0.036354</td>\n",
              "      <td>0.034841</td>\n",
              "      <td>0.089133</td>\n",
              "      <td>-0.168739</td>\n",
              "      <td>-0.175130</td>\n",
              "      <td>-0.006920</td>\n",
              "      <td>0.028832</td>\n",
              "      <td>0.009434</td>\n",
              "      <td>-0.250778</td>\n",
              "      <td>-0.014791</td>\n",
              "      <td>0.018521</td>\n",
              "      <td>0.102688</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>-0.045560</td>\n",
              "      <td>0.042128</td>\n",
              "      <td>0.078331</td>\n",
              "      <td>-0.055687</td>\n",
              "      <td>-0.025772</td>\n",
              "      <td>-0.022669</td>\n",
              "      <td>0.003055</td>\n",
              "      <td>-0.012343</td>\n",
              "      <td>0.008025</td>\n",
              "      <td>-0.006138</td>\n",
              "      <td>-0.009338</td>\n",
              "      <td>-0.004617</td>\n",
              "      <td>-0.002291</td>\n",
              "      <td>0.002559</td>\n",
              "      <td>-0.000371</td>\n",
              "      <td>0.003729</td>\n",
              "      <td>-0.004520</td>\n",
              "      <td>0.021719</td>\n",
              "      <td>-0.010093</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>-0.000744</td>\n",
              "      <td>-0.013623</td>\n",
              "      <td>0.005775</td>\n",
              "      <td>0.007258</td>\n",
              "      <td>0.001160</td>\n",
              "      <td>0.003248</td>\n",
              "      <td>-0.007089</td>\n",
              "      <td>0.003018</td>\n",
              "      <td>-0.000076</td>\n",
              "      <td>-0.007684</td>\n",
              "      <td>-0.011160</td>\n",
              "      <td>0.001841</td>\n",
              "      <td>-0.002550</td>\n",
              "      <td>-0.001739</td>\n",
              "      <td>-0.001598</td>\n",
              "      <td>0.001802</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.000029</td>\n",
              "      <td>0.000037</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>1.061504e-04</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>2.535008e-06</td>\n",
              "      <td>3.381653e-06</td>\n",
              "      <td>1.600827e-05</td>\n",
              "      <td>-6.671434e-07</td>\n",
              "      <td>-4.225529e-09</td>\n",
              "      <td>1.336913e-14</td>\n",
              "      <td>1.554691e-17</td>\n",
              "      <td>5.380169e-17</td>\n",
              "      <td>-5.182148e-17</td>\n",
              "      <td>-1.393769e-17</td>\n",
              "      <td>1.937620e-17</td>\n",
              "      <td>8.659651e-17</td>\n",
              "      <td>5.998579e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.705317</td>\n",
              "      <td>0.246329</td>\n",
              "      <td>0.110341</td>\n",
              "      <td>-0.711713</td>\n",
              "      <td>0.381522</td>\n",
              "      <td>0.122896</td>\n",
              "      <td>-0.235481</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>-0.037500</td>\n",
              "      <td>-0.003030</td>\n",
              "      <td>0.105523</td>\n",
              "      <td>0.148764</td>\n",
              "      <td>0.205875</td>\n",
              "      <td>-0.113824</td>\n",
              "      <td>-0.059042</td>\n",
              "      <td>-0.067677</td>\n",
              "      <td>-0.030813</td>\n",
              "      <td>0.036519</td>\n",
              "      <td>0.005807</td>\n",
              "      <td>-0.013207</td>\n",
              "      <td>0.130793</td>\n",
              "      <td>0.013535</td>\n",
              "      <td>-0.027019</td>\n",
              "      <td>-0.046712</td>\n",
              "      <td>-0.007212</td>\n",
              "      <td>0.002803</td>\n",
              "      <td>-0.001043</td>\n",
              "      <td>0.002211</td>\n",
              "      <td>-0.000531</td>\n",
              "      <td>-0.000670</td>\n",
              "      <td>-0.001004</td>\n",
              "      <td>-0.000618</td>\n",
              "      <td>0.004156</td>\n",
              "      <td>-0.003454</td>\n",
              "      <td>0.005413</td>\n",
              "      <td>-0.000653</td>\n",
              "      <td>0.003335</td>\n",
              "      <td>0.003948</td>\n",
              "      <td>-0.001197</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>-0.001182</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>-0.002296</td>\n",
              "      <td>0.000748</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>-0.000443</td>\n",
              "      <td>-0.000510</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>-0.000097</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>-0.000170</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>0.000235</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>-0.000013</td>\n",
              "      <td>-0.000044</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>-0.000002</td>\n",
              "      <td>-1.493894e-05</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>3.370267e-07</td>\n",
              "      <td>6.703074e-07</td>\n",
              "      <td>-7.556229e-07</td>\n",
              "      <td>-3.937491e-08</td>\n",
              "      <td>8.076255e-10</td>\n",
              "      <td>1.965755e-16</td>\n",
              "      <td>1.244710e-18</td>\n",
              "      <td>1.027711e-16</td>\n",
              "      <td>-4.379671e-17</td>\n",
              "      <td>-1.937365e-18</td>\n",
              "      <td>-5.589524e-18</td>\n",
              "      <td>-5.663658e-17</td>\n",
              "      <td>1.372642e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.097000</td>\n",
              "      <td>1.026849</td>\n",
              "      <td>-0.466014</td>\n",
              "      <td>0.769796</td>\n",
              "      <td>-0.284325</td>\n",
              "      <td>0.443920</td>\n",
              "      <td>0.231653</td>\n",
              "      <td>-0.427328</td>\n",
              "      <td>0.016124</td>\n",
              "      <td>0.081095</td>\n",
              "      <td>0.301759</td>\n",
              "      <td>-0.064301</td>\n",
              "      <td>-0.027400</td>\n",
              "      <td>0.060609</td>\n",
              "      <td>-0.050881</td>\n",
              "      <td>-0.101476</td>\n",
              "      <td>-0.023151</td>\n",
              "      <td>-0.137598</td>\n",
              "      <td>0.056145</td>\n",
              "      <td>-0.035790</td>\n",
              "      <td>-0.008768</td>\n",
              "      <td>-0.045601</td>\n",
              "      <td>-0.001778</td>\n",
              "      <td>0.014292</td>\n",
              "      <td>-0.005594</td>\n",
              "      <td>0.001618</td>\n",
              "      <td>-0.005491</td>\n",
              "      <td>-0.001541</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>-0.002835</td>\n",
              "      <td>-0.001738</td>\n",
              "      <td>-0.031204</td>\n",
              "      <td>-0.005182</td>\n",
              "      <td>0.002629</td>\n",
              "      <td>-0.000094</td>\n",
              "      <td>-0.001397</td>\n",
              "      <td>-0.011319</td>\n",
              "      <td>0.002979</td>\n",
              "      <td>0.000222</td>\n",
              "      <td>-0.001706</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.001041</td>\n",
              "      <td>-0.001235</td>\n",
              "      <td>0.001271</td>\n",
              "      <td>-0.000074</td>\n",
              "      <td>-0.000605</td>\n",
              "      <td>0.000385</td>\n",
              "      <td>0.001514</td>\n",
              "      <td>0.002105</td>\n",
              "      <td>-0.000290</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>-0.000223</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>-0.000052</td>\n",
              "      <td>0.000154</td>\n",
              "      <td>-0.000378</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000149</td>\n",
              "      <td>-0.000031</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>2.275794e-05</td>\n",
              "      <td>-0.000048</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>2.737968e-06</td>\n",
              "      <td>1.159845e-05</td>\n",
              "      <td>3.537904e-06</td>\n",
              "      <td>-1.723659e-06</td>\n",
              "      <td>-1.121113e-08</td>\n",
              "      <td>-8.167227e-16</td>\n",
              "      <td>5.180455e-17</td>\n",
              "      <td>1.022034e-16</td>\n",
              "      <td>-2.658160e-18</td>\n",
              "      <td>3.496821e-17</td>\n",
              "      <td>1.868822e-17</td>\n",
              "      <td>-1.804450e-16</td>\n",
              "      <td>2.060025e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.883575</td>\n",
              "      <td>0.750642</td>\n",
              "      <td>-0.220291</td>\n",
              "      <td>0.089906</td>\n",
              "      <td>-0.137388</td>\n",
              "      <td>-0.354584</td>\n",
              "      <td>-0.244610</td>\n",
              "      <td>-0.044015</td>\n",
              "      <td>0.115940</td>\n",
              "      <td>0.346570</td>\n",
              "      <td>-0.269264</td>\n",
              "      <td>0.251641</td>\n",
              "      <td>-0.017005</td>\n",
              "      <td>-0.096137</td>\n",
              "      <td>0.232606</td>\n",
              "      <td>-0.045314</td>\n",
              "      <td>-0.037130</td>\n",
              "      <td>0.041674</td>\n",
              "      <td>0.029598</td>\n",
              "      <td>-0.079600</td>\n",
              "      <td>-0.071720</td>\n",
              "      <td>0.036267</td>\n",
              "      <td>-0.001167</td>\n",
              "      <td>-0.006967</td>\n",
              "      <td>-0.001204</td>\n",
              "      <td>0.013526</td>\n",
              "      <td>0.002268</td>\n",
              "      <td>0.013734</td>\n",
              "      <td>-0.003108</td>\n",
              "      <td>-0.003876</td>\n",
              "      <td>0.003145</td>\n",
              "      <td>0.002278</td>\n",
              "      <td>-0.010702</td>\n",
              "      <td>0.001501</td>\n",
              "      <td>-0.003494</td>\n",
              "      <td>-0.001884</td>\n",
              "      <td>0.001071</td>\n",
              "      <td>-0.001006</td>\n",
              "      <td>0.003381</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.001113</td>\n",
              "      <td>-0.002917</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>-0.004871</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>-0.000853</td>\n",
              "      <td>0.001666</td>\n",
              "      <td>0.000193</td>\n",
              "      <td>-0.000801</td>\n",
              "      <td>0.001089</td>\n",
              "      <td>-0.000792</td>\n",
              "      <td>-0.000382</td>\n",
              "      <td>-0.000894</td>\n",
              "      <td>-0.000219</td>\n",
              "      <td>-0.000372</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>-0.000136</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>-0.000107</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>-0.000016</td>\n",
              "      <td>8.035994e-07</td>\n",
              "      <td>-0.000051</td>\n",
              "      <td>-0.000059</td>\n",
              "      <td>1.109809e-05</td>\n",
              "      <td>4.916593e-06</td>\n",
              "      <td>6.246139e-06</td>\n",
              "      <td>-7.740305e-07</td>\n",
              "      <td>-4.819689e-08</td>\n",
              "      <td>-4.638772e-15</td>\n",
              "      <td>1.376174e-17</td>\n",
              "      <td>1.493844e-16</td>\n",
              "      <td>-2.132667e-17</td>\n",
              "      <td>6.505406e-18</td>\n",
              "      <td>-1.584292e-18</td>\n",
              "      <td>4.212307e-17</td>\n",
              "      <td>8.283071e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.906004</td>\n",
              "      <td>-0.733026</td>\n",
              "      <td>0.148430</td>\n",
              "      <td>-0.075756</td>\n",
              "      <td>-0.194602</td>\n",
              "      <td>-0.402469</td>\n",
              "      <td>0.332488</td>\n",
              "      <td>-0.172710</td>\n",
              "      <td>-0.098643</td>\n",
              "      <td>-0.521091</td>\n",
              "      <td>0.099618</td>\n",
              "      <td>-0.333205</td>\n",
              "      <td>0.180124</td>\n",
              "      <td>-0.021190</td>\n",
              "      <td>-0.430085</td>\n",
              "      <td>-0.042203</td>\n",
              "      <td>0.276950</td>\n",
              "      <td>-0.122133</td>\n",
              "      <td>0.155934</td>\n",
              "      <td>0.023362</td>\n",
              "      <td>-0.097217</td>\n",
              "      <td>-0.070542</td>\n",
              "      <td>0.125015</td>\n",
              "      <td>-0.061340</td>\n",
              "      <td>0.007793</td>\n",
              "      <td>0.019321</td>\n",
              "      <td>0.011040</td>\n",
              "      <td>0.044168</td>\n",
              "      <td>-0.031216</td>\n",
              "      <td>0.027433</td>\n",
              "      <td>-0.014642</td>\n",
              "      <td>0.010023</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>0.014066</td>\n",
              "      <td>0.006955</td>\n",
              "      <td>-0.031520</td>\n",
              "      <td>0.067692</td>\n",
              "      <td>0.016650</td>\n",
              "      <td>0.061013</td>\n",
              "      <td>0.108993</td>\n",
              "      <td>0.012872</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>0.006336</td>\n",
              "      <td>-0.015623</td>\n",
              "      <td>-0.022526</td>\n",
              "      <td>0.011228</td>\n",
              "      <td>-0.008603</td>\n",
              "      <td>-0.010924</td>\n",
              "      <td>-0.028336</td>\n",
              "      <td>0.011406</td>\n",
              "      <td>-0.007047</td>\n",
              "      <td>-0.012134</td>\n",
              "      <td>-0.003711</td>\n",
              "      <td>0.007950</td>\n",
              "      <td>0.000749</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>-0.000011</td>\n",
              "      <td>-0.000018</td>\n",
              "      <td>0.004028</td>\n",
              "      <td>0.004844</td>\n",
              "      <td>-0.000084</td>\n",
              "      <td>-1.875047e-03</td>\n",
              "      <td>0.001892</td>\n",
              "      <td>-0.000702</td>\n",
              "      <td>3.250905e-05</td>\n",
              "      <td>-1.783376e-05</td>\n",
              "      <td>2.876633e-05</td>\n",
              "      <td>3.172480e-06</td>\n",
              "      <td>-4.236382e-07</td>\n",
              "      <td>5.626355e-16</td>\n",
              "      <td>-4.427582e-17</td>\n",
              "      <td>-1.497967e-16</td>\n",
              "      <td>4.237967e-17</td>\n",
              "      <td>-1.404902e-17</td>\n",
              "      <td>-5.862961e-18</td>\n",
              "      <td>4.593071e-17</td>\n",
              "      <td>-1.468250e-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.269360</td>\n",
              "      <td>-1.427422</td>\n",
              "      <td>-0.022287</td>\n",
              "      <td>0.795755</td>\n",
              "      <td>0.676687</td>\n",
              "      <td>-0.004024</td>\n",
              "      <td>-0.302277</td>\n",
              "      <td>0.108517</td>\n",
              "      <td>0.323924</td>\n",
              "      <td>0.103873</td>\n",
              "      <td>-0.092631</td>\n",
              "      <td>-0.045926</td>\n",
              "      <td>0.030301</td>\n",
              "      <td>-0.057931</td>\n",
              "      <td>0.003269</td>\n",
              "      <td>0.019289</td>\n",
              "      <td>0.006769</td>\n",
              "      <td>0.003090</td>\n",
              "      <td>-0.016583</td>\n",
              "      <td>-0.007482</td>\n",
              "      <td>-0.019938</td>\n",
              "      <td>-0.022593</td>\n",
              "      <td>-0.012416</td>\n",
              "      <td>-0.005646</td>\n",
              "      <td>0.000746</td>\n",
              "      <td>0.002342</td>\n",
              "      <td>-0.002875</td>\n",
              "      <td>0.002046</td>\n",
              "      <td>-0.002247</td>\n",
              "      <td>-0.001114</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>-0.000159</td>\n",
              "      <td>0.003029</td>\n",
              "      <td>-0.004901</td>\n",
              "      <td>-0.000856</td>\n",
              "      <td>-0.001014</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>-0.003070</td>\n",
              "      <td>-0.000250</td>\n",
              "      <td>0.000401</td>\n",
              "      <td>-0.000141</td>\n",
              "      <td>-0.001208</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000441</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>-0.000216</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.000813</td>\n",
              "      <td>0.000198</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>-0.000004</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>-0.000019</td>\n",
              "      <td>-0.000006</td>\n",
              "      <td>-0.000015</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>-1.215735e-05</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>2.306841e-06</td>\n",
              "      <td>-2.065234e-06</td>\n",
              "      <td>1.548875e-06</td>\n",
              "      <td>1.510208e-07</td>\n",
              "      <td>-2.777240e-09</td>\n",
              "      <td>-4.136765e-16</td>\n",
              "      <td>3.709522e-18</td>\n",
              "      <td>-8.421800e-18</td>\n",
              "      <td>-1.062519e-16</td>\n",
              "      <td>5.384828e-18</td>\n",
              "      <td>-1.407710e-17</td>\n",
              "      <td>-3.709330e-17</td>\n",
              "      <td>1.324261e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.363014</td>\n",
              "      <td>0.698347</td>\n",
              "      <td>0.073176</td>\n",
              "      <td>0.274132</td>\n",
              "      <td>-0.132425</td>\n",
              "      <td>0.045027</td>\n",
              "      <td>-0.668782</td>\n",
              "      <td>-0.069744</td>\n",
              "      <td>-0.125251</td>\n",
              "      <td>0.074095</td>\n",
              "      <td>-0.015165</td>\n",
              "      <td>0.039565</td>\n",
              "      <td>-0.038962</td>\n",
              "      <td>0.042716</td>\n",
              "      <td>-0.025120</td>\n",
              "      <td>-0.010657</td>\n",
              "      <td>-0.050406</td>\n",
              "      <td>-0.005320</td>\n",
              "      <td>-0.078858</td>\n",
              "      <td>0.013993</td>\n",
              "      <td>0.036207</td>\n",
              "      <td>-0.046769</td>\n",
              "      <td>0.103983</td>\n",
              "      <td>-0.009584</td>\n",
              "      <td>-0.019586</td>\n",
              "      <td>0.059521</td>\n",
              "      <td>0.012007</td>\n",
              "      <td>-0.016557</td>\n",
              "      <td>0.009020</td>\n",
              "      <td>-0.022936</td>\n",
              "      <td>0.032721</td>\n",
              "      <td>-0.010135</td>\n",
              "      <td>0.002399</td>\n",
              "      <td>-0.008567</td>\n",
              "      <td>0.013699</td>\n",
              "      <td>0.005632</td>\n",
              "      <td>-0.016115</td>\n",
              "      <td>-0.006741</td>\n",
              "      <td>0.007939</td>\n",
              "      <td>0.011853</td>\n",
              "      <td>0.001808</td>\n",
              "      <td>0.007065</td>\n",
              "      <td>-0.003584</td>\n",
              "      <td>-0.001911</td>\n",
              "      <td>-0.002094</td>\n",
              "      <td>0.000825</td>\n",
              "      <td>-0.003243</td>\n",
              "      <td>-0.001390</td>\n",
              "      <td>0.006592</td>\n",
              "      <td>-0.000149</td>\n",
              "      <td>-0.000650</td>\n",
              "      <td>-0.001007</td>\n",
              "      <td>-0.001907</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>-0.000910</td>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.000337</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>-0.002648</td>\n",
              "      <td>-0.000447</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>3.149584e-04</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>-0.000039</td>\n",
              "      <td>-1.643623e-05</td>\n",
              "      <td>1.565507e-06</td>\n",
              "      <td>4.406435e-06</td>\n",
              "      <td>1.740552e-07</td>\n",
              "      <td>-1.592051e-08</td>\n",
              "      <td>4.952606e-15</td>\n",
              "      <td>-3.806585e-17</td>\n",
              "      <td>-9.933668e-17</td>\n",
              "      <td>4.772081e-17</td>\n",
              "      <td>1.358903e-17</td>\n",
              "      <td>-2.476525e-17</td>\n",
              "      <td>1.911723e-17</td>\n",
              "      <td>-4.198538e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.485298</td>\n",
              "      <td>-0.452846</td>\n",
              "      <td>-0.516268</td>\n",
              "      <td>-0.611352</td>\n",
              "      <td>0.314698</td>\n",
              "      <td>0.103022</td>\n",
              "      <td>0.835726</td>\n",
              "      <td>0.060756</td>\n",
              "      <td>0.015481</td>\n",
              "      <td>0.390987</td>\n",
              "      <td>-0.301307</td>\n",
              "      <td>-0.059095</td>\n",
              "      <td>-0.064001</td>\n",
              "      <td>-0.063584</td>\n",
              "      <td>-0.354922</td>\n",
              "      <td>-0.083940</td>\n",
              "      <td>0.293437</td>\n",
              "      <td>-0.151907</td>\n",
              "      <td>-0.135756</td>\n",
              "      <td>-0.139980</td>\n",
              "      <td>0.019655</td>\n",
              "      <td>0.035230</td>\n",
              "      <td>0.059897</td>\n",
              "      <td>-0.009439</td>\n",
              "      <td>-0.064176</td>\n",
              "      <td>-0.057387</td>\n",
              "      <td>-0.006318</td>\n",
              "      <td>0.013059</td>\n",
              "      <td>0.002570</td>\n",
              "      <td>0.004373</td>\n",
              "      <td>-0.017866</td>\n",
              "      <td>-0.002858</td>\n",
              "      <td>-0.000217</td>\n",
              "      <td>0.006319</td>\n",
              "      <td>-0.004676</td>\n",
              "      <td>0.001042</td>\n",
              "      <td>0.008414</td>\n",
              "      <td>0.020366</td>\n",
              "      <td>-0.008274</td>\n",
              "      <td>-0.018523</td>\n",
              "      <td>-0.002926</td>\n",
              "      <td>-0.000737</td>\n",
              "      <td>0.006030</td>\n",
              "      <td>0.009198</td>\n",
              "      <td>0.010084</td>\n",
              "      <td>-0.002369</td>\n",
              "      <td>-0.002307</td>\n",
              "      <td>-0.002068</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.001572</td>\n",
              "      <td>0.000811</td>\n",
              "      <td>-0.000562</td>\n",
              "      <td>0.000766</td>\n",
              "      <td>-0.000708</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>-0.000524</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>-0.000018</td>\n",
              "      <td>-0.000991</td>\n",
              "      <td>-0.000115</td>\n",
              "      <td>-0.000033</td>\n",
              "      <td>3.549956e-04</td>\n",
              "      <td>0.000546</td>\n",
              "      <td>-0.000057</td>\n",
              "      <td>-4.356167e-06</td>\n",
              "      <td>1.234088e-06</td>\n",
              "      <td>1.990480e-06</td>\n",
              "      <td>-2.269772e-07</td>\n",
              "      <td>-7.228749e-09</td>\n",
              "      <td>5.796567e-15</td>\n",
              "      <td>-2.502870e-17</td>\n",
              "      <td>-1.069897e-16</td>\n",
              "      <td>4.620496e-17</td>\n",
              "      <td>-2.095386e-17</td>\n",
              "      <td>-7.428734e-18</td>\n",
              "      <td>1.432901e-16</td>\n",
              "      <td>-7.421773e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.053763</td>\n",
              "      <td>0.431512</td>\n",
              "      <td>1.470356</td>\n",
              "      <td>0.338930</td>\n",
              "      <td>-0.030375</td>\n",
              "      <td>-0.276931</td>\n",
              "      <td>-0.049404</td>\n",
              "      <td>-0.061485</td>\n",
              "      <td>0.025761</td>\n",
              "      <td>0.034717</td>\n",
              "      <td>-0.065724</td>\n",
              "      <td>-0.140164</td>\n",
              "      <td>0.192608</td>\n",
              "      <td>-0.007704</td>\n",
              "      <td>0.167306</td>\n",
              "      <td>-0.288536</td>\n",
              "      <td>-0.261066</td>\n",
              "      <td>0.047316</td>\n",
              "      <td>0.233377</td>\n",
              "      <td>0.059993</td>\n",
              "      <td>-0.116945</td>\n",
              "      <td>-0.079269</td>\n",
              "      <td>0.042427</td>\n",
              "      <td>-0.004294</td>\n",
              "      <td>0.028465</td>\n",
              "      <td>-0.109752</td>\n",
              "      <td>0.022337</td>\n",
              "      <td>0.013891</td>\n",
              "      <td>-0.047396</td>\n",
              "      <td>0.001997</td>\n",
              "      <td>0.037853</td>\n",
              "      <td>0.058525</td>\n",
              "      <td>-0.011176</td>\n",
              "      <td>-0.013955</td>\n",
              "      <td>0.017766</td>\n",
              "      <td>0.006997</td>\n",
              "      <td>-0.035563</td>\n",
              "      <td>0.016486</td>\n",
              "      <td>-0.013138</td>\n",
              "      <td>0.014975</td>\n",
              "      <td>0.001579</td>\n",
              "      <td>-0.009302</td>\n",
              "      <td>-0.000441</td>\n",
              "      <td>-0.007538</td>\n",
              "      <td>-0.004675</td>\n",
              "      <td>0.003696</td>\n",
              "      <td>0.003128</td>\n",
              "      <td>0.000670</td>\n",
              "      <td>-0.001083</td>\n",
              "      <td>-0.004846</td>\n",
              "      <td>0.004904</td>\n",
              "      <td>-0.003757</td>\n",
              "      <td>0.005552</td>\n",
              "      <td>-0.000715</td>\n",
              "      <td>-0.000893</td>\n",
              "      <td>0.000799</td>\n",
              "      <td>-0.001270</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>-0.002537</td>\n",
              "      <td>0.001223</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>-1.302672e-03</td>\n",
              "      <td>0.001071</td>\n",
              "      <td>-0.000046</td>\n",
              "      <td>2.874768e-05</td>\n",
              "      <td>1.920554e-06</td>\n",
              "      <td>-6.106031e-06</td>\n",
              "      <td>6.118902e-07</td>\n",
              "      <td>-7.607018e-08</td>\n",
              "      <td>-1.820610e-14</td>\n",
              "      <td>-9.096018e-18</td>\n",
              "      <td>1.008635e-16</td>\n",
              "      <td>-6.912240e-17</td>\n",
              "      <td>-1.655960e-17</td>\n",
              "      <td>9.001405e-18</td>\n",
              "      <td>1.838770e-16</td>\n",
              "      <td>-6.226768e-16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...            75            76            77\n",
              "0  2.000408  0.456157 -0.193931  ... -1.949659e-17  3.082198e-17 -7.641116e-16\n",
              "1 -0.758438 -0.286833  0.531995  ...  1.937620e-17  8.659651e-17  5.998579e-16\n",
              "2 -0.705317  0.246329  0.110341  ... -5.589524e-18 -5.663658e-17  1.372642e-16\n",
              "3 -1.097000  1.026849 -0.466014  ...  1.868822e-17 -1.804450e-16  2.060025e-16\n",
              "4 -0.883575  0.750642 -0.220291  ... -1.584292e-18  4.212307e-17  8.283071e-17\n",
              "5  0.906004 -0.733026  0.148430  ... -5.862961e-18  4.593071e-17 -1.468250e-15\n",
              "6 -0.269360 -1.427422 -0.022287  ... -1.407710e-17 -3.709330e-17  1.324261e-16\n",
              "7  2.363014  0.698347  0.073176  ... -2.476525e-17  1.911723e-17 -4.198538e-17\n",
              "8  0.485298 -0.452846 -0.516268  ... -7.428734e-18  1.432901e-16 -7.421773e-17\n",
              "9 -0.053763  0.431512  1.470356  ...  9.001405e-18  1.838770e-16 -6.226768e-16\n",
              "\n",
              "[10 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leIDYI_dXhwA"
      },
      "source": [
        "## Training and Making Predictions\n",
        "\n",
        "In this case we'll use random forest classification for making the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swXJ6_ydXhwA"
      },
      "source": [
        "pca = PCA(n_components=12)\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4Yt7PnkXhwA"
      },
      "source": [
        "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "classifier.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test_pca)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7X48ybRXhwA",
        "outputId": "b5b85b59-ff9c-4274-dc9d-39bbf53df1b4"
      },
      "source": [
        "print('Accuracy:%f' %accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:%f\" %metrics.average_precision_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Recall:%f\" %metrics.recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"F1-score:%f\" %metrics.f1_score(y_test, y_pred,average='weighted'))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.724893\n",
            "Precision:0.734083\n",
            "Recall:0.724893\n",
            "F1-score:0.755240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfibn9gAXhwB",
        "scrolled": true,
        "outputId": "be99767f-51c7-4306-cdb3-c104d7f00ce7"
      },
      "source": [
        "#The confusion matrix takes a vector of labels (not the one-hot encoding). \n",
        "\n",
        "\n",
        "cm = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[138946      0      0      0      0      0      0      0      0      0\n",
            "     189      0      0      0      0]\n",
            " [   489      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [ 31990      0      0      0      0      0      0      0      0      0\n",
            "      16      0      0      0      0]\n",
            " [  2573      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [ 57531      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [  1373      0      0      0      0      0      0      0      0      0\n",
            "       1      0      0      0      0]\n",
            " [  1444      0      0      0      0      0      0      0      0      0\n",
            "       5      0      0      0      0]\n",
            " [  1983      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [     2      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [     9      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [  1667      0      0      0      0      0      0      0      0      0\n",
            "   38034      0      0      0      0]\n",
            " [  1474      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [   376      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [     5      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0]\n",
            " [   162      0      0      0      0      0      0      0      0      0\n",
            "       1      0      0      0      0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxRNywIXXhwC"
      },
      "source": [
        "Get the attacks' names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9AlIiTKXhwC"
      },
      "source": [
        "labels_d = make_value2index(df_test['Label'])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1vqAhE1XhwC",
        "outputId": "42aa0ac3-e651-4482-ca2b-aff12d23cfdd"
      },
      "source": [
        "print(labels_d)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'BENIGN': 105018, 'Bot': 105298, 'DDoS': 124569, 'DoS GoldenEye': 126111, 'DoS Hulk': 160658, 'DoS Slowhttptest': 161486, 'DoS slowloris': 162320, 'FTP-Patator': 163498, 'Heartbleed': 163500, 'Infiltration': 163501, 'PortScan': 187347, 'SSH-Patator': 188173, 'Web Attack � Brute Force': 188382, 'Web Attack � Sql Injection': 188389, 'Web Attack � XSS': 188482}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO4EmilxXhwD",
        "outputId": "afce2f53-02f1-46ff-b344-fd79a2c21dbf"
      },
      "source": [
        "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1), target_names=labels_d))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.69      0.99      0.81    105019\n",
            "                       Bot       0.00      0.00      0.00       280\n",
            "                      DDoS       0.00      0.00      0.00     19271\n",
            "             DoS GoldenEye       0.00      0.00      0.00      1542\n",
            "                  DoS Hulk       0.98      0.43      0.59     34547\n",
            "          DoS Slowhttptest       0.00      0.00      0.00       828\n",
            "             DoS slowloris       0.00      0.00      0.00       834\n",
            "               FTP-Patator       0.00      0.00      0.00      1178\n",
            "                Heartbleed       0.00      0.00      0.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.96      0.92      0.94     23846\n",
            "               SSH-Patator       0.00      0.00      0.00       826\n",
            "  Web Attack � Brute Force       0.00      0.00      0.00       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.00      0.00      0.00        93\n",
            "\n",
            "                  accuracy                           0.75    188483\n",
            "                 macro avg       0.18      0.16      0.16    188483\n",
            "              weighted avg       0.69      0.75      0.68    188483\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRtGAy_3gY2n"
      },
      "source": [
        "# Model : Naive Bayes model (GaussianNB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxNz3yQch35o"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Izw8QWLIgcTx",
        "outputId": "7ede9a07-ed9f-429e-b6f2-704eb5dd439c"
      },
      "source": [
        "model_gaussian = GaussianNB()\r\n",
        "model_gaussian.fit(X_train, y_train_ada)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c15lYNIdgs9V"
      },
      "source": [
        "# make predictions\r\n",
        "y_pred = model_gaussian.predict(X_test)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ6JwTSDg6iE",
        "outputId": "9663a9ba-74b7-495f-b8f9-4c0010caf1cb"
      },
      "source": [
        "display_metrics(y_test_ada, y_pred, labels_d)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.56\n",
            "\n",
            "Micro Precision: 0.56\n",
            "Micro Recall: 0.56\n",
            "Micro F1-score: 0.56\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.04\n",
            "Macro Recall: 0.07\n",
            "Macro F1-score: 0.05\n",
            "\n",
            "Weighted Precision: 0.31\n",
            "Weighted Recall: 0.56\n",
            "Weighted F1-score: 0.40\n",
            "\n",
            "Classification Report\n",
            "\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.56      1.00      0.72    105019\n",
            "                       Bot       0.00      0.00      0.00       280\n",
            "                      DDoS       0.00      0.00      0.00     19271\n",
            "             DoS GoldenEye       0.00      0.00      0.00      1542\n",
            "                  DoS Hulk       0.00      0.00      0.00     34547\n",
            "          DoS Slowhttptest       0.00      0.00      0.00       828\n",
            "             DoS slowloris       0.00      0.00      0.00       834\n",
            "               FTP-Patator       0.00      0.00      0.00      1178\n",
            "                Heartbleed       0.00      0.00      0.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.00      0.00      0.00     23846\n",
            "               SSH-Patator       0.00      0.00      0.00       826\n",
            "  Web Attack � Brute Force       0.00      0.00      0.00       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.00      0.00      0.00        93\n",
            "\n",
            "                  accuracy                           0.56    188483\n",
            "                 macro avg       0.04      0.07      0.05    188483\n",
            "              weighted avg       0.31      0.56      0.40    188483\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXea3TMVXhwD"
      },
      "source": [
        "# Model 3: Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOUaeJwiXhwD"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRMY85VyXhwE"
      },
      "source": [
        "model_dec = DecisionTreeClassifier()\n",
        "model_dec.fit(X_train, y_train_ada)\n",
        "y_pred = model_dec.predict(X_test)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFQ6iCJjXhwE",
        "outputId": "550f88b2-dc9a-4234-cbb6-4b20eca16881"
      },
      "source": [
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_ada, y_pred)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_ada, y_pred, average='weighted')))\n",
        " \n",
        "print('\\nClassification Report\\n')\n",
        "\n",
        "print(classification_report(y_test_ada , y_pred, target_names=labels_d))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.99\n",
            "\n",
            "Micro Precision: 0.99\n",
            "Micro Recall: 0.99\n",
            "Micro F1-score: 0.99\n",
            "\n",
            "Macro Precision: 0.85\n",
            "Macro Recall: 0.92\n",
            "Macro F1-score: 0.88\n",
            "\n",
            "Weighted Precision: 0.99\n",
            "Weighted Recall: 0.99\n",
            "Weighted F1-score: 0.99\n",
            "\n",
            "Classification Report\n",
            "\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.99      0.99      0.99    105019\n",
            "                       Bot       0.69      0.96      0.80       280\n",
            "                      DDoS       1.00      0.97      0.99     19271\n",
            "             DoS GoldenEye       0.71      1.00      0.83      1542\n",
            "                  DoS Hulk       1.00      0.98      0.99     34547\n",
            "          DoS Slowhttptest       0.95      0.96      0.95       828\n",
            "             DoS slowloris       0.87      0.88      0.88       834\n",
            "               FTP-Patator       1.00      1.00      1.00      1178\n",
            "                Heartbleed       0.67      1.00      0.80         2\n",
            "              Infiltration       0.50      1.00      0.67         1\n",
            "                  PortScan       0.97      0.99      0.98     23846\n",
            "               SSH-Patator       1.00      1.00      1.00       826\n",
            "  Web Attack � Brute Force       0.90      0.88      0.89       209\n",
            "Web Attack � Sql Injection       0.75      0.43      0.55         7\n",
            "          Web Attack � XSS       0.83      0.83      0.83        93\n",
            "\n",
            "                  accuracy                           0.99    188483\n",
            "                 macro avg       0.85      0.92      0.88    188483\n",
            "              weighted avg       0.99      0.99      0.99    188483\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABYQjuBCXhwE"
      },
      "source": [
        "# Model 4: Random Foresty with DecisionTree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI6QGw9LXhwF"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=10, random_state=10)\n",
        "clf.fit(X_train,y_train)\n",
        "    \n",
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFh6H0d3lNmz",
        "outputId": "47a3e523-9564-4bed-f2fa-d212c07d4abc"
      },
      "source": [
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_ada, np.argmax(y_pred, axis = 1))))\r\n",
        "\r\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_ada, np.argmax(y_pred, axis = 1), average='micro')))\r\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_ada, np.argmax(y_pred, axis = 1), average='micro')))\r\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, np.argmax(y_pred, axis = 1), average='micro')))\r\n",
        "\r\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_ada, np.argmax(y_pred, axis = 1), average='macro')))\r\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_ada, np.argmax(y_pred, axis = 1), average='macro')))\r\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, np.argmax(y_pred, axis = 1), average='macro')))\r\n",
        "\r\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_ada, np.argmax(y_pred, axis = 1), average='weighted')))\r\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_ada, np.argmax(y_pred, axis = 1), average='weighted')))\r\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_ada, np.argmax(y_pred, axis = 1), average='weighted')))\r\n",
        " \r\n",
        "print('\\nClassification Report\\n')\r\n",
        "\r\n",
        "print(classification_report(y_test_ada ,np.argmax(y_pred, axis = 1), target_names=labels_d))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.92\n",
            "\n",
            "Micro Precision: 0.92\n",
            "Micro Recall: 0.92\n",
            "Micro F1-score: 0.92\n",
            "\n",
            "Macro Precision: 0.91\n",
            "Macro Recall: 0.75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.80\n",
            "\n",
            "Weighted Precision: 0.93\n",
            "Weighted Recall: 0.92\n",
            "Weighted F1-score: 0.91\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.88      1.00      0.93    105019\n",
            "                       Bot       0.94      0.18      0.31       280\n",
            "                      DDoS       1.00      0.91      0.95     19271\n",
            "             DoS GoldenEye       1.00      0.92      0.96      1542\n",
            "                  DoS Hulk       1.00      1.00      1.00     34547\n",
            "          DoS Slowhttptest       1.00      0.99      0.99       828\n",
            "             DoS slowloris       1.00      0.90      0.95       834\n",
            "               FTP-Patator       1.00      0.53      0.69      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       1.00      1.00      1.00         1\n",
            "                  PortScan       1.00      0.51      0.68     23846\n",
            "               SSH-Patator       1.00      0.99      1.00       826\n",
            "  Web Attack � Brute Force       0.91      0.75      0.82       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.87      0.56      0.68        93\n",
            "\n",
            "                  accuracy                           0.92    188483\n",
            "                 macro avg       0.91      0.75      0.80    188483\n",
            "              weighted avg       0.93      0.92      0.91    188483\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xi2INVUk9p9"
      },
      "source": [
        "# Model 5: Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_AoQZpOnxuD"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBqJDnChnmxJ"
      },
      "source": [
        "attack_classifier = linear_model.LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\r\n",
        "attack_classifier.fit(X_train, y_train_ada)\r\n",
        "\r\n",
        "y_pred = attack_classifier.predict(X_test)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3x76HdDorw7",
        "outputId": "7d88966a-be59-4e6a-8e36-42de212c9ab0"
      },
      "source": [
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_ada, y_pred)))\r\n",
        "\r\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='micro')))\r\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='micro')))\r\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='micro')))\r\n",
        "\r\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='macro')))\r\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='macro')))\r\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='macro')))\r\n",
        "\r\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='weighted')))\r\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='weighted')))\r\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_ada, y_pred, average='weighted')))\r\n",
        " \r\n",
        "print('\\nClassification Report\\n')\r\n",
        "\r\n",
        "print(classification_report(y_test_ada , y_pred, target_names=labels_d))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.91\n",
            "\n",
            "Micro Precision: 0.91\n",
            "Micro Recall: 0.91\n",
            "Micro F1-score: 0.91\n",
            "\n",
            "Macro Precision: 0.53\n",
            "Macro Recall: 0.90\n",
            "Macro F1-score: 0.58\n",
            "\n",
            "Weighted Precision: 0.96\n",
            "Weighted Recall: 0.91\n",
            "Weighted F1-score: 0.93\n",
            "\n",
            "Classification Report\n",
            "\n",
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       1.00      0.87      0.93    105019\n",
            "                       Bot       0.04      0.96      0.08       280\n",
            "                      DDoS       0.87      0.98      0.92     19271\n",
            "             DoS GoldenEye       0.83      0.97      0.89      1542\n",
            "                  DoS Hulk       0.99      0.92      0.95     34547\n",
            "          DoS Slowhttptest       0.96      0.99      0.97       828\n",
            "             DoS slowloris       0.65      0.96      0.78       834\n",
            "               FTP-Patator       0.85      0.99      0.91      1178\n",
            "                Heartbleed       0.33      1.00      0.50         2\n",
            "              Infiltration       0.00      1.00      0.00         1\n",
            "                  PortScan       0.91      1.00      0.95     23846\n",
            "               SSH-Patator       0.36      0.99      0.53       826\n",
            "  Web Attack � Brute Force       0.12      0.55      0.19       209\n",
            "Web Attack � Sql Injection       0.01      0.71      0.01         7\n",
            "          Web Attack � XSS       0.07      0.68      0.13        93\n",
            "\n",
            "                  accuracy                           0.91    188483\n",
            "                 macro avg       0.53      0.90      0.58    188483\n",
            "              weighted avg       0.96      0.91      0.93    188483\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfXJKq1zXhwF"
      },
      "source": [
        "# Model 6: AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqqrLskIXhwF"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT8egNOEXhwG"
      },
      "source": [
        "model_ada = AdaBoostClassifier(n_estimators=100)\n",
        "model_ada.fit(X_train, y_train_ada)\n",
        "\n",
        "# make predictions\n",
        "expected = y_test_ada\n",
        "predicted = model_ada.predict(X_test)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJCcrCS4XhwG",
        "outputId": "ef24334c-ebd0-4169-b7a1-b8d57c5d80fe"
      },
      "source": [
        "y_pred = predicted\n",
        "\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_ada, y_pred)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_ada, y_pred, average='weighted')))\n",
        " \n",
        "print('\\nClassification Report\\n')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.70\n",
            "\n",
            "Micro Precision: 0.70\n",
            "Micro Recall: 0.70\n",
            "Micro F1-score: 0.70\n",
            "\n",
            "Macro Precision: 0.15\n",
            "Macro Recall: 0.19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.11\n",
            "\n",
            "Weighted Precision: 0.71\n",
            "Weighted Recall: 0.70\n",
            "Weighted F1-score: 0.63\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_lvcZVXXhwG",
        "scrolled": true,
        "outputId": "14e3b3e6-71e7-41eb-8665-feaa44edec25"
      },
      "source": [
        "print(classification_report(y_test_ada, predicted, target_names=labels_d))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.93      0.94      0.94    105019\n",
            "                       Bot       0.00      0.00      0.00       280\n",
            "                      DDoS       0.00      0.00      0.00     19271\n",
            "             DoS GoldenEye       0.00      0.00      0.00      1542\n",
            "                  DoS Hulk       0.41      0.97      0.57     34547\n",
            "          DoS Slowhttptest       0.00      0.00      0.00       828\n",
            "             DoS slowloris       0.00      0.00      0.00       834\n",
            "               FTP-Patator       0.00      0.00      0.00      1178\n",
            "                Heartbleed       0.03      1.00      0.05         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.92      0.01      0.02     23846\n",
            "               SSH-Patator       0.00      0.00      0.00       826\n",
            "  Web Attack � Brute Force       0.00      0.00      0.00       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.00      0.00      0.00        93\n",
            "\n",
            "                  accuracy                           0.70    188483\n",
            "                 macro avg       0.15      0.19      0.11    188483\n",
            "              weighted avg       0.71      0.70      0.63    188483\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn7bQX_Gvusc"
      },
      "source": [
        "# Model 6: XGBClassifier (very slow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ttK187BvuLn"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "53QHIzuAv5z9",
        "outputId": "0e392ce3-2300-4f4f-a1e0-44bdc7723ac0"
      },
      "source": [
        "xgboostc = XGBClassifier(learning_rate = 0.1, max_depth = 5,n_estimators = 1165, subsample=0.8,colsample_bytree=0.8,seed=27)\r\n",
        "xgboostc.fit(X_train,y_train)\r\n",
        "    \r\n",
        "y_pred = xgboostc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-07eedb02b743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgboostc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1165\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolsample_bytree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgboostc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboostc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz8IN3Jfwav0"
      },
      "source": [
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test_ada, y_pred)))\r\n",
        "\r\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='micro')))\r\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='micro')))\r\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='micro')))\r\n",
        "\r\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='macro')))\r\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='macro')))\r\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test_ada, y_pred, average='macro')))\r\n",
        "\r\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_test_ada, y_pred, average='weighted')))\r\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_test_ada, y_pred, average='weighted')))\r\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_test_ada, y_pred, average='weighted')))\r\n",
        " \r\n",
        "print('\\nClassification Report\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KznBGxa2yiLk"
      },
      "source": [
        "# Model 7: Voting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfa2lmvytnh"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIYUdP7iyuRG",
        "outputId": "a621c6ae-133c-459c-c365-77064a1b89bd"
      },
      "source": [
        "rfc = RandomForestClassifier(n_jobs=-1, n_estimators=35, criterion=\"entropy\")\r\n",
        "ada = AdaBoostClassifier(n_estimators=75, learning_rate=1.5)\r\n",
        "etc = ExtraTreesClassifier(n_jobs=-1, criterion=\"entropy\", n_estimators=5)\r\n",
        "eclf = VotingClassifier(estimators=[('ada', ada), ('rfc', rfc), ('etc', etc)], voting='soft', weights=[2, 1, 3],n_jobs=1)\r\n",
        "eclf.fit(X_train,y_train_ada)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('ada',\n",
              "                              AdaBoostClassifier(algorithm='SAMME.R',\n",
              "                                                 base_estimator=None,\n",
              "                                                 learning_rate=1.5,\n",
              "                                                 n_estimators=75,\n",
              "                                                 random_state=None)),\n",
              "                             ('rfc',\n",
              "                              RandomForestClassifier(bootstrap=True,\n",
              "                                                     ccp_alpha=0.0,\n",
              "                                                     class_weight=None,\n",
              "                                                     criterion='entropy',\n",
              "                                                     max_depth=None,\n",
              "                                                     max_features='auto',\n",
              "                                                     max_leaf_nodes=None,\n",
              "                                                     max_samples=None,\n",
              "                                                     min_impurity_decrease=0.0,\n",
              "                                                     min_im...\n",
              "                                                   criterion='entropy',\n",
              "                                                   max_depth=None,\n",
              "                                                   max_features='auto',\n",
              "                                                   max_leaf_nodes=None,\n",
              "                                                   max_samples=None,\n",
              "                                                   min_impurity_decrease=0.0,\n",
              "                                                   min_impurity_split=None,\n",
              "                                                   min_samples_leaf=1,\n",
              "                                                   min_samples_split=2,\n",
              "                                                   min_weight_fraction_leaf=0.0,\n",
              "                                                   n_estimators=5, n_jobs=-1,\n",
              "                                                   oob_score=False,\n",
              "                                                   random_state=None, verbose=0,\n",
              "                                                   warm_start=False))],\n",
              "                 flatten_transform=True, n_jobs=1, voting='soft',\n",
              "                 weights=[2, 1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rig3c_bqzpim"
      },
      "source": [
        "y_pred = eclf.predict(X_test)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuI-C6lZzqeV",
        "outputId": "d385a06a-b6b1-4a2a-aa9f-a74fca9a8276"
      },
      "source": [
        "display_metrics(y_test_ada, y_pred,labels_d)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 1.00\n",
            "\n",
            "Micro Precision: 1.00\n",
            "Micro Recall: 1.00\n",
            "Micro F1-score: 1.00\n",
            "\n",
            "Macro Precision: 0.87\n",
            "Macro Recall: 0.76\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.80\n",
            "\n",
            "Weighted Precision: 1.00\n",
            "Weighted Recall: 1.00\n",
            "Weighted F1-score: 1.00\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.99      1.00      1.00    105019\n",
            "                       Bot       0.97      0.34      0.51       280\n",
            "                      DDoS       1.00      1.00      1.00     19271\n",
            "             DoS GoldenEye       1.00      1.00      1.00      1542\n",
            "                  DoS Hulk       1.00      1.00      1.00     34547\n",
            "          DoS Slowhttptest       0.99      0.99      0.99       828\n",
            "             DoS slowloris       1.00      0.98      0.99       834\n",
            "               FTP-Patator       1.00      0.88      0.94      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       1.00      0.99      0.99     23846\n",
            "               SSH-Patator       1.00      0.97      0.99       826\n",
            "  Web Attack � Brute Force       0.86      0.59      0.70       209\n",
            "Web Attack � Sql Injection       0.50      0.14      0.22         7\n",
            "          Web Attack � XSS       0.78      0.54      0.64        93\n",
            "\n",
            "                  accuracy                           1.00    188483\n",
            "                 macro avg       0.87      0.76      0.80    188483\n",
            "              weighted avg       1.00      1.00      1.00    188483\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAuDnGKYXhwH"
      },
      "source": [
        "# Model 8: KNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7fba3ZuXhwH"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgx8g7vuXhwH"
      },
      "source": [
        "features_order = ['dst sport count', 'src dport count', 'dst src count', 'dport count', 'sport count', 'dst host count','src host count', 'Source Port', 'Destination Port',\n",
        "                      'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets',\n",
        "                      'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
        "                      'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std',\n",
        "                      'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total',\n",
        "                      'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
        "                      'Bwd IAT Min', 'Fwd PSH Flags', 'Fwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\n",
        "                      'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std',\n",
        "                      'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count',\n",
        "                      'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size',\n",
        "                      'Avg Bwd Segment Size','Subflow Fwd Packets', 'Subflow Fwd Bytes',\n",
        "                      'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward',\n",
        "                      'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean',\n",
        "                      'Idle Std', 'Idle Max', 'Idle Min']"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyhoOfFgXhwH"
      },
      "source": [
        "features=['dst sport count', 'src dport count', 'dst src count', 'dport count', 'sport count', 'dst host count','src host count', \"Fwd Packet Length Max\",\"Flow IAT Std\",\"Fwd Packet Length Std\" ,\"Fwd IAT Total\",'Flow Packets/s', \"Fwd Packet Length Mean\",  \"Flow Bytes/s\",  \"Flow IAT Mean\", \"Bwd Packet Length Mean\",  \"Flow IAT Max\", \"Bwd Packet Length Std\", ]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "GlhN1BDdXhwI",
        "outputId": "00e22cb8-fa9e-41ac-963a-bc064db727c8"
      },
      "source": [
        "df_knn_train = pd.DataFrame(X_train, columns = features_order)\n",
        "df_knn_train.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.938079</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>8.178046e-01</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>1.813646e-05</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>0.336096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.530855</td>\n",
              "      <td>0.362854</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>6.815038e-02</td>\n",
              "      <td>0.290094</td>\n",
              "      <td>7.141667e-01</td>\n",
              "      <td>1.166667e-07</td>\n",
              "      <td>8.158333e-01</td>\n",
              "      <td>1.166667e-01</td>\n",
              "      <td>0.381123</td>\n",
              "      <td>7.141667e-01</td>\n",
              "      <td>1.083333e-07</td>\n",
              "      <td>2.384917e-03</td>\n",
              "      <td>5.962292e-04</td>\n",
              "      <td>0.001660</td>\n",
              "      <td>2.317825e-03</td>\n",
              "      <td>1.508333e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>2.717302e-08</td>\n",
              "      <td>2.547471e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.285298</td>\n",
              "      <td>0.375124</td>\n",
              "      <td>0.140638</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.268839</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.530855</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>1.813646e-05</td>\n",
              "      <td>0.003922</td>\n",
              "      <td>0.00351</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>0.4075</td>\n",
              "      <td>0.686508</td>\n",
              "      <td>0.714167</td>\n",
              "      <td>0.101667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.323232</td>\n",
              "      <td>0.757839</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>1.015983e-03</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>5.643706e-07</td>\n",
              "      <td>0.027438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038557</td>\n",
              "      <td>0.058490</td>\n",
              "      <td>0.020085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020649</td>\n",
              "      <td>0.025689</td>\n",
              "      <td>0.005765</td>\n",
              "      <td>0.400011</td>\n",
              "      <td>1.693375e-04</td>\n",
              "      <td>0.000293</td>\n",
              "      <td>5.154583e-04</td>\n",
              "      <td>1.166667e-07</td>\n",
              "      <td>7.597250e-04</td>\n",
              "      <td>3.798625e-04</td>\n",
              "      <td>0.000275</td>\n",
              "      <td>5.154500e-04</td>\n",
              "      <td>2.443750e-04</td>\n",
              "      <td>7.724000e-04</td>\n",
              "      <td>2.574667e-04</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>7.629667e-04</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>8.202302e-06</td>\n",
              "      <td>1.640460e-05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.027438</td>\n",
              "      <td>0.044863</td>\n",
              "      <td>0.053490</td>\n",
              "      <td>0.002860</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.044863</td>\n",
              "      <td>0.038557</td>\n",
              "      <td>0.020649</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000240</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>5.643706e-07</td>\n",
              "      <td>0.125015</td>\n",
              "      <td>0.07724</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585859</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.909255</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.564500e-04</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>4.095986e-07</td>\n",
              "      <td>0.001491</td>\n",
              "      <td>0.017918</td>\n",
              "      <td>0.006230</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007539</td>\n",
              "      <td>0.066062</td>\n",
              "      <td>0.029972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005766</td>\n",
              "      <td>0.400026</td>\n",
              "      <td>8.548889e-05</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>2.563917e-04</td>\n",
              "      <td>1.333333e-07</td>\n",
              "      <td>2.500000e-08</td>\n",
              "      <td>2.500000e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.500000e-08</td>\n",
              "      <td>1.250000e-07</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>3.333333e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>2.166401e-05</td>\n",
              "      <td>3.249602e-05</td>\n",
              "      <td>0.025552</td>\n",
              "      <td>0.005278</td>\n",
              "      <td>0.025548</td>\n",
              "      <td>0.010881</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.027943</td>\n",
              "      <td>0.006230</td>\n",
              "      <td>0.029972</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>4.095986e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.776971</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.403390</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>1.091667e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>9.999999e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>2.824859e-03</td>\n",
              "      <td>4.237288e-03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.013824</td>\n",
              "      <td>0.00351</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.854337</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.408511</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>4.999999e-07</td>\n",
              "      <td>3.916667e-07</td>\n",
              "      <td>3.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.916667e-07</td>\n",
              "      <td>4.916666e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.995718</td>\n",
              "      <td>0.994635</td>\n",
              "      <td>1.418440e-02</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.003967</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dst sport count  src dport count  ...  Idle Max  Idle Min\n",
              "0         0.010101         1.000000  ...  0.714167  0.101667\n",
              "1         0.010101         0.222222  ...  0.000000  0.000000\n",
              "2         0.000000         0.010101  ...  0.000000  0.000000\n",
              "3         0.010101         0.000000  ...  0.000000  0.000000\n",
              "4         0.010101         0.030303  ...  0.000000  0.000000\n",
              "\n",
              "[5 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eda-FM60XhwI"
      },
      "source": [
        "df_knn_test = pd.DataFrame(X_test, columns = features_order)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "iv6nljzO5_Wd",
        "outputId": "11c42bd0-3009-4658-8c9a-9cedef69525e"
      },
      "source": [
        "df_knn_test.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Source Port</th>\n",
              "      <th>Destination Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Total Fwd Packets</th>\n",
              "      <th>Total Backward Packets</th>\n",
              "      <th>Total Length of Fwd Packets</th>\n",
              "      <th>Total Length of Bwd Packets</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Fwd Packet Length Min</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Bwd Packet Length Max</th>\n",
              "      <th>Bwd Packet Length Min</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Flow IAT Min</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Fwd IAT Mean</th>\n",
              "      <th>Fwd IAT Std</th>\n",
              "      <th>Fwd IAT Max</th>\n",
              "      <th>Fwd IAT Min</th>\n",
              "      <th>Bwd IAT Total</th>\n",
              "      <th>Bwd IAT Mean</th>\n",
              "      <th>Bwd IAT Std</th>\n",
              "      <th>Bwd IAT Max</th>\n",
              "      <th>Bwd IAT Min</th>\n",
              "      <th>Fwd PSH Flags</th>\n",
              "      <th>Fwd URG Flags</th>\n",
              "      <th>Fwd Header Length</th>\n",
              "      <th>Bwd Header Length</th>\n",
              "      <th>Fwd Packets/s</th>\n",
              "      <th>Bwd Packets/s</th>\n",
              "      <th>Min Packet Length</th>\n",
              "      <th>Max Packet Length</th>\n",
              "      <th>Packet Length Mean</th>\n",
              "      <th>Packet Length Std</th>\n",
              "      <th>Packet Length Variance</th>\n",
              "      <th>FIN Flag Count</th>\n",
              "      <th>SYN Flag Count</th>\n",
              "      <th>RST Flag Count</th>\n",
              "      <th>PSH Flag Count</th>\n",
              "      <th>ACK Flag Count</th>\n",
              "      <th>URG Flag Count</th>\n",
              "      <th>CWE Flag Count</th>\n",
              "      <th>ECE Flag Count</th>\n",
              "      <th>Down/Up Ratio</th>\n",
              "      <th>Average Packet Size</th>\n",
              "      <th>Avg Fwd Segment Size</th>\n",
              "      <th>Avg Bwd Segment Size</th>\n",
              "      <th>Subflow Fwd Packets</th>\n",
              "      <th>Subflow Fwd Bytes</th>\n",
              "      <th>Subflow Bwd Packets</th>\n",
              "      <th>Subflow Bwd Bytes</th>\n",
              "      <th>Init_Win_bytes_forward</th>\n",
              "      <th>Init_Win_bytes_backward</th>\n",
              "      <th>act_data_pkt_fwd</th>\n",
              "      <th>min_seg_size_forward</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.664337</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>7.168427e-01</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>1.849282e-05</td>\n",
              "      <td>0.013417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014166</td>\n",
              "      <td>0.023453</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.492073</td>\n",
              "      <td>0.324761</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>6.627202e-02</td>\n",
              "      <td>0.305425</td>\n",
              "      <td>7.158333e-01</td>\n",
              "      <td>1.271186e-07</td>\n",
              "      <td>0.715833</td>\n",
              "      <td>0.143333</td>\n",
              "      <td>0.460432</td>\n",
              "      <td>0.715833</td>\n",
              "      <td>8.333333e-09</td>\n",
              "      <td>0.001270</td>\n",
              "      <td>0.000254</td>\n",
              "      <td>0.000725</td>\n",
              "      <td>0.001143</td>\n",
              "      <td>3.833333e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.981499</td>\n",
              "      <td>0.979061</td>\n",
              "      <td>2.325012e-08</td>\n",
              "      <td>3.487518e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233360</td>\n",
              "      <td>0.432854</td>\n",
              "      <td>0.362787</td>\n",
              "      <td>1.315395e-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.421723</td>\n",
              "      <td>0.014166</td>\n",
              "      <td>0.492073</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000363</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.849163e-05</td>\n",
              "      <td>0.003845</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.715833</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.715833</td>\n",
              "      <td>0.715833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.629271</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>6.987776e-01</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>1.849282e-05</td>\n",
              "      <td>0.013175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017305</td>\n",
              "      <td>0.025003</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.492073</td>\n",
              "      <td>0.352229</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>7.106208e-02</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>6.975000e-01</td>\n",
              "      <td>1.694915e-07</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.174167</td>\n",
              "      <td>0.501199</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>5.000000e-08</td>\n",
              "      <td>0.699167</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>0.452215</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>1.750000e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.981499</td>\n",
              "      <td>0.979061</td>\n",
              "      <td>1.987600e-08</td>\n",
              "      <td>3.577679e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233360</td>\n",
              "      <td>0.469397</td>\n",
              "      <td>0.395969</td>\n",
              "      <td>1.567024e-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.460524</td>\n",
              "      <td>0.017305</td>\n",
              "      <td>0.492073</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000370</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>1.849163e-05</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.003601</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.000094</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.697500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857247</td>\n",
              "      <td>0.089692</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>6.416672e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.569378e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.003525</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005799</td>\n",
              "      <td>0.337778</td>\n",
              "      <td>6.525424e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.416667e-07</td>\n",
              "      <td>7.542372e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.981498</td>\n",
              "      <td>0.979060</td>\n",
              "      <td>4.444444e-03</td>\n",
              "      <td>6.666667e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.000944</td>\n",
              "      <td>0.000732</td>\n",
              "      <td>5.357143e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.001273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>9.568759e-09</td>\n",
              "      <td>0.445572</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.101010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.622190</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>1.420557e-01</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.440678e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.416667e-01</td>\n",
              "      <td>1.440679e-01</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>1.416667e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.981499</td>\n",
              "      <td>0.979060</td>\n",
              "      <td>3.910831e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.006271</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>0.141667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.282828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282828</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.813331</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>4.070336e-04</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>4.497608e-07</td>\n",
              "      <td>0.018251</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023124</td>\n",
              "      <td>0.034950</td>\n",
              "      <td>0.019475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023935</td>\n",
              "      <td>0.024243</td>\n",
              "      <td>0.005768</td>\n",
              "      <td>0.333361</td>\n",
              "      <td>5.914770e-05</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>1.938250e-04</td>\n",
              "      <td>6.779660e-07</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>0.000207</td>\n",
              "      <td>1.600000e-06</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>1.262500e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.981499</td>\n",
              "      <td>0.979060</td>\n",
              "      <td>3.412364e-05</td>\n",
              "      <td>3.071127e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018251</td>\n",
              "      <td>0.038527</td>\n",
              "      <td>0.035421</td>\n",
              "      <td>1.253951e-03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038980</td>\n",
              "      <td>0.023124</td>\n",
              "      <td>0.023935</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000494</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>4.497317e-07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.014343</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.999999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dst sport count  src dport count  ...  Idle Max  Idle Min\n",
              "0              0.0         0.969697  ...  0.715833  0.715833\n",
              "1              0.0         0.969697  ...  0.697500  0.697500\n",
              "2              0.0         0.000000  ...  0.000000  0.000000\n",
              "3              0.0         0.070707  ...  0.141667  0.141667\n",
              "4              0.0         0.282828  ...  0.000000  0.000000\n",
              "\n",
              "[5 rows x 78 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9T8Abk2XhwI"
      },
      "source": [
        "Select a subset of features from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "LFABov84XhwK",
        "outputId": "a7ff97cf-9558-430d-c1c1-9009762adf4d"
      },
      "source": [
        "df_knn_sub=df_knn_train.loc[:, features]\n",
        "df_knn_sub.head()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000806</td>\n",
              "      <td>0.290094</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>8.158333e-01</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.001179</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>6.815038e-02</td>\n",
              "      <td>0.530855</td>\n",
              "      <td>7.141667e-01</td>\n",
              "      <td>0.362854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.121212</td>\n",
              "      <td>0.323232</td>\n",
              "      <td>0.027438</td>\n",
              "      <td>0.000293</td>\n",
              "      <td>0.058490</td>\n",
              "      <td>7.597250e-04</td>\n",
              "      <td>0.400011</td>\n",
              "      <td>0.038557</td>\n",
              "      <td>0.005765</td>\n",
              "      <td>1.693375e-04</td>\n",
              "      <td>0.020649</td>\n",
              "      <td>5.154583e-04</td>\n",
              "      <td>0.025689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.020202</td>\n",
              "      <td>0.575758</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585859</td>\n",
              "      <td>0.060606</td>\n",
              "      <td>0.001491</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.500000e-08</td>\n",
              "      <td>0.400026</td>\n",
              "      <td>0.006230</td>\n",
              "      <td>0.005766</td>\n",
              "      <td>8.548889e-05</td>\n",
              "      <td>0.029972</td>\n",
              "      <td>2.563917e-04</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.040404</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.403390</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.916667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.010101</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.916667e-07</td>\n",
              "      <td>0.408511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000e-07</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dst sport count  src dport count  ...  Flow IAT Max  Bwd Packet Length Std\n",
              "0         0.010101         1.000000  ...  7.141667e-01               0.362854\n",
              "1         0.010101         0.222222  ...  5.154583e-04               0.025689\n",
              "2         0.000000         0.010101  ...  2.563917e-04               0.000000\n",
              "3         0.010101         0.000000  ...  9.916667e-07               0.000000\n",
              "4         0.010101         0.030303  ...  4.000000e-07               0.000000\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "zhVGlgN5XhwK",
        "outputId": "b9aee704-8323-463b-83fc-e0e03b3d99ad"
      },
      "source": [
        "df_knn_test_sub=df_knn_test.loc[:, features]\n",
        "df_knn_test_sub.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dst sport count</th>\n",
              "      <th>src dport count</th>\n",
              "      <th>dst src count</th>\n",
              "      <th>dport count</th>\n",
              "      <th>sport count</th>\n",
              "      <th>dst host count</th>\n",
              "      <th>src host count</th>\n",
              "      <th>Fwd Packet Length Max</th>\n",
              "      <th>Flow IAT Std</th>\n",
              "      <th>Fwd Packet Length Std</th>\n",
              "      <th>Fwd IAT Total</th>\n",
              "      <th>Flow Packets/s</th>\n",
              "      <th>Fwd Packet Length Mean</th>\n",
              "      <th>Flow Bytes/s</th>\n",
              "      <th>Flow IAT Mean</th>\n",
              "      <th>Bwd Packet Length Mean</th>\n",
              "      <th>Flow IAT Max</th>\n",
              "      <th>Bwd Packet Length Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.013417</td>\n",
              "      <td>0.305425</td>\n",
              "      <td>0.023453</td>\n",
              "      <td>0.715833</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.014166</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>6.627202e-02</td>\n",
              "      <td>0.492073</td>\n",
              "      <td>7.158333e-01</td>\n",
              "      <td>0.324761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.969697</td>\n",
              "      <td>0.013175</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.025003</td>\n",
              "      <td>0.697500</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.017305</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>7.106208e-02</td>\n",
              "      <td>0.492073</td>\n",
              "      <td>6.975000e-01</td>\n",
              "      <td>0.352229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.337778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005799</td>\n",
              "      <td>6.525424e-07</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>6.416667e-07</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.101010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070707</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005761</td>\n",
              "      <td>1.440678e-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.416667e-01</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.282828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282828</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484848</td>\n",
              "      <td>0.018251</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.034950</td>\n",
              "      <td>0.000407</td>\n",
              "      <td>0.333361</td>\n",
              "      <td>0.023124</td>\n",
              "      <td>0.005768</td>\n",
              "      <td>5.914770e-05</td>\n",
              "      <td>0.023935</td>\n",
              "      <td>1.938250e-04</td>\n",
              "      <td>0.024243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   dst sport count  src dport count  ...  Flow IAT Max  Bwd Packet Length Std\n",
              "0              0.0         0.969697  ...  7.158333e-01               0.324761\n",
              "1              0.0         0.969697  ...  6.975000e-01               0.352229\n",
              "2              0.0         0.000000  ...  6.416667e-07               0.000000\n",
              "3              0.0         0.070707  ...  1.416667e-01               0.000000\n",
              "4              0.0         0.282828  ...  1.938250e-04               0.024243\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k59G_b79XhwK"
      },
      "source": [
        "Convert dataframes to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJHMos8rXhwK"
      },
      "source": [
        "X_train_knn = df_knn_sub.to_numpy()\n",
        "X_test_knn = df_knn_test_sub.to_numpy()"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hAzqyPsXhwK",
        "outputId": "bbe9fe67-662c-4d8e-d917-169987a4ba62"
      },
      "source": [
        "for i in range(5,X_train_knn.shape[1]+1):\n",
        "    knn=KNeighborsClassifier(n_neighbors=i)\n",
        "    model_knn=knn.fit(X_train_knn,y_train)\n",
        "    y_pred=model_knn.predict(X_test_knn)\n",
        "    print(\"for \" , i,  \" as K, accuracy is : \", accuracy_score(y_test, y_pred))\n",
        "    display_metrics(y_test, y_pred, labels_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for  5  as K, accuracy is :  0.9596674501148644\n",
            "\n",
            "Accuracy: 0.96\n",
            "\n",
            "Micro Precision: 0.96\n",
            "Micro Recall: 0.96\n",
            "Micro F1-score: 0.96\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.79\n",
            "Macro Recall: 0.75\n",
            "Macro F1-score: 0.77\n",
            "\n",
            "Weighted Precision: 0.96\n",
            "Weighted Recall: 0.96\n",
            "Weighted F1-score: 0.96\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.95      0.99      0.97    105019\n",
            "                       Bot       0.75      0.63      0.68       280\n",
            "                      DDoS       0.98      1.00      0.99     19271\n",
            "             DoS GoldenEye       0.95      0.98      0.97      1542\n",
            "                  DoS Hulk       1.00      0.98      0.99     34547\n",
            "          DoS Slowhttptest       0.98      0.99      0.98       828\n",
            "             DoS slowloris       0.78      0.89      0.83       834\n",
            "               FTP-Patator       0.94      0.82      0.88      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.94      0.81      0.87     23846\n",
            "               SSH-Patator       0.95      0.59      0.73       826\n",
            "  Web Attack � Brute Force       0.86      0.78      0.82       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.84      0.78      0.81        93\n",
            "\n",
            "                 micro avg       0.96      0.96      0.96    188483\n",
            "                 macro avg       0.79      0.75      0.77    188483\n",
            "              weighted avg       0.96      0.96      0.96    188483\n",
            "               samples avg       0.96      0.96      0.96    188483\n",
            "\n",
            "for  6  as K, accuracy is :  0.9583039319195895\n",
            "\n",
            "Accuracy: 0.96\n",
            "\n",
            "Micro Precision: 0.96\n",
            "Micro Recall: 0.96\n",
            "Micro F1-score: 0.96\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.81\n",
            "Macro Recall: 0.73\n",
            "Macro F1-score: 0.76\n",
            "\n",
            "Weighted Precision: 0.96\n",
            "Weighted Recall: 0.96\n",
            "Weighted F1-score: 0.96\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.95      0.98      0.97    105019\n",
            "                       Bot       0.79      0.59      0.68       280\n",
            "                      DDoS       0.98      1.00      0.99     19271\n",
            "             DoS GoldenEye       0.96      0.98      0.97      1542\n",
            "                  DoS Hulk       1.00      0.98      0.99     34547\n",
            "          DoS Slowhttptest       1.00      0.99      0.99       828\n",
            "             DoS slowloris       0.79      0.87      0.83       834\n",
            "               FTP-Patator       0.95      0.79      0.86      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.94      0.81      0.87     23846\n",
            "               SSH-Patator       0.96      0.58      0.72       826\n",
            "  Web Attack � Brute Force       0.89      0.71      0.79       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.92      0.72      0.81        93\n",
            "\n",
            "                 micro avg       0.96      0.96      0.96    188483\n",
            "                 macro avg       0.81      0.73      0.76    188483\n",
            "              weighted avg       0.96      0.96      0.96    188483\n",
            "               samples avg       0.96      0.96      0.96    188483\n",
            "\n",
            "for  7  as K, accuracy is :  0.9595560342312038\n",
            "\n",
            "Accuracy: 0.96\n",
            "\n",
            "Micro Precision: 0.96\n",
            "Micro Recall: 0.96\n",
            "Micro F1-score: 0.96\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.79\n",
            "Macro Recall: 0.74\n",
            "Macro F1-score: 0.76\n",
            "\n",
            "Weighted Precision: 0.96\n",
            "Weighted Recall: 0.96\n",
            "Weighted F1-score: 0.96\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.95      0.99      0.97    105019\n",
            "                       Bot       0.77      0.63      0.69       280\n",
            "                      DDoS       0.98      1.00      0.99     19271\n",
            "             DoS GoldenEye       0.94      0.98      0.96      1542\n",
            "                  DoS Hulk       1.00      0.98      0.99     34547\n",
            "          DoS Slowhttptest       0.99      0.99      0.99       828\n",
            "             DoS slowloris       0.77      0.89      0.83       834\n",
            "               FTP-Patator       0.92      0.85      0.88      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.94      0.81      0.87     23846\n",
            "               SSH-Patator       0.95      0.58      0.72       826\n",
            "  Web Attack � Brute Force       0.83      0.74      0.78       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.86      0.72      0.78        93\n",
            "\n",
            "                 micro avg       0.96      0.96      0.96    188483\n",
            "                 macro avg       0.79      0.74      0.76    188483\n",
            "              weighted avg       0.96      0.96      0.96    188483\n",
            "               samples avg       0.96      0.96      0.96    188483\n",
            "\n",
            "for  8  as K, accuracy is :  0.9581712939628507\n",
            "\n",
            "Accuracy: 0.96\n",
            "\n",
            "Micro Precision: 0.96\n",
            "Micro Recall: 0.96\n",
            "Micro F1-score: 0.96\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.80\n",
            "Macro Recall: 0.73\n",
            "Macro F1-score: 0.76\n",
            "\n",
            "Weighted Precision: 0.96\n",
            "Weighted Recall: 0.96\n",
            "Weighted F1-score: 0.96\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.95      0.98      0.97    105019\n",
            "                       Bot       0.79      0.60      0.68       280\n",
            "                      DDoS       0.98      1.00      0.99     19271\n",
            "             DoS GoldenEye       0.96      0.98      0.97      1542\n",
            "                  DoS Hulk       1.00      0.98      0.99     34547\n",
            "          DoS Slowhttptest       0.99      0.99      0.99       828\n",
            "             DoS slowloris       0.79      0.88      0.83       834\n",
            "               FTP-Patator       0.92      0.81      0.86      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.94      0.81      0.87     23846\n",
            "               SSH-Patator       0.96      0.55      0.70       826\n",
            "  Web Attack � Brute Force       0.85      0.73      0.79       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.91      0.67      0.77        93\n",
            "\n",
            "                 micro avg       0.96      0.96      0.96    188483\n",
            "                 macro avg       0.80      0.73      0.76    188483\n",
            "              weighted avg       0.96      0.96      0.96    188483\n",
            "               samples avg       0.96      0.96      0.96    188483\n",
            "\n",
            "for  9  as K, accuracy is :  0.9593278969456132\n",
            "\n",
            "Accuracy: 0.96\n",
            "\n",
            "Micro Precision: 0.96\n",
            "Micro Recall: 0.96\n",
            "Micro F1-score: 0.96\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.79\n",
            "Macro Recall: 0.74\n",
            "Macro F1-score: 0.76\n",
            "\n",
            "Weighted Precision: 0.96\n",
            "Weighted Recall: 0.96\n",
            "Weighted F1-score: 0.96\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.95      0.98      0.97    105019\n",
            "                       Bot       0.75      0.66      0.70       280\n",
            "                      DDoS       0.98      1.00      0.99     19271\n",
            "             DoS GoldenEye       0.96      0.98      0.97      1542\n",
            "                  DoS Hulk       1.00      0.98      0.99     34547\n",
            "          DoS Slowhttptest       0.99      0.99      0.99       828\n",
            "             DoS slowloris       0.78      0.88      0.83       834\n",
            "               FTP-Patator       0.91      0.88      0.90      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.93      0.81      0.87     23846\n",
            "               SSH-Patator       0.95      0.55      0.70       826\n",
            "  Web Attack � Brute Force       0.79      0.76      0.77       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.85      0.68      0.75        93\n",
            "\n",
            "                 micro avg       0.96      0.96      0.96    188483\n",
            "                 macro avg       0.79      0.74      0.76    188483\n",
            "              weighted avg       0.96      0.96      0.96    188483\n",
            "               samples avg       0.96      0.96      0.96    188483\n",
            "\n",
            "for  10  as K, accuracy is :  0.9581872105176594\n",
            "\n",
            "Accuracy: 0.96\n",
            "\n",
            "Micro Precision: 0.96\n",
            "Micro Recall: 0.96\n",
            "Micro F1-score: 0.96\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.80\n",
            "Macro Recall: 0.73\n",
            "Macro F1-score: 0.76\n",
            "\n",
            "Weighted Precision: 0.96\n",
            "Weighted Recall: 0.96\n",
            "Weighted F1-score: 0.96\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.95      0.98      0.97    105019\n",
            "                       Bot       0.76      0.64      0.69       280\n",
            "                      DDoS       0.98      1.00      0.99     19271\n",
            "             DoS GoldenEye       0.96      0.98      0.97      1542\n",
            "                  DoS Hulk       1.00      0.98      0.99     34547\n",
            "          DoS Slowhttptest       1.00      0.99      0.99       828\n",
            "             DoS slowloris       0.78      0.87      0.82       834\n",
            "               FTP-Patator       0.91      0.85      0.88      1178\n",
            "                Heartbleed       1.00      1.00      1.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.94      0.81      0.87     23846\n",
            "               SSH-Patator       0.95      0.54      0.69       826\n",
            "  Web Attack � Brute Force       0.84      0.73      0.78       209\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         7\n",
            "          Web Attack � XSS       0.91      0.62      0.74        93\n",
            "\n",
            "                 micro avg       0.96      0.96      0.96    188483\n",
            "                 macro avg       0.80      0.73      0.76    188483\n",
            "              weighted avg       0.96      0.96      0.96    188483\n",
            "               samples avg       0.96      0.96      0.96    188483\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQvcVlbmXhwL"
      },
      "source": [
        "# Model 9: DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tL-xBt_XhwL"
      },
      "source": [
        "def make_model(metrics=METRICS, output_bias=None):\n",
        "  if output_bias is not None:\n",
        "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(\n",
        "          256, activation='relu',\n",
        "          input_shape=(X_train.shape[-1],)),\n",
        "      #tf.keras.layers.Dropout(0.9),\n",
        "      tf.keras.layers.Dense(256, activation ='relu'),\n",
        "      #tf.keras.layers.Dropout(0.4),\n",
        "      #tf.keras.layers.Dense(256, activation ='relu'),\n",
        "      #tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(128, activation ='relu'),\n",
        "      #tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(64, activation ='relu'),\n",
        "      tf.keras.layers.Dense(y_train.shape[-1], activation='softmax',\n",
        "                         bias_initializer=output_bias),\n",
        "  ])\n",
        " \n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
        "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "      metrics=metrics)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAzpGMEoXhwL"
      },
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 9000\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_auc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWmjTb9kXhwL",
        "outputId": "bfc8258a-4b9b-4aaf-b96d-09fab04d6dc0"
      },
      "source": [
        "model_dnn = make_model()\n",
        "model_dnn.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               20224     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 15)                975       \n",
            "=================================================================\n",
            "Total params: 128,143\n",
            "Trainable params: 128,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajWocDr4_30a"
      },
      "source": [
        "If loading the validation dataset has an issue, please load the csv files again, and encode it again. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeRlOQj6XhwL",
        "outputId": "b71382df-e1b2-439b-879b-f63569eb2453"
      },
      "source": [
        "baseline_history = model_dnn.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    #callbacks=[early_stopping],\n",
        "    validation_data=(X_val, y_val))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "98/98 [==============================] - 3s 26ms/step - loss: 0.0100 - tp: 872642.0000 - fp: 6874.0000 - tn: 12307372.0000 - fn: 6947.0000 - accuracy: 0.9990 - precision: 0.9922 - recall: 0.9921 - auc: 0.9983 - val_loss: 0.0023 - val_tp: 187574.0000 - val_fp: 897.0000 - val_tn: 2637879.0000 - val_fn: 910.0000 - val_accuracy: 0.9994 - val_precision: 0.9952 - val_recall: 0.9952 - val_auc: 0.9997\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 2s 24ms/step - loss: 0.0014 - tp: 876663.0000 - fp: 2873.0000 - tn: 12311373.0000 - fn: 2926.0000 - accuracy: 0.9996 - precision: 0.9967 - recall: 0.9967 - auc: 0.9999 - val_loss: 0.0019 - val_tp: 187789.0000 - val_fp: 686.0000 - val_tn: 2638090.0000 - val_fn: 695.0000 - val_accuracy: 0.9995 - val_precision: 0.9964 - val_recall: 0.9963 - val_auc: 0.9998\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 2s 25ms/step - loss: 0.0012 - tp: 877118.0000 - fp: 2432.0000 - tn: 12311814.0000 - fn: 2471.0000 - accuracy: 0.9996 - precision: 0.9972 - recall: 0.9972 - auc: 0.9999 - val_loss: 0.0018 - val_tp: 187836.0000 - val_fp: 637.0000 - val_tn: 2638139.0000 - val_fn: 648.0000 - val_accuracy: 0.9995 - val_precision: 0.9966 - val_recall: 0.9966 - val_auc: 0.9998\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 2s 25ms/step - loss: 0.0011 - tp: 877453.0000 - fp: 2100.0000 - tn: 12312146.0000 - fn: 2136.0000 - accuracy: 0.9997 - precision: 0.9976 - recall: 0.9976 - auc: 0.9999 - val_loss: 0.0017 - val_tp: 187913.0000 - val_fp: 567.0000 - val_tn: 2638209.0000 - val_fn: 571.0000 - val_accuracy: 0.9996 - val_precision: 0.9970 - val_recall: 0.9970 - val_auc: 0.9998\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 2s 25ms/step - loss: 9.1591e-04 - tp: 877716.0000 - fp: 1833.0000 - tn: 12312413.0000 - fn: 1873.0000 - accuracy: 0.9997 - precision: 0.9979 - recall: 0.9979 - auc: 0.9999 - val_loss: 0.0018 - val_tp: 187893.0000 - val_fp: 582.0000 - val_tn: 2638194.0000 - val_fn: 591.0000 - val_accuracy: 0.9996 - val_precision: 0.9969 - val_recall: 0.9969 - val_auc: 0.9997\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 2s 25ms/step - loss: 7.5887e-04 - tp: 878138.0000 - fp: 1414.0000 - tn: 12312832.0000 - fn: 1451.0000 - accuracy: 0.9998 - precision: 0.9984 - recall: 0.9984 - auc: 0.9999 - val_loss: 0.0017 - val_tp: 187980.0000 - val_fp: 492.0000 - val_tn: 2638284.0000 - val_fn: 504.0000 - val_accuracy: 0.9996 - val_precision: 0.9974 - val_recall: 0.9973 - val_auc: 0.9997\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 2s 25ms/step - loss: 6.4384e-04 - tp: 878536.0000 - fp: 1010.0000 - tn: 12313236.0000 - fn: 1053.0000 - accuracy: 0.9998 - precision: 0.9989 - recall: 0.9988 - auc: 0.9999 - val_loss: 0.0017 - val_tp: 188001.0000 - val_fp: 472.0000 - val_tn: 2638304.0000 - val_fn: 483.0000 - val_accuracy: 0.9997 - val_precision: 0.9975 - val_recall: 0.9974 - val_auc: 0.9997\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 3s 26ms/step - loss: 5.7025e-04 - tp: 878658.0000 - fp: 890.0000 - tn: 12313356.0000 - fn: 931.0000 - accuracy: 0.9999 - precision: 0.9990 - recall: 0.9989 - auc: 0.9999 - val_loss: 0.0018 - val_tp: 187996.0000 - val_fp: 478.0000 - val_tn: 2638298.0000 - val_fn: 488.0000 - val_accuracy: 0.9997 - val_precision: 0.9975 - val_recall: 0.9974 - val_auc: 0.9997\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 2s 25ms/step - loss: 5.3363e-04 - tp: 878717.0000 - fp: 833.0000 - tn: 12313413.0000 - fn: 872.0000 - accuracy: 0.9999 - precision: 0.9991 - recall: 0.9990 - auc: 0.9999 - val_loss: 0.0019 - val_tp: 187960.0000 - val_fp: 515.0000 - val_tn: 2638261.0000 - val_fn: 524.0000 - val_accuracy: 0.9996 - val_precision: 0.9973 - val_recall: 0.9972 - val_auc: 0.9997\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 2s 25ms/step - loss: 5.0953e-04 - tp: 878763.0000 - fp: 786.0000 - tn: 12313460.0000 - fn: 826.0000 - accuracy: 0.9999 - precision: 0.9991 - recall: 0.9991 - auc: 0.9999 - val_loss: 0.0017 - val_tp: 188000.0000 - val_fp: 475.0000 - val_tn: 2638301.0000 - val_fn: 484.0000 - val_accuracy: 0.9997 - val_precision: 0.9975 - val_recall: 0.9974 - val_auc: 0.9997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7q_MD9Q5_Jd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPDH0IA_8xee"
      },
      "source": [
        "y_pred=model_dnn.predict(X_test)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PdaWVhX9BvJ",
        "outputId": "f97d0271-c4ca-45fe-f5bb-29b64d4cd75d"
      },
      "source": [
        "accuracy = model_dnn.evaluate(X_test, y_test, batch_size=BATCH_SIZE, verbose=1)\r\n",
        "print('Accuracy is: ', accuracy)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 [==============================] - 0s 21ms/step - loss: 0.0203 - tp: 185828.0000 - fp: 2636.0000 - tn: 2636126.0000 - fn: 2655.0000 - accuracy: 0.9981 - precision: 0.9860 - recall: 0.9859 - auc: 0.9932\n",
            "Accuracy is:  [0.020345160737633705, 185828.0, 2636.0, 2636126.0, 2655.0, 0.9981285333633423, 0.9860132336616516, 0.985913872718811, 0.993186891078949]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZcyLQPqAlWS",
        "outputId": "5b14f91d-5767-41e0-c3f3-570f4f262dd0"
      },
      "source": [
        "display_metrics(y_test_ada, np.argmax(y_pred, axis = 1), labels_d)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.99\n",
            "\n",
            "Micro Precision: 0.99\n",
            "Micro Recall: 0.99\n",
            "Micro F1-score: 0.99\n",
            "\n",
            "Macro Precision: 0.81\n",
            "Macro Recall: 0.72\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.74\n",
            "\n",
            "Weighted Precision: 0.99\n",
            "Weighted Recall: 0.99\n",
            "Weighted F1-score: 0.99\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.99      0.99      0.99    105019\n",
            "                       Bot       0.88      0.98      0.93       280\n",
            "                      DDoS       1.00      1.00      1.00     19271\n",
            "             DoS GoldenEye       0.99      0.99      0.99      1542\n",
            "                  DoS Hulk       1.00      1.00      1.00     34547\n",
            "          DoS Slowhttptest       1.00      0.99      1.00       828\n",
            "             DoS slowloris       0.99      0.99      0.99       834\n",
            "               FTP-Patator       0.98      0.51      0.67      1178\n",
            "                Heartbleed       0.00      0.00      0.00         2\n",
            "              Infiltration       0.00      0.00      0.00         1\n",
            "                  PortScan       0.94      1.00      0.97     23846\n",
            "               SSH-Patator       0.88      0.48      0.62       826\n",
            "  Web Attack � Brute Force       0.84      0.68      0.75       209\n",
            "Web Attack � Sql Injection       1.00      0.29      0.44         7\n",
            "          Web Attack � XSS       0.59      0.88      0.71        93\n",
            "\n",
            "                  accuracy                           0.99    188483\n",
            "                 macro avg       0.81      0.72      0.74    188483\n",
            "              weighted avg       0.99      0.99      0.99    188483\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPThzsW6QleP"
      },
      "source": [
        "The above result is based on Standardization dataset, not normalization dataset. However, we notice that using normalized dataset, we can detect Heartbleed and Infliltration cases, but not sql injection cases. Using standardized dataset, we can detect all sql attacks, but not the other two cases. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erUa8gpIZ04U"
      },
      "source": [
        "# Model 10: CNN1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTmLBZDpZ04U"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Flatten, Dense, Activation,Dropout\n",
        "from tensorflow.keras.constraints import max_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLXy3meMZ04U",
        "outputId": "f144a82f-a850-49c4-974e-1d2ae9ca3ca2"
      },
      "source": [
        "#hyper-params\n",
        "batch_size = 1024 # increasing batch size with more gpu added\n",
        "input_dim = X_train.shape[1]\n",
        "num_class = 15                   # 15 intrusion classes, including benign traffic class\n",
        "num_epochs = 30\n",
        "learning_rates = 1e-3\n",
        "regularizations = 1e-3\n",
        "optim = tf.keras.optimizers.Adam(lr=learning_rates, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "print(input_dim)\n",
        "print(num_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNRbsq6CZ04V",
        "outputId": "148ee859-e320-4a22-c118-cabe52ab7d56"
      },
      "source": [
        "#X_train_r = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_train_r = np.zeros((len(X_train), input_dim, 1))\n",
        "X_train_r[:, :, 0] = X_train[:, :input_dim]\n",
        "print(X_train_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(556548, 71, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjmIpn1HZ04W",
        "outputId": "2c1c2f93-014b-4c08-8435-e739318768fc"
      },
      "source": [
        "X_test_r = np.zeros((len(X_test), input_dim, 1))\n",
        "X_test_r[:, :, 0] = X_test[:, :input_dim]\n",
        "print(X_test_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(278270, 71, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_KlI1VeZ04W",
        "outputId": "68ffab00-7db7-42ca-d671-16330e9fa8f9"
      },
      "source": [
        "X_val_r = np.zeros((len(X_val), input_dim, 1))\n",
        "X_val_r[:, :, 0] = X_val[:, :input_dim]\n",
        "print(X_val_r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(278270, 71, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkQlzQU0ajuD",
        "outputId": "71d58c31-8c34-435a-934b-9006668ffdc5"
      },
      "source": [
        "X_train_r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[7.66048676e-01],\n",
              "        [5.93603125e-03],\n",
              "        [1.00000000e+00],\n",
              "        ...,\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[7.29167620e-01],\n",
              "        [1.22077764e-03],\n",
              "        [3.52941176e-01],\n",
              "        ...,\n",
              "        [0.00000000e+00],\n",
              "        [7.12500000e-01],\n",
              "        [7.12500000e-01]],\n",
              "\n",
              "       [[7.86144808e-01],\n",
              "        [6.76005616e-03],\n",
              "        [3.52941176e-01],\n",
              "        ...,\n",
              "        [8.96864890e-03],\n",
              "        [4.90833333e-01],\n",
              "        [4.83333333e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[2.53009842e-01],\n",
              "        [1.22077764e-03],\n",
              "        [3.52941176e-01],\n",
              "        ...,\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[7.85610742e-01],\n",
              "        [8.08765183e-04],\n",
              "        [1.00000000e+00],\n",
              "        ...,\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]],\n",
              "\n",
              "       [[8.26276036e-01],\n",
              "        [1.22077764e-03],\n",
              "        [3.52941176e-01],\n",
              "        ...,\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00],\n",
              "        [0.00000000e+00]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpTZU5OPZ04W",
        "outputId": "31aa9725-0fe7-4c0d-9ab7-1b4176ad7fcd"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# input layer\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', input_shape=(71,1)))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model.add(Conv1D(filters=128, kernel_size=3))\n",
        "model.add(BatchNormalization(axis=1))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_class))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_8 (Conv1D)            (None, 71, 32)            128       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 71, 32)            284       \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 71, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_9 (Conv1D)            (None, 69, 128)           12416     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 69, 128)           276       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 69, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 8832)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               883300    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 15)                1515      \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 897,919\n",
            "Trainable params: 897,639\n",
            "Non-trainable params: 280\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEpzDBNyC7P2"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\r\n",
        "    monitor='val_accuracy', \r\n",
        "    verbose=1,\r\n",
        "    patience=10,\r\n",
        "    mode='max',\r\n",
        "    restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb52JhHSZ04W"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFJZ11t1Z04X"
      },
      "source": [
        "## Step 5. Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq31n_0YZ04X",
        "outputId": "ad9b4e62-35a9-429f-9d10-4086725a878f"
      },
      "source": [
        "# fit network\n",
        "epochs = 50\n",
        "model.fit(X_train_r, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test_r, y_test), verbose=1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.9541 - val_accuracy: 0.8272\n",
            "Epoch 2/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.5939 - val_accuracy: 0.8978\n",
            "Epoch 3/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.4867 - val_accuracy: 0.9373\n",
            "Epoch 4/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 1.2544 - val_accuracy: 0.7860\n",
            "Epoch 5/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.5194 - val_accuracy: 0.9147\n",
            "Epoch 6/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.7574 - val_accuracy: 0.8717\n",
            "Epoch 7/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0095 - accuracy: 0.9965 - val_loss: 0.4678 - val_accuracy: 0.9551\n",
            "Epoch 8/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.3560 - val_accuracy: 0.9581\n",
            "Epoch 9/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.7849 - val_accuracy: 0.8832\n",
            "Epoch 10/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.3110 - val_accuracy: 0.9654\n",
            "Epoch 11/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.7204 - val_accuracy: 0.8893\n",
            "Epoch 12/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.5198 - val_accuracy: 0.9458\n",
            "Epoch 13/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.9469 - val_accuracy: 0.8524\n",
            "Epoch 14/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0085 - accuracy: 0.9968 - val_loss: 0.3824 - val_accuracy: 0.9637\n",
            "Epoch 15/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.3664 - val_accuracy: 0.9600\n",
            "Epoch 16/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0088 - accuracy: 0.9967 - val_loss: 0.5777 - val_accuracy: 0.9319\n",
            "Epoch 17/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0087 - accuracy: 0.9967 - val_loss: 0.3704 - val_accuracy: 0.9621\n",
            "Epoch 18/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.4081 - val_accuracy: 0.9647\n",
            "Epoch 19/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.4933 - val_accuracy: 0.9559\n",
            "Epoch 20/50\n",
            "544/544 [==============================] - 10s 19ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 1.0666 - val_accuracy: 0.8716\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7fd100bba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSo0TpT5Z04X",
        "outputId": "d07be9f6-400d-481c-8ee2-ebceae01716b"
      },
      "source": [
        "# evaluate model\n",
        "accuracy = model.evaluate(X_val_r, y_val, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "272/272 [==============================] - 2s 6ms/step - loss: 79.3116 - accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGNmOrhH1CL"
      },
      "source": [
        "y_pred=model.predict(X_val_r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltyd2KVLIBCK",
        "outputId": "aad22263-814e-4f9e-a3c2-621c490ef3df"
      },
      "source": [
        "display_metrics(y_val_ada, np.argmax(y_pred, axis = 1), labels_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy: 0.50\n",
            "\n",
            "Micro Precision: 0.50\n",
            "Micro Recall: 0.50\n",
            "Micro F1-score: 0.50\n",
            "\n",
            "Macro Precision: 0.03\n",
            "Macro Recall: 0.07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Macro F1-score: 0.04\n",
            "\n",
            "Weighted Precision: 0.25\n",
            "Weighted Recall: 0.50\n",
            "Weighted F1-score: 0.33\n",
            "\n",
            "Classification Report\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "                    BENIGN       0.50      1.00      0.67    139135\n",
            "                       Bot       0.00      0.00      0.00       489\n",
            "                      DDoS       0.00      0.00      0.00     32006\n",
            "             DoS GoldenEye       0.00      0.00      0.00      2573\n",
            "                  DoS Hulk       0.00      0.00      0.00     57531\n",
            "          DoS Slowhttptest       0.00      0.00      0.00      1374\n",
            "             DoS slowloris       0.00      0.00      0.00      1449\n",
            "               FTP-Patator       0.00      0.00      0.00      1983\n",
            "                Heartbleed       0.00      0.00      0.00         2\n",
            "              Infiltration       0.00      0.00      0.00         9\n",
            "                  PortScan       0.00      0.00      0.00     39701\n",
            "               SSH-Patator       0.00      0.00      0.00      1474\n",
            "  Web Attack � Brute Force       0.00      0.00      0.00       376\n",
            "Web Attack � Sql Injection       0.00      0.00      0.00         5\n",
            "          Web Attack � XSS       0.00      0.00      0.00       163\n",
            "\n",
            "                  accuracy                           0.50    278270\n",
            "                 macro avg       0.03      0.07      0.04    278270\n",
            "              weighted avg       0.25      0.50      0.33    278270\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbhp6oW_Z04X"
      },
      "source": [
        ""
      ]
    }
  ]
}